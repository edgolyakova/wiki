{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4cRE8IbIrIV"
   },
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install 🤗 Transformers and 🤗 Datasets. Uncomment the following cell and run it. We also use the `sacrebleu` and `sentencepiece` libraries - you may need to install these even if you already have 🤗 Transformers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOsHUjgdIrIW",
    "outputId": "fc34e508-ae47-497a-a9da-d823281274a1"
   },
   "outputs": [],
   "source": [
    "! pip install transformers[sentencepiece] datasets\n",
    "! pip install sacrebleu sentencepiece\n",
    "! pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CLMDDAWk6Mij",
    "outputId": "2f74a3f8-237c-40d7-ac3e-8b6c310af4f4"
   },
   "outputs": [],
   "source": [
    "! pip install tensorflow==2.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDKJezAo6Mij"
   },
   "source": [
    "If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.\n",
    "\n",
    "To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\n",
    "\n",
    "First you have to store your authentication token from the Hugging Face website (sign up [here](https://huggingface.co/join) if you haven't already!) then uncomment the following cell and input your token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303,
     "referenced_widgets": [
      "ad13f142a3034624aecd0fa85db427c9",
      "e218550fb85f4b52b05e7058b8817449",
      "2222791718d74b89be49dc52a2c4df64",
      "5a79ae84164049d39a9e3fc7cae0a8fc",
      "25127df4fea7451281eca5d116a6b688",
      "102ffa5cc3774a2fa5c0da171bf8af88",
      "18368eb62d7c4ef2b6a5bc82e099dc97",
      "b660541fd76f491db348829f3b5135c9",
      "c90d886a7ff84c9c8e4a9a18a83b8441",
      "5fd67795b114407b865e334d3e043fcb",
      "931c89c5da334cb8b4ba35eb94658d11",
      "ef6f751742c54800a465c41186f3f623",
      "6cb3ed3091ea46f6a08a03b9e91e6a46",
      "7d110c8373464d298702384b29dab14b",
      "d67e2ea73a9b4371adef225a84a3fd60",
      "f5a2549f677e490fa4f22c8e82b8672b",
      "5d77c0ac0e3643a7a314f86187fee512"
     ]
    },
    "id": "ESRuAmhx6Mik",
    "outputId": "21e1279c-611b-4dbc-fea6-5d96df4e36ae"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c63qsBA26Mik"
   },
   "source": [
    "Then you need to install Git-LFS and setup Git if you haven't already. Uncomment the following instructions and adapt with your name and email:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TS68y8Dt6Mil",
    "outputId": "1076a88c-f443-4d15-d66e-21e0dbd9c8f7"
   },
   "outputs": [],
   "source": [
    "# !apt install git-lfs\n",
    "# !git config --global user.email \"you@example.com\"\n",
    "# !git config --global user.name \"Your Name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em65bWwy6Mil"
   },
   "source": [
    "Make sure your version of Transformers is at least 4.16.0 since some of the functionality we use was introduced in that version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWpsyLMu6Mil",
    "outputId": "42ff4791-f8fd-4606-eeff-cc97a9ded7fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.21.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFASsisvIrIb"
   },
   "source": [
    "You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs [here](https://github.com/huggingface/transformers/tree/master/examples/seq2seq)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-Ilyyvl6Mil"
   },
   "source": [
    "# Convert CSV-file to a dataset-ready format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vw563szX6Mil"
   },
   "source": [
    "The code below works with a specifically formatted csv. Run the cell below to format your CSV accordingly.\n",
    "Your CSV should have at least 2 columns `en` and `xx` where xx is the code of the target language.\n",
    "\n",
    "If the CSV file has PoS tags for source and target language, the expected column names for them are:\n",
    "`pos_en` and `pos_xx`. \n",
    "\n",
    "If the CSV file has WA tags, the expected column name is `wa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kAaBktPX6Mim"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# source_lang accepted value = 'en'\n",
    "# target_lang accepted values = 'fr'|'zh'\n",
    "# Choose pos_tags=True if the file has PoS tags for the both languages\n",
    "# Choose wa_tags=True if the file has WA tags.\n",
    "# Choose store=True if you want to create a json dump of the file that can be used later\n",
    "\n",
    "def csv_to_dataset(filename, source_lang, target_lang, pos_tags=False, wa_tags=False, store=False):\n",
    "    data = pd.read_csv(filename)\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['translation'] = [{source_lang: x, target_lang: y} for x, y in zip(data[source_lang], data[target_lang])]\n",
    "    if pos_tags:\n",
    "        new_df['pos'] = [{source_lang: x, target_lang: y} for x, y in zip(data[f'pos_{source_lang}'], data[f'pos_{target_lang}'])]\n",
    "    if wa_tags:\n",
    "        new_df['wa'] = data['wa']\n",
    "    return Dataset.from_pandas(new_df).train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "loaded_dataset = load_from_disk('zh_split_dataset.hf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "# Fine-tuning a model on a translation task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTCFado4IrIc"
   },
   "source": [
    "In this notebook, we will see how to fine-tune one of the [🤗 Transformers](https://github.com/huggingface/transformers) model for a translation task. We will use the [WMT dataset](http://www.statmt.org/wmt16/), a machine translation dataset composed from a collection of various sources, including news commentaries and parliament proceedings.\n",
    "\n",
    "![Widget inference on a translation task](images/translation.png)\n",
    "\n",
    "We will see how to easily load the dataset for this task using 🤗 Datasets and how to fine-tune a model on it using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hmPTXpyG6Min"
   },
   "outputs": [],
   "source": [
    "tokenizer_checkpoint = \"xlm-roberta-base\"\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-zh\"\n",
    "facebook_model = 'facebook/mbart-large-cc25'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RRkXuteIrIh"
   },
   "source": [
    "This notebook is built to run  with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a sequence-to-sequence version in the Transformers library. Here we picked the [`Helsinki-NLP/opus-mt-en-romance`](https://huggingface.co/Helsinki-NLP/opus-mt-en-ROMANCE) checkpoint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "We will use the [🤗 Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the `datasets` function `load_dataset` and the `evaluate` function `load`. We use the English/Romanian part of the WMT dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f2ea9af3be8e41039ca9a7bd896c5a5c",
      "e1577b81df0949228560afb795b43f92",
      "749e363a49a948788eb5f8c896084ff7",
      "d9894f8558424c6bb6b1dcb726e33c2d",
      "244c69abb61f4c11bdb55dc5866d1286",
      "27284060931c496a9954d6678f0309c8",
      "93a91d53b4c34de5946fe08ab92d2783",
      "ea3708c0edd1467596d1d173019ef1bc",
      "c1a5d057f6834c7191daceb38167d195",
      "baf79d06246d423f9fab5abf179a1a7e",
      "7d81df6aca764daaaae0a123a2ab4ce1"
     ]
    },
    "id": "IreSlFmlIrIm",
    "outputId": "5a388eca-815e-44da-8121-ae2c7b65a508"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "\n",
    "metric = load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHUmphG3IrI3"
   },
   "source": [
    "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "i3j8APAoIrI3"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def show_random_elements(dataset, num_examples=5):\n",
    "    assert num_examples <= len(\n",
    "        dataset\n",
    "    ), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset) - 1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset) - 1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "SZy5tRB_IrI7",
    "outputId": "fe85c361-1f20-4e44-8bdd-b19179cbadc9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "      <th>pos</th>\n",
       "      <th>wa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'en': 'two days later on 29 march more fighti...</td>\n",
       "      <td>{'en': 'two NUM\n",
       "days NOUN\n",
       "later ADV\n",
       "on ADP\n",
       "29 ...</td>\n",
       "      <td>0-0 1-0 2-1 3-3 4-4 4-5 5-2 5-6 6-11 6-12 7-8 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'en': 'He also stated that Turkey would not g...</td>\n",
       "      <td>{'en': 'He PRON\n",
       "also ADV\n",
       "stated VERB\n",
       "that SCON...</td>\n",
       "      <td>0-0 1-1 2-2 3-2 4-3 5-4 6-4 7-5 8-6 10-8 12-9 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'en': 'he also managed the los nettos network...</td>\n",
       "      <td>{'en': 'he PRON\n",
       "also ADV\n",
       "managed VERB\n",
       "the DET\n",
       "...</td>\n",
       "      <td>0-0 1-1 2-2 2-3 3-3 4-4 5-5 5-6 6-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'en': 'to win a war you need to know your ene...</td>\n",
       "      <td>{'en': 'to PART\n",
       "win VERB\n",
       "a DET\n",
       "war NOUN\n",
       "you PR...</td>\n",
       "      <td>0-0 1-1 2-1 3-2 4-3 5-4 6-4 7-5 8-6 8-7 9-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'en': 'sometimes that result is an equilibriu...</td>\n",
       "      <td>{'en': 'sometimes ADV\n",
       "that DET\n",
       "result NOUN\n",
       "is ...</td>\n",
       "      <td>0-0 1-1 2-2 3-3 4-4 5-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         translation  \\\n",
       "0  {'en': 'two days later on 29 march more fighti...   \n",
       "1  {'en': 'He also stated that Turkey would not g...   \n",
       "2  {'en': 'he also managed the los nettos network...   \n",
       "3  {'en': 'to win a war you need to know your ene...   \n",
       "4  {'en': 'sometimes that result is an equilibriu...   \n",
       "\n",
       "                                                 pos  \\\n",
       "0  {'en': 'two NUM\n",
       "days NOUN\n",
       "later ADV\n",
       "on ADP\n",
       "29 ...   \n",
       "1  {'en': 'He PRON\n",
       "also ADV\n",
       "stated VERB\n",
       "that SCON...   \n",
       "2  {'en': 'he PRON\n",
       "also ADV\n",
       "managed VERB\n",
       "the DET\n",
       "...   \n",
       "3  {'en': 'to PART\n",
       "win VERB\n",
       "a DET\n",
       "war NOUN\n",
       "you PR...   \n",
       "4  {'en': 'sometimes ADV\n",
       "that DET\n",
       "result NOUN\n",
       "is ...   \n",
       "\n",
       "                                                  wa  \n",
       "0  0-0 1-0 2-1 3-3 4-4 4-5 5-2 5-6 6-11 6-12 7-8 ...  \n",
       "1  0-0 1-1 2-2 3-2 4-3 5-4 6-4 7-5 8-6 10-8 12-9 ...  \n",
       "2                0-0 1-1 2-2 2-3 3-3 4-4 5-5 5-6 6-6  \n",
       "3        0-0 1-1 2-1 3-2 4-3 5-4 6-4 7-5 8-6 8-7 9-8  \n",
       "4                            0-0 1-1 2-2 3-3 4-4 5-5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_random_elements(loaded_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAjuAGDlzSDm",
    "outputId": "46387022-5acb-428c-accc-197439555cfc"
   },
   "outputs": [],
   "source": [
    "!pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213,
     "referenced_widgets": [
      "e569b660e9ef4533b48460b6360e6874",
      "df17515c40504961b7e1b3e807c1e86d",
      "20031c6fef51409f850dcba3b868a1bc",
      "ec27ccf1d1fd419e969a3c10b25232b6",
      "378758016fc046c3883547505c883423",
      "53738098bfd6457caf45ddad9568e6c0",
      "b27b4221f5894332b994483261006b16",
      "70efe7b5094840b894ff61ccc6aed030",
      "7a403937ec524de6b337665a78308fed",
      "4056f31f319e4698977fbe02563f496b",
      "0e31cb1acb8f43c482707191555e53b6",
      "1a7fb058ad4e4974b7277c1c14be649c",
      "2c85d14b6fb846459cef7759ca7d1468",
      "0907f16279864bd48df6d4ec2b2b17cb",
      "d26fefef32494d5da7b20f5cdcbef70f",
      "86149699e693402caa772053da514b06",
      "0d2eabc03ac34121bab54748d92032c5",
      "7e8117c102274c9c8aaa86c918d5dd00",
      "119301bd3069434cb2f2a2308536b096",
      "911f864acf124650a152b4db8245ee27",
      "2751ee9a4ae142a6b9e9f88166d8d390",
      "1570b274a2fc44c3a40d0e34b02df66d",
      "9e3c8c0436ca4391b13f412feb98482f",
      "3dbf9ae2ad01407eb6d1f35f34ea31ec",
      "0524ec1e318841e39b54a61d250c6799",
      "c561eef4836b4255a4eb960ecba6b0a5",
      "c9d4d468062b42f8a0aacaa4657667bf",
      "96eb996b9c804b9e9b8c6dc771792502",
      "5692edda5470493799ae37277e968324",
      "65094228a62d4a14aa1ddc309546dbef",
      "583734d4fd3c43d6b5593a37f3561b52",
      "5998028d41aa4031ab11850e1c8babba",
      "a101d5cf6b0249049e24c8a9b16d896f",
      "b6683e918c0e430c984fad9adb81b033",
      "a83a452b4afe49e7b8e17e8d9fd63485",
      "4ee97aed9b70428088829aa7b00b2f87",
      "94e601c51f9e44ec8a5b99939eefbb7f",
      "8b8f7eb8638342d9a41fadd370192be2",
      "8f99fbcd296c41f492c2383564e7a2d4",
      "7eb53ddfd0f9484883016e0f4831bb59",
      "dd046fa7a6154fda951901d2ca822f64",
      "2384f392f8544d27a8cf8af92d65b0b0",
      "72b1cd9045d244a487667e763d97c769",
      "61846cdcb60b46d5b8221fcb702f40b6",
      "182c9714756f4f919d8f370d7b674166",
      "0d22e89479e947c888cc0505edcdad45",
      "12f5618901b04cc7a3367e412e4f525a",
      "b8b146c4d0bc4117b432b33e932b9877",
      "77022603cf7d4fbaa21ce3ca627293c7",
      "8a0f8412de2b4c8b94cf9cd51827f40f",
      "49894c5d38c54ee28d79cfaade6eb15e",
      "86733c8117da49658dd1e8d197759d3c",
      "8e856733baf3434092ab5889cb30c6aa",
      "4662851903844f9496171c2a83834605",
      "33cad270c9b841d9a7af9e38b03f4f07"
     ]
    },
    "id": "eXNLu_-nIrJI",
    "outputId": "8097df1a-b0d3-4238-e77f-83df79bd55d7"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "y_CwkVsLzafe"
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'他们 r\\n砍掉 v\\n高大 a\\n的 uj\\n树 v\\n'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dataset['train']['pos'][90]['zh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 4127, 5609, 10, 6494, 5609, 10, 11015, 10, 22690, 2, 250004]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('a good side a bad side a past a future')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both English and Chinese the encodings are ended with 2s which shouldn't affect the WA and PoS tags.\n",
    "\n",
    "In comparison to the English tokenized sentence, the Chinse sentence also includes space encodings. We will filter it out later when working with WA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65097, 156, 316, 65033, 0]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x!= 8, tokenizer.encode('Safari 不 支持 MNGJNG')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add all the chinese tokens from our files to the tokenizer so the tokenizer won't split them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = set()\n",
    "\n",
    "for x in loaded_dataset['train']['translation']:\n",
    "    zh_sent = x['zh'].rstrip().split()\n",
    "    tokens.update(zh_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = tokens - set(tokenizer.get_vocab().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(list(new_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp9zMv8j6Mio"
   },
   "source": [
    "Later on, for Word Alignment encoding we will be using these token values instead of real words to express relatedness of words in 2 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkMmAoB6zxVH",
    "outputId": "84ad6bad-0375-46b0-b6d4-6a66c9c604d9"
   },
   "outputs": [],
   "source": [
    "#! python -m spacy download zh_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "WNrn_RpB6Mio"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "en_pos_sp = spacy.load(\"en_core_web_sm\")\n",
    "zh_pos_sp = spacy.load('zh_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "If you are using one of the five T5 checkpoints that require a special prefix to put before the inputs, you should adapt the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "rK3wfeQw6Mio"
   },
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"translate English to Chinese: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJgVBneR6Mio"
   },
   "source": [
    "We can then write the function that will preprocess our samples. We just feed them to the `tokenizer` with the argument `truncation=True`. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9AHtsb96Mio"
   },
   "source": [
    "For PoS tags we will use a separate function that will parse the sentences and extract the PoS information from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "id": "4NEj0t4D6Mip"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get_pos_tags receives a tokenized input from the model. The tokenization is a bit different from spacy model,\n",
    "so to keep the same dimensions of vectors as in the sentence embeddings for each token in a sentence we will:\n",
    "- decode the token received from the model\n",
    "- get a Part of Speech id for it from Spacy and return it\n",
    "\"\"\"\n",
    "spacy_encoding = {\n",
    "    'ADJ': 0.3,\n",
    " 'ADP': 0.5,\n",
    " 'ADV': 0.4,\n",
    " 'AUX': 0.10,\n",
    " 'CCONJ': 0.11,\n",
    " 'DET': 0.6,\n",
    " 'INTJ': 0.12,\n",
    " 'NOUN': 0.1,\n",
    " 'NUM': 0.13,\n",
    " 'PART': 0.7,\n",
    " 'PRON': 0.8,\n",
    " 'PROPN': 0.9,\n",
    " 'PUNCT': 0.14,\n",
    " 'SCONJ': 0.15,\n",
    " 'SPACE': 0.16,\n",
    " 'SYM': 0.17,\n",
    " 'VERB': 0.2,\n",
    " 'X': 0.18,\n",
    "}\n",
    "\n",
    "jieba_spacy = {\n",
    "    'a': 'ADJ',\n",
    "    'ad': 'ADJ',\n",
    "    'an': 'ADJ',\n",
    "    'b': 'ADJ',\n",
    "    'c': 'CCONJ',\n",
    "    'd': 'ADV',\n",
    "    'df': 'ADV',\n",
    "    'dg': 'ADV',\n",
    "    'e': 'INTJ',\n",
    "    'f': 'ADP',\n",
    "    'g': 'NOUN',\n",
    "    'h': 'ADV',\n",
    "    'j': 'PROPN',\n",
    "    'k': 'PART',\n",
    "    'm': 'NUM',\n",
    "    'mg': 'NUM',\n",
    "    'mq': 'NOUN',\n",
    "    'n': 'NOUN',\n",
    "    'ng': 'NOUN',\n",
    "    'nr': 'PROPN',\n",
    "    'nrfg': 'PROPN',\n",
    "    'nrt': 'PROPN',\n",
    "    'ns': 'PROPN',\n",
    "    'nt': 'PROPN',\n",
    "    'nz': 'PROPN',\n",
    "    'o': 'NOUN',\n",
    "    'p': 'ADP',\n",
    "    'q': 'NOUN',\n",
    "    'r': 'PRON',\n",
    "    'rg': 'PRON',\n",
    "    'rr': 'PRON',\n",
    "    'rz': 'PRON',\n",
    "    's': 'NOUN',\n",
    "    't': 'NOUN',\n",
    "    'u': 'PART',\n",
    "    'ud': 'PART',\n",
    "    'ug': 'PART',\n",
    "    'uj': 'PART',\n",
    "    'ul': 'PART',\n",
    "    'uv': 'PART',\n",
    "    'uz': 'PART',\n",
    "    'v': 'VERB',\n",
    "    'vd': 'VERB',\n",
    "    'vg': 'VERB',\n",
    "    'vi': 'VERB',\n",
    "    'vn': 'VERB',\n",
    "    'vq': 'VERB',\n",
    "    'w': 'PUNCT',\n",
    "    'x': 'NOUN',\n",
    "    'y': 'INTJ',\n",
    "    'z': 'ADV',\n",
    "    'zg': 'PROPN'\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "Stop getting the POS on the fly\n",
    "def token_to_pos(token, lang):\n",
    "    if lang == 'en':\n",
    "        decoded = list(en_pos_sp(tokenizer.decode(token)))\n",
    "    elif lang == 'zh':\n",
    "        decoded = list(zh_pos_sp(tokenizer.decode(token)))\n",
    "    return decoded[-1].pos if decoded else -1\n",
    "\"\"\"\n",
    "\n",
    "def get_pos_tags(tokenized_sent, pos_tags_sent, lang):\n",
    "    n = len(tokenized_sent)\n",
    "    pos_embedding = [0] * n\n",
    "    \n",
    "    words_pos = pos_tags_sent.rstrip().split('\\n')\n",
    "    pos_tags = list(map(lambda x: x.split()[-1], words_pos))\n",
    "    m = len(pos_tags)\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "    while (i < n) and (j < m):\n",
    "        if lang == 'en':\n",
    "            if i < m: \n",
    "                break\n",
    "            pos_embedding[i] = spacy_encoding.get(pos_tags[i], 100)\n",
    "            \n",
    "        elif lang == 'zh':\n",
    "            if tokenized_sent[i] == 8:\n",
    "                spacy_tag = 'SPACE'\n",
    "            else:\n",
    "                spacy_tag = jieba_spacy.get(pos_tags[j], None)\n",
    "                if not spacy_tag:\n",
    "                    decoded_word = tokenizer.decode(tokenized_sent[i])\n",
    "                    spacy_tag = zh_pos_sp(decoded_word)[-1].pos_ if decoded_word else 'SPACE'\n",
    "                j += 1\n",
    "            pos_embedding[i] = spacy_encoding.get(spacy_tag, 100)\n",
    "        i += 1\n",
    "        \n",
    "    return pos_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnGXDRwd6Mip"
   },
   "source": [
    "Word Alignment information can be encoded in different ways:\n",
    "- Name: `trg-ids`. Create a vector of the same length as the tokenized input sentence. For each position i in the new vector, find a corresponding word in the original input sentence. Find a connected word from the target sentence and put its tokenized value in the new vector.\n",
    "- Name: `sums`. Create a copy of the input vector. For i-th word that has a connected word in the target sentence, add its value to the tokenized value to the i-th position of the new vector.\n",
    "- Name: `mult`. Same as sums but replaces sums with multiplication of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "if list(zh_pos_sp('')): print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "tafYVGb06Mip"
   },
   "outputs": [],
   "source": [
    "def encode_wa(tokenized_input, tokenized_target, wa, wa_type):\n",
    "    # Parse the WA string into a dictionary\n",
    "    wa_dict = {int(src): int(trg) for src, trg in map(lambda x: x.split('-'), wa.split())}\n",
    "    n = len(tokenized_input)\n",
    "    # As we have seen above, the Chinese tokenizer adds 8 for spaces which will remove for WA to work properly\n",
    "    filtered_target = list(filter(lambda x: x!=8, tokenized_target))\n",
    "    m = len(filtered_target)\n",
    "    if wa_type == 'trg-ids':\n",
    "        wa_emb = [0]*n\n",
    "        for k, v in wa_dict.items():\n",
    "            if k >= n or v >= m:\n",
    "                break\n",
    "            wa_emb[k] = filtered_target[v]\n",
    "        return wa_emb\n",
    "    elif wa_type == 'sums':\n",
    "        wa_emb = deepcopy(tokenized_input)\n",
    "        for k, v in wa_dict.items():\n",
    "            if k >= n or v >= m:\n",
    "                break\n",
    "            wa_emb[k] += filtered_target[v]\n",
    "        return wa_emb\n",
    "    \n",
    "    elif wa_type == 'mult':\n",
    "        wa_emb = deepcopy(tokenized_input)\n",
    "        for k, v in wa_dict.items():\n",
    "            if k >= n or v >= m:\n",
    "                break\n",
    "            wa_emb[k] *= filtered_target[v]\n",
    "        return wa_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "id": "vc0BSBLIIrJQ"
   },
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"en\"\n",
    "target_lang = \"zh\"\n",
    "pos_tags=False\n",
    "wa_type=None\n",
    "\n",
    "def preprocess_function(dataset):\n",
    "    global source_lang, target_lang, pos_tags, wa_type\n",
    "    inputs = [prefix + d[source_lang] for d in dataset[\"translation\"]]\n",
    "    targets = [d[target_lang] for d in dataset[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    if pos_tags:\n",
    "        model_inputs['pos'] = [get_pos_tags(x[0], x[1]['en'], 'en') for x in zip(model_inputs['input_ids'], dataset['pos'])]\n",
    "        model_inputs['target_pos'] = [get_pos_tags(y[0], y[1]['zh'], 'zh') for y in zip(model_inputs['labels'], dataset['pos'])]\n",
    "        \n",
    "    if wa_type:\n",
    "        model_inputs['wa'] = [encode_wa(src, trg, wa, wa_type) for src, trg, wa \\\n",
    "                              in zip(model_inputs['input_ids'],  model_inputs['labels'], dataset[\"wa\"])]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lm8ozrJIrJR"
   },
   "source": [
    "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS-6iXTkIrJT"
   },
   "source": [
    "To apply this function on all the pairs of sentences in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "xSA2364u6Mip"
   },
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def metric_fn(eval_predictions):\n",
    "    preds, labels = eval_predictions\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "    ]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # We use -100 to mask labels - replace it with the tokenizer pad token when decoding\n",
    "    # so that no output is emitted for these\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "uIqkIujg6Miq"
   },
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, AutoModelForMaskedLM, AutoModelForSeq2SeqLM\n",
    "from transformers import AdamWeightDecay\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## Fine-tuning the model with no extra tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "2aeb275a8ca14f42858e74ba42af6cb5",
      "12c4085c95a54102a9d79bba052d5a88",
      "286f168473df4744b41fe333ff06f5e9",
      "c06c5377e71348ceab4ff26b14dd3557",
      "1c9428203bcb44fbb306752e952caea8",
      "846d5fa7a3234831b6ba846aee21a91c",
      "c00b27a3745c459aae9e8a594665b572",
      "2c6148ea304b457cb33674d77cc59c20",
      "6b7664a7478f4d4a8d3680b9522ba48b",
      "f134d321d064438e85cb619e6986ab4b",
      "5638df0c4eab47faa3dea137e63e302f",
      "9c9a34cc8ee14c8e85c3d0a584ec2b5a",
      "94bbd725b159412fb7a28d861ca7dc51",
      "1df11a486b9a4780ab54ff267d6dafc3",
      "de993462f296433e938eed9c6fd397fe",
      "14457006742049e29de9e2f9dd4af415",
      "52e4234c6adb42f09fd24bd4eeee1a2d",
      "84a1e68713764068a1cf98a2cbbeb21b",
      "20054fae2d9f4e42bb16950b192b4280",
      "1625d5e0a9fc4f60913fa52c1c169c24",
      "5e12fd7723794148b373dba092aea7cd",
      "c6af1206fb0e4f0292a2584fcb87d030"
     ]
    },
    "id": "HAOl44Rh6Miq",
    "outputId": "d51f3f84-323c-429c-d79d-4524e0567413"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c37ba08d3f4f36abf5537d8ff4bc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5abd18ede2943b68d5ea300a558dfa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"en\"\n",
    "target_lang = \"zh\"\n",
    "pos_tags=False\n",
    "wa_tags = False\n",
    "wa_type = None\n",
    "\n",
    "split_dataset = loaded_dataset.remove_columns(['pos', 'wa'])\n",
    "no_anno_dataset = split_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120,
     "referenced_widgets": [
      "97232d895f1d43be90ee49446a790e9c",
      "4589337588fd46deb82448cb5cddd114",
      "44536a7805524265baf7bd3f9c857fa8",
      "fd4ae36b9f4b44bca4e51281b12347f3",
      "994899e2f5b740298b2d0852c7906914",
      "c684be315e9242b28213fd230c9de3ff",
      "2334406aa71d437093daf5c121b63af9",
      "f54c4a3f69db492383df94b59bdeadeb",
      "6c41570b336a4324840e6088d85d0a38",
      "b516939c6dfc4fde929473a552ff3b5f",
      "1f9602dec6a8455cb0f25d6283e3a8a4"
     ]
    },
    "id": "TlqNaB8jIrJW",
    "outputId": "a5dd0f32-bd63-4599-e163-fcb1ba02610b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at Helsinki-NLP/opus-mt-en-zh were not used when initializing TFMarianMTModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing TFMarianMTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFMarianMTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-zh.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.modeling_tf_utils.TFSharedEmbeddings at 0x7f98d427a100>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CczA5lJlIrJX"
   },
   "source": [
    "Note that  we don't get a warning like in our classification example. This means we used all the weights of the pretrained model and there is no randomly initialized head in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N8urzhyIrJY"
   },
   "source": [
    "Next we set some parameters like the learning rate and the `batch_size`and customize the weight decay. \n",
    "\n",
    "The last two arguments are to setup everything so we can push the model to the [Hub](https://huggingface.co/models) at the end of training. Remove the two of them if you didn't follow the installation steps at the top of the notebook, otherwise you can change the value of push_to_hub_model_id to something you would prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "Bliy8zgjIrJY"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "num_train_epochs = 1\n",
    "\n",
    "#model_name = model_checkpoint.split(\"/\")[-1]\n",
    "#push_to_hub_model_id = f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km3pGVdTIrJc"
   },
   "source": [
    "Then, we need a special kind of data collator, which will not only pad the inputs to the maximum length in the batch, but also the labels. Note that our data collators are multi-framework, so make sure you set `return_tensors='tf'` so you get `tf.Tensor` objects back and not something else!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "FzDrp8zl6Miq"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")\n",
    "\n",
    "generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\", pad_to_multiple_of=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2Td7Obf6Miq"
   },
   "source": [
    "Next, we convert our datasets to `tf.data.Dataset`, which Keras understands natively. There are two ways to do this - we can use the slightly more low-level [`Dataset.to_tf_dataset()`](https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.to_tf_dataset) method, or we can use [`Model.prepare_tf_dataset()`](https://huggingface.co/docs/transformers/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset). The main difference between these two is that the `Model` method can inspect the model to determine which column names it can use as input, which means you don't need to specify them yourself. Make sure to specify the collator we just created as our `collate_fn`!\n",
    "\n",
    "We also want to compute `BLEU` metrics, which will require us to generate text from our model. To speed things up, we can compile our generation loop with XLA. This results in a *huge* speedup - up to 100X! The downside of XLA generation, though, is that it doesn't like variable input shapes, because it needs to run a new compilation for each new input shape! To compensate for that, let's use `pad_to_multiple_of` for the dataset we use for text generation. This will reduce the number of unique input shapes a lot, meaning we can get the benefits of XLA generation with only a few compilations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "JDPe3SOe6Mir"
   },
   "outputs": [],
   "source": [
    "train_dataset = model.prepare_tf_dataset(\n",
    "    no_anno_dataset[\"train\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "validation_dataset = model.prepare_tf_dataset(\n",
    "    no_anno_dataset[\"test\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "generation_dataset = model.prepare_tf_dataset(\n",
    "    no_anno_dataset[\"test\"],\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=generation_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ss1W1ZMb6Mir"
   },
   "source": [
    "Now we initialize our loss and optimizer and compile the model. Note that most Transformers models compute loss internally, so we can just leave the loss argument blank to use the internal loss instead. For the optimizer, we can use the `AdamWeightDecay` optimizer in the Transformer library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U61xmR_d6Mir",
    "outputId": "d6513c62-46b8-483c-9670-d4de2f2ecd6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPxGZoDq6Mir"
   },
   "source": [
    "Now we can train our model. We can also add a few optional callbacks here, which you can remove if they aren't useful to you. In no particular order, these are:\n",
    "- PushToHubCallback will sync up our model with the Hub - this allows us to resume training from other machines, share the model after training is finished, and even test the model's inference quality midway through training!\n",
    "- TensorBoard is a built-in Keras callback that logs TensorBoard metrics.\n",
    "- KerasMetricCallback is a callback for computing advanced metrics. There are a number of common metrics in NLP like ROUGE which are hard to fit into your compiled training loop because they depend on decoding predictions and labels back to strings with the tokenizer, and calling arbitrary Python functions to compute the metric. The KerasMetricCallback will wrap a metric function, outputting metrics as training progresses.\n",
    "\n",
    "If this is the first time you've seen `KerasMetricCallback`, it's worth explaining what exactly is going on here. The callback takes two main arguments - a `metric_fn` and an `eval_dataset`. It then iterates over the `eval_dataset` and collects the model's outputs for each sample, before passing the `list` of predictions and the associated `list` of labels to the user-defined `metric_fn`. If the `predict_with_generate` argument is `True`, then it will call `model.generate()` for each input sample instead of `model.predict()` - this is useful for metrics that expect generated text from the model, like `ROUGE` and `BLEU`.\n",
    "\n",
    "This callback allows complex metrics to be computed each epoch that would not function as a standard Keras Metric. Metric values are printed each epoch, and can be used by other callbacks like `TensorBoard` or `EarlyStopping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "vrjzS7Xs6Mir"
   },
   "outputs": [],
   "source": [
    "metric_callback = KerasMetricCallback(\n",
    "    metric_fn=metric_fn, eval_dataset=generation_dataset, predict_with_generate=True, use_xla_generation=True, \n",
    "    generate_kwargs={\"max_length\": 128}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClP-5bOX6Mir"
   },
   "source": [
    "With the metric callback ready, now we can specify the other callbacks and fit our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtomiKCq6Mir",
    "outputId": "e3c9bb26-45a2-4aef-d1ce-8e52c6cd6da2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 1312s 13s/step - loss: 2.3934 - val_loss: 1.4680 - bleu: 21.6963 - gen_len: 22.4111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f98846ab490>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir=\"./translation_model_save/logs\")\n",
    "\n",
    "\"\"\"push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"./translation_model_save\",\n",
    "    tokenizer=tokenizer,\n",
    "    hub_model_id=push_to_hub_model_id,\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#callbacks = [metric_callback, tensorboard_callback, push_to_hub_callback]\n",
    "callbacks = [metric_callback]\n",
    "\n",
    "model.fit(\n",
    "    train_dataset, validation_data=validation_dataset, epochs=1, callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_vfizXc6Mir"
   },
   "source": [
    "## Running the model with PoS features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFK2FZWT6Mir"
   },
   "source": [
    "This cell can run pretty slow and can take 5-10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "393f9c7c91304cba8852591f362a8a6e",
      "31678423b14b49aebdc272486ee932f7",
      "68fa49d7de8e4324bb8aceb6d37467d7",
      "82d58697108546e697ef92413ecfeeab",
      "25fd87d2ed6a4d9e8cd08425b3b7c45c",
      "3cad5b2ae2df40f3afd14437ee69c072",
      "05d8367fa58a445cbcf860959d38f3e8",
      "8106395016d34529bd2ea946421fd266",
      "2061c2d630a34eba9870c21302be5016",
      "a8134e8f7af74efdb7ed9fc21670ce02",
      "0aafac33857a4c4ca7a6ee8abf32de8b"
     ]
    },
    "id": "2rpgdWmb6Mir",
    "outputId": "52eb9e3d-44fc-4b4b-cf44-85f598c78e79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at zh_split_dataset.hf/train/cache-e24140dfbcddc9e9.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at zh_split_dataset.hf/test/cache-4a57c33f6cc7b8cf.arrow\n"
     ]
    }
   ],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"en\"\n",
    "target_lang = \"zh\"\n",
    "# Pos_tags need to be set to True in the cell\n",
    "pos_tags = True\n",
    "wa_tags = False\n",
    "wa_type = None\n",
    "\n",
    "split_dataset = loaded_dataset.remove_columns(['wa'])\n",
    "pos_anno_dataset = split_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "id": "3xtFvoa76Mis",
    "outputId": "ac41b6d1-ddd2-47a1-8573-99dfd3ac55e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at Helsinki-NLP/opus-mt-en-zh were not used when initializing TFMarianMTModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing TFMarianMTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFMarianMTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-zh.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.modeling_tf_utils.TFSharedEmbeddings at 0x7f9548686700>"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_pos = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model_with_pos.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "id": "kgbQ4D_g6Mis"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "num_train_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "id": "62ZgYu3b6Mis"
   },
   "outputs": [],
   "source": [
    "data_collator_pos = DataCollatorForSeq2Seq(tokenizer, model=model_with_pos, return_tensors=\"tf\")\n",
    "\n",
    "generation_data_collator_pos = DataCollatorForSeq2Seq(tokenizer, model=model_with_pos, return_tensors=\"tf\", pad_to_multiple_of=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "id": "KxnaM7XQ6Mis"
   },
   "outputs": [],
   "source": [
    "train_dataset = model_with_pos.prepare_tf_dataset(\n",
    "    pos_anno_dataset[\"train\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator_pos,\n",
    ")\n",
    "\n",
    "validation_dataset = model_with_pos.prepare_tf_dataset(\n",
    "    pos_anno_dataset[\"test\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator_pos,\n",
    ")\n",
    "\n",
    "generation_dataset = model_with_pos.prepare_tf_dataset(\n",
    "    pos_anno_dataset[\"test\"],\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=generation_data_collator_pos,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "id": "2mpHlr7g6Mis",
    "outputId": "66c7aa64-3520-4776-e719-2756dfec0479"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\n",
    "model_with_pos.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "id": "qfcdF-4q6Mis"
   },
   "outputs": [],
   "source": [
    "metric_callback = KerasMetricCallback(\n",
    "    metric_fn=metric_fn, eval_dataset=generation_dataset, predict_with_generate=True, use_xla_generation=True, \n",
    "    generate_kwargs={\"max_length\": 128}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "id": "Yw-PixgQ6Mis",
    "outputId": "152bcd63-5edb-4382-d9ea-0477dfca551c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 1292s 12s/step - loss: 2.3859 - val_loss: 1.4937 - bleu: 21.5432 - gen_len: 22.7452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9739edfac0>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir=\"./translation_model_save/logs\")\n",
    "\n",
    "callbacks = [metric_callback]\n",
    "\n",
    "model_with_pos.fit(\n",
    "    train_dataset, validation_data=validation_dataset, epochs=1, callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec5ipdtX6Mis"
   },
   "source": [
    "## Running model with WA (vector with target ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "057f0b7f4f464e48ac08a16a2628ff4c",
      "f8234b401b7f4cb2bbd46ff6da4d43cf"
     ]
    },
    "id": "Dzw4jJb26Mis",
    "outputId": "c5214a4f-bb76-45df-bcca-f78262e09511"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a13d571670f4a2e83001395b898081e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d396ce97df4cecbba87cd829961c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"en\"\n",
    "target_lang = \"zh\"\n",
    "pos_tags = False\n",
    "wa_tags = True\n",
    "wa_type=\"trg-ids\"\n",
    "\n",
    "split_dataset = loaded_dataset.remove_columns(['pos'])\n",
    "wa_trg_id_dataset = split_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "id": "NCcKEPBK6Mit",
    "outputId": "8c39a763-d46e-4326-8df0-2ce1978a7534"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at Helsinki-NLP/opus-mt-en-zh were not used when initializing TFMarianMTModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing TFMarianMTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFMarianMTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-zh.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.modeling_tf_utils.TFSharedEmbeddings at 0x7f963579ccd0>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_wa_trg_ids = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model_with_wa_trg_ids.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "id": "ufChOSTN6Mit"
   },
   "outputs": [],
   "source": [
    "data_collator_wa_trg_ids = DataCollatorForSeq2Seq(tokenizer, model=model_with_wa_trg_ids, return_tensors=\"tf\")\n",
    "\n",
    "generation_data_collator_wa_trg_ids = DataCollatorForSeq2Seq(tokenizer, model=model_with_wa_trg_ids, return_tensors=\"tf\", pad_to_multiple_of=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "id": "YQBxecGl6Mit"
   },
   "outputs": [],
   "source": [
    "train_dataset = model_with_wa_trg_ids.prepare_tf_dataset(\n",
    "    wa_trg_id_dataset[\"train\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator_wa_trg_ids,\n",
    ")\n",
    "\n",
    "validation_dataset = model_with_wa_trg_ids.prepare_tf_dataset(\n",
    "    wa_trg_id_dataset[\"test\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=generation_data_collator_wa_trg_ids,\n",
    ")\n",
    "\n",
    "generation_dataset = model_with_wa_trg_ids.prepare_tf_dataset(\n",
    "    wa_trg_id_dataset[\"test\"],\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=generation_data_collator_wa_trg_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "id": "VG6eun2I6Mit",
    "outputId": "a1cd0433-ae50-41f9-d041-4ef6a51a6577"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\n",
    "model_with_wa_trg_ids.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "id": "gVrKMKMH6Mit"
   },
   "outputs": [],
   "source": [
    "metric_callback = KerasMetricCallback(\n",
    "    metric_fn=metric_fn, eval_dataset=generation_dataset, predict_with_generate=True, use_xla_generation=True, \n",
    "    generate_kwargs={\"max_length\": 128}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "id": "7WzXzrxa6Mit",
    "outputId": "89850c33-8b24-41b9-fb17-d0b075579a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 1351s 13s/step - loss: 2.4194 - val_loss: 1.5139 - bleu: 20.4420 - gen_len: 23.5553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9736943af0>"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir=\"./wa_trg_ids/logs\")\n",
    "\n",
    "callbacks = [metric_callback]\n",
    "\n",
    "model_with_wa_trg_ids.fit(\n",
    "    train_dataset, validation_data=validation_dataset, epochs=1, callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3RGtQov6Miv"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkRl3qq86Miv",
    "outputId": "94f5df45-cadb-4af8-d813-791b0e88249d"
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Annotation','BLEU'])\n",
    "results_list = [\n",
    "    ('No annotation', 21.9916),\n",
    "    ('Part of Speech', 22.4789),\n",
    "    ('Word alignment: target token ids', 31.5155)\n",
    "]\n",
    "results.append([{'Annotation': x[0], 'BLEU': x[1]} for x in results_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEL75VHb6Miv"
   },
   "source": [
    "## Translation with the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyHixsh06Miv"
   },
   "source": [
    "Now we've trained our model, let's see how we could load it and use it to translate text in future! First, let's load it from the hub. This means we can resume the code from here without needing to rerun everything above every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "575bOhS36Miv"
   },
   "source": [
    "Now let's try tokenizing some text and passing it to the model to generate a translation. Don't forget to add the \"translate: \" string at the start if you're using a `T5` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cAmlrDY6Miv"
   },
   "source": [
    "Well, that's some tokens and a lot of padding! Let's decode those to see what it says, using the `skip_special_tokens` argument to skip those padding tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "Hk5aeUsP6Miv",
    "outputId": "27e77b06-71a3-46de-b954-17ae6d16775d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 其实 不是 一个 非常 有 能力 的 罗马尼亚 演讲 但 让我们 尽 我们 的 最大 努力\n"
     ]
    }
   ],
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "vital = pd.read_csv(\"~/wikipedia/wiki/scrapping/ver2/articles_clean_ver2/en_only_fr.csv\", sep=\";\", encoding=\"iso-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     In Chinese painting, abstraction can be traced...\n",
       "1     While none of his paintings remain, this style...\n",
       "2     The Chan buddhist painter Liang Kai (??, c. 11...\n",
       "3     A late Song painter named Yu Jian, adept to Ti...\n",
       "4     When Turing was 39 years old in 1951, he turne...\n",
       "5     He was interested in morphogenesis, the develo...\n",
       "6     He suggested that a system of chemicals reacti...\n",
       "7     He used systems of partial differential equati...\n",
       "8     For example, if a catalyst A is required for a...\n",
       "9     Turing discovered that patterns could be creat...\n",
       "10    If A and B then diffused through the container...\n",
       "11    To calculate the extent of this, Turing would ...\n",
       "12    These calculations gave the right qualitative ...\n",
       "13    The Russian biochemist Boris Belousov had perf...\n",
       "14    Belousov was not aware of Turing's paper in th...\n",
       "15    Although published before the structure and ro...\n",
       "16    One of the early applications of Turing's pape...\n",
       "17    Further research in the area suggests that Tur...\n",
       "18                               In 2012, Sheth, et al.\n",
       "19    found that in mice, removal of Hox genes cause...\n",
       "20    Later papers were not available until Collecte...\n",
       "21    Within Humanistic Judaism, Talmud is studied a...\n",
       "22    One religious ceremony practiced in Gabon and ...\n",
       "23    In this state, depending upon the region, drum...\n",
       "24    When this trance-like state is witnessed and u...\n",
       "25    This builds skills at separating the feelings ...\n",
       "26    Such separation and subsequent contemplation o...\n",
       "27    In linguistics, articulatory phonetics is the ...\n",
       "28    Speech sounds are categorized by manner of art...\n",
       "29    Place of articulation refers to where in the n...\n",
       "30    Manner of articulation refers to the manner in...\n",
       "31    pulmonic, implosive, ejectives, and clicks), w...\n",
       "32    The concept is primarily used for the producti...\n",
       "33    For any place of articulation, there may be se...\n",
       "34    Normal human speech is pulmonic, produced with...\n",
       "35    However humans can pronounce words without the...\n",
       "36    Speech production is a complex activity, and a...\n",
       "Name: sentences, dtype: object"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vital['sentences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with no annotaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "for input_sentence in vital[\"sentences\"]:\n",
    "    tokenized_sentence = tokenizer([input_sentence], return_tensors='np')\n",
    "    out = model.generate(**tokenized_sentence, max_length=128)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        output_sentence = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "        print(output_sentence)\n",
    "        outputs.append(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vital[\"no_anno\"] = outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with POS tags (jieba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 中国 的 画 中, 抽象 可以 追溯 到 汤 时代 的 画 家 王 模 的 风格\n",
      "虽然 他 的 绘 画 都 没有 留下 了 但 这种 风格 在 一些 宋 时代 的 绘画 中 明显 可见\n",
      "Chan Buddhist 画家 梁凯 (?, c 1140 * 1210 ) 运用 了 这种 风格 来 绘制 他 的 “ 在 喷 墨 中 的 永恒 ” 其中 牺牲 了 准确 的 表述 来 增强 与 开 明 人 非 理性 的 思想 相联系 的 自 性\n",
      "一位 已故 的 画 画 人  看向 并 得 于 天 台 佛教 创建 了 一系列 被 喷 的 墨 景 最终 激发 许多 日本 锌 画 家\n",
      "当 1951 年 Turing 39 岁 时 他 转向 数学 生物学 最后 在 1 月 发表 他 的 杰作 《 产生 的 化学 基础 》\n",
      "他 对 生物 生物 的 形态 和 形状 的 发展 感兴趣\n",
      "他 提议 一个 化学 系统 互相 反应 并 在 整个 空间 传播 称为 一个 反应 扩散 系统 可能 代表 了 “ 产生 的 主要 现象 ”\n",
      "他 使用 部分 差异 等 系统 来 模拟 催 化 化学 反应\n",
      "例如 如果 某种 化学 反应 需要 一个 催化剂 A 进行 并且 如果 该 反应 产生 了 更多 的 催化剂 A 那么 我们 就 说 该 反应 是 自动 催化 的, 有 积极 的 反馈 可以 以 非 线 差异 公式 来 模拟\n",
      "Turing 发现 如果 化学 反应 不仅 产生 催化剂 A 并且 还 产生 抑制 剂 B 从而 减缓 A 的 生产\n",
      "如果 A 和 B 然后 以 不同 的 速度 在 集装箱 中 扩散 那么 你 可以 有 一些 A 统治 的 地区 和 一些 B 统治 的 地区\n",
      "为 计算 其 程度, 图 灵 需要 一个 强大 的 计算机 但 这些 计算机 在 1951 年 并 没有 如此 自由 的 可用 因此 他 不得不 使用 线 近 点 来 亲 手 解决 这些 方程式\n",
      "这些 计算 给出 了 正确 的 质量 结果 例如 产生 了 一个 统一 的 混合物 奇怪 地 经常 间隔 固定 的 红色 点\n",
      "俄罗斯 生物 化学 学家 Boris Belousov 曾 进行 类似 的 实验 但 无法 发表 他 的 论文 因为 当代 的 偏见 任何 这种 东西 都 违反 了 热 动力 的 第二项 法律\n",
      "Belousov 并不知道 Turing 在 皇家 协会 哲学 交易 中 的 论文\n",
      "尽管 在 DNA 的 结构 和 作用 被 理解 之前 已经 公布 了  图 灵 关于 摩 的 工作 今天 仍然 重要 并且 被视为 数学 生物学 的 重要 作品\n",
      "图 灵 论文 的 早期 应用 之一 是 詹姆斯 默 的 著作 写 在 猫 的 皮 上 的 斑点 和 条状\n",
      "这个 领域 的 进一步 研究 表明 图 灵 的 工作 可以 部分 排除 了 心脏 的 生长 和 头发 的 增长 以及 肺 的 支 出 模式 甚至 将 心脏 放在 胸部 的 左 侧 的 左右 不对称\n",
      "2012 年 谢 等人\n",
      "在 老鼠 中 发现 移 了 赫 克斯 基因 导致 数字 数量 增加 而 没有 增加 肢体 的 整体 大小 表明 霍 克斯 基因 通过 调 Turing 型 机制 的 波 长度 来 控制 数字 形成\n",
      "后来 的 论文 直到 1992 年 公布 了 收集 的 图 灵 工程\n",
      "在 人类 犹太 内部 被 研究 成 一个 历史 文字 来 发现 它 如何 展示 与 今日 生活 的 实际 关联\n",
      "在 加蓬 和 喀麦隆 举行 的 一个 宗教 仪式 是 由 几个 班图 民族 进行 的 奥 圭\n",
      "在 这个 州, 取决于 区域 的 区域, 由 受 尊重 的 音乐 人 所 发挥 的 鼓 或 工具 节奏 ( 每个 音乐 人 都 是 被 授予 的 神 或 祖先 所 独 有 的 ) 参与者 通过 进行 不同 的 仪式 运动 或 舞蹈 来 进一步 增强 他们 的 意识 体现 了 一种 神圣 的 或 祖先 的 能量 或 思想 状态\n",
      "当 这 类似 的 国家 被 见证 和 理解 时, 追随 者 也 具有 一种 思考 一种 方式 的 简单 或 象征性 的 体现 一种 特定 的 思想 或 参照 框架\n",
      "这 建立 了 技能 将 这种 思想 所 激发 的 情感 与 他们 在 日常生活 中 的 情景 表现 分离\n",
      "这种 分离 和 随后 对 纯 能源 或 情感 的 性质 和 来源 的 思考 有助于 参与者 在 常见 的 环境 中 管理和 接受 它们\n",
      "在 语言 上, 脉 音 是 研究 舌 、 嘴 、 下 牙 、 声 带 和其他 语言 器官 如何 用于 制造 声音\n",
      "声音 按 表达 方式 和 表达 地点 分类\n",
      "表达 的 地点 指 在 颈 或 口 中 空气 流 被 压缩 的 地方\n",
      "表达 方式 指 语言 器官 互动 的 方式, 如 空气 如何 受 限制, 使用 了 何种 形式 的 空气 ( 例如 空气 流 )\n",
      "脉 性 性 性 性 性 性 和 点击 的 性 性 性 的 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性 性\n",
      "这个 概念 主要 用于 制作 合成 材料 但 可以 用于 音 和 鼻 音 等 品质 的 元\n",
      "对于 任何 的 表达 地 可能 有 几种 表达 方式 因此 有 几种 神圣 的 声音\n",
      "正常 的 人类 语言 是 肺 的 压力 产生 了 硫 酸 的 声音 并 被 声音 和 口 改变 成 不同 的 元 和 调\n",
      "然而 人类 可以 在 耶路撒冷 的 演讲 中 不 使用 肺 和 glottis 其中 有 三种 类型 的 演讲 : 食 语 演讲 、 法 利亚 演讲 和 Buccal 演讲 ( 更 称 Donald Duck 演讲 )\n",
      "语言 制作 是 一项 复杂 的 活动, 因此 特别 在 儿童 中 也 是 常见 的\n"
     ]
    }
   ],
   "source": [
    "outputs_pos = []\n",
    "\n",
    "for input_sentence in vital[\"sentences\"]:\n",
    "    tokenized_sentence = tokenizer([input_sentence], return_tensors='np')\n",
    "    out = model_with_pos.generate(**tokenized_sentence, max_length=128)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        output_sentence = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "        print(output_sentence)\n",
    "        outputs_pos.append(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "vital[\"pos_anno\"] = outputs_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>sentences</th>\n",
       "      <th>no_anno</th>\n",
       "      <th>pos_anno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstract art</td>\n",
       "      <td>In Chinese painting, abstraction can be traced...</td>\n",
       "      <td>在 中国 的 画 中 抽象 可以 追溯 到 唐 时代 的 画 人 王 模 (? ) 他 被 ...</td>\n",
       "      <td>在 中国 的 画 中, 抽象 可以 追溯 到 汤 时代 的 画 家 王 模 的 风格</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract art</td>\n",
       "      <td>While none of his paintings remain, this style...</td>\n",
       "      <td>虽然 他 的 绘 画 都 没有 留下 但 这种 风格 在 一些 宋 时代 的 绘画 中 明显 可见</td>\n",
       "      <td>虽然 他 的 绘 画 都 没有 留下 了 但 这种 风格 在 一些 宋 时代 的 绘画 中 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract art</td>\n",
       "      <td>The Chan buddhist painter Liang Kai (??, c. 11...</td>\n",
       "      <td>Chan buddist 画家 Liang Kai (?, c 1140 * 1210 ) ...</td>\n",
       "      <td>Chan Buddhist 画家 梁凯 (?, c 1140 * 1210 ) 运用 了 这...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract art</td>\n",
       "      <td>A late Song painter named Yu Jian, adept to Ti...</td>\n",
       "      <td>一位 已故 的 画 画 名为 于 建 的 专家 于 天 台 孟加拉 创建 了 一系列 被 喷...</td>\n",
       "      <td>一位 已故 的 画 画 人  看向 并 得 于 天 台 佛教 创建 了 一系列 被 喷 的 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>When Turing was 39 years old in 1951, he turne...</td>\n",
       "      <td>当 1951 年 Turing 年 39 岁 时 他 转向 数学 生物学 最后 在 年 1 ...</td>\n",
       "      <td>当 1951 年 Turing 39 岁 时 他 转向 数学 生物学 最后 在 1 月 发表...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>He was interested in morphogenesis, the develo...</td>\n",
       "      <td>他 对 生物 生物 生物 的 形态 和 形状 的 发展 感兴趣</td>\n",
       "      <td>他 对 生物 生物 的 形态 和 形状 的 发展 感兴趣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>He suggested that a system of chemicals reacti...</td>\n",
       "      <td>他 提出 一个 化学 系统 互相 反应 并 扩散 整个 空间 被 称为 一个 反应 扩散 系...</td>\n",
       "      <td>他 提议 一个 化学 系统 互相 反应 并 在 整个 空间 传播 称为 一个 反应 扩散 系...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>He used systems of partial differential equati...</td>\n",
       "      <td>他 使用 部分 差异 等 系统 来 模拟 催 化 化学 反应</td>\n",
       "      <td>他 使用 部分 差异 等 系统 来 模拟 催 化 化学 反应</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>For example, if a catalyst A is required for a...</td>\n",
       "      <td>例如 如果 某种 化学 反应 需要 一个 催化剂 A 而 如果 该 反应 产生 了 更多 的...</td>\n",
       "      <td>例如 如果 某种 化学 反应 需要 一个 催化剂 A 进行 并且 如果 该 反应 产生 了 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>Turing discovered that patterns could be creat...</td>\n",
       "      <td>Turing 发现 如果 化学 反应 不仅 产生 了 催化剂 A 并且 也 产生 了 抑制 ...</td>\n",
       "      <td>Turing 发现 如果 化学 反应 不仅 产生 催化剂 A 并且 还 产生 抑制 剂 B ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>If A and B then diffused through the container...</td>\n",
       "      <td>如果 A 和 B 然后 以 不同 的 速度 在 容器 中 扩散 那么 你 可以 有 一些 A...</td>\n",
       "      <td>如果 A 和 B 然后 以 不同 的 速度 在 集装箱 中 扩散 那么 你 可以 有 一些 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>To calculate the extent of this, Turing would ...</td>\n",
       "      <td>为 计算 这个 程度 的 程度, 图 灵 需要 一个 强大 的 计算机 但 这些 计算机 在...</td>\n",
       "      <td>为 计算 其 程度, 图 灵 需要 一个 强大 的 计算机 但 这些 计算机 在 1951 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>These calculations gave the right qualitative ...</td>\n",
       "      <td>这些 计算 给出 了 正确 的 质量 结果 并 产生 例如 一种 统一 的 混合物 奇怪 地...</td>\n",
       "      <td>这些 计算 给出 了 正确 的 质量 结果 例如 产生 了 一个 统一 的 混合物 奇怪 地...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>The Russian biochemist Boris Belousov had perf...</td>\n",
       "      <td>俄罗斯 生物 化学 学家 Boris Belousov 已经 进行 了 类似 的 实验 但 ...</td>\n",
       "      <td>俄罗斯 生物 化学 学家 Boris Belousov 曾 进行 类似 的 实验 但 无法 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>Belousov was not aware of Turing's paper in th...</td>\n",
       "      <td>Belousov 并不知道 Turing 在 皇家 协会 的 哲学 交易 中 的 论文</td>\n",
       "      <td>Belousov 并不知道 Turing 在 皇家 协会 哲学 交易 中 的 论文</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>Although published before the structure and ro...</td>\n",
       "      <td>尽管 在 DNA 的 结构 和 作用 被 理解 之前 已经 公布 了  图 灵 关于 形态 ...</td>\n",
       "      <td>尽管 在 DNA 的 结构 和 作用 被 理解 之前 已经 公布 了  图 灵 关于 摩 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>One of the early applications of Turing's pape...</td>\n",
       "      <td>图 灵 论文 的 早期 应用 之一 是 詹姆斯 默 的 作品 包括 大型 和 小型 猫 的 ...</td>\n",
       "      <td>图 灵 论文 的 早期 应用 之一 是 詹姆斯 默 的 著作 写 在 猫 的 皮 上 的 斑...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>Further research in the area suggests that Tur...</td>\n",
       "      <td>这个 领域 的 进一步 研究 表明 图 灵 的 工作 可以 部分 延 于 1978 年 的 ...</td>\n",
       "      <td>这个 领域 的 进一步 研究 表明 图 灵 的 工作 可以 部分 排除 了 心脏 的 生长 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>In 2012, Sheth, et al.</td>\n",
       "      <td>2012 年 谢 等人</td>\n",
       "      <td>2012 年 谢 等人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>found that in mice, removal of Hox genes cause...</td>\n",
       "      <td>在 老鼠 中 发现 移 了 赫 克斯 基因 导致 数字 数量 增加 而 没有 增加 肢体 的...</td>\n",
       "      <td>在 老鼠 中 发现 移 了 赫 克斯 基因 导致 数字 数量 增加 而 没有 增加 肢体 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>Later papers were not available until Collecte...</td>\n",
       "      <td>后来 的 论文 直到 1992 年 公布 了 收集 的 图 灵 工程</td>\n",
       "      <td>后来 的 论文 直到 1992 年 公布 了 收集 的 图 灵 工程</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Talmud</td>\n",
       "      <td>Within Humanistic Judaism, Talmud is studied a...</td>\n",
       "      <td>在 人类 犹太 内部 被 研究 成 一个 历史 的 文字 来 发现 它 如何 显示 与 今天...</td>\n",
       "      <td>在 人类 犹太 内部 被 研究 成 一个 历史 文字 来 发现 它 如何 展示 与 今日 生...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Traditional African religions</td>\n",
       "      <td>One religious ceremony practiced in Gabon and ...</td>\n",
       "      <td>在 加蓬 和 喀麦隆 举行 的 一个 宗教 仪式 是 由 一些 班图 民族 进行 的 Okuyi</td>\n",
       "      <td>在 加蓬 和 喀麦隆 举行 的 一个 宗教 仪式 是 由 几个 班图 民族 进行 的 奥 圭</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Traditional African religions</td>\n",
       "      <td>In this state, depending upon the region, drum...</td>\n",
       "      <td>在 这种 状态 中, 取决于 区域 的 区域, 受到 尊重 的 音乐 们 所 演奏 的 鼓 ...</td>\n",
       "      <td>在 这个 州, 取决于 区域 的 区域, 由 受 尊重 的 音乐 人 所 发挥 的 鼓 或 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Traditional African religions</td>\n",
       "      <td>When this trance-like state is witnessed and u...</td>\n",
       "      <td>当 这种 类似 的 国家 被 见证 和 理解 时, 信徒 也 被 了解 一种 方式 来 思考...</td>\n",
       "      <td>当 这 类似 的 国家 被 见证 和 理解 时, 追随 者 也 具有 一种 思考 一种 方式...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Traditional African religions</td>\n",
       "      <td>This builds skills at separating the feelings ...</td>\n",
       "      <td>这 建立 了 技能 将 这种 思想 所 激发 的 情感 与 他们 在 日常生活 中 的 情景...</td>\n",
       "      <td>这 建立 了 技能 将 这种 思想 所 激发 的 情感 与 他们 在 日常生活 中 的 情景...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Traditional African religions</td>\n",
       "      <td>Such separation and subsequent contemplation o...</td>\n",
       "      <td>这种 分离 和 随后 对 纯 能源 或 情感 的 性质 和 来源 的 思考 有助于 参与者 ...</td>\n",
       "      <td>这种 分离 和 随后 对 纯 能源 或 情感 的 性质 和 来源 的 思考 有助于 参与者 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Speech</td>\n",
       "      <td>In linguistics, articulatory phonetics is the ...</td>\n",
       "      <td>在 语言 上, 动 语 是 研究 舌 、 嘴 、 下 牙 、 声 带 和其他 语言 器官 如...</td>\n",
       "      <td>在 语言 上, 脉 音 是 研究 舌 、 嘴 、 下 牙 、 声 带 和其他 语言 器官 如...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Speech</td>\n",
       "      <td>Speech sounds are categorized by manner of art...</td>\n",
       "      <td>声音 按 表达 方式 和 表达 地点 分类</td>\n",
       "      <td>声音 按 表达 方式 和 表达 地点 分类</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Speech</td>\n",
       "      <td>Place of articulation refers to where in the n...</td>\n",
       "      <td>连接 的 地点 指 在 颈 或 口 中 空气 流 被 压缩 的 地方</td>\n",
       "      <td>表达 的 地点 指 在 颈 或 口 中 空气 流 被 压缩 的 地方</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Speech</td>\n",
       "      <td>Manner of articulation refers to the manner in...</td>\n",
       "      <td>表达 方式 指 语言 器官 互动 的 方式 例如 空气 被 限制 的 程度 以及 使用 的 ...</td>\n",
       "      <td>表达 方式 指 语言 器官 互动 的 方式, 如 空气 如何 受 限制, 使用 了 何种 形...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Speech</td>\n",
       "      <td>pulmonic, implosive, ejectives, and clicks), w...</td>\n",
       "      <td>脉 性 性 性 性 性 性 和 点击 的 性 性 性 的 性 性 性 性 性 性 性 性 性...</td>\n",
       "      <td>脉 性 性 性 性 性 性 和 点击 的 性 性 性 的 性 性 性 性 性 性 性 性 性...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Speech</td>\n",
       "      <td>The concept is primarily used for the producti...</td>\n",
       "      <td>这个 概念 主要 用于 制作 合成, 但 可以 用于 音 的 音, 如 发票 和 鼻 化</td>\n",
       "      <td>这个 概念 主要 用于 制作 合成 材料 但 可以 用于 音 和 鼻 音 等 品质 的 元</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Speech</td>\n",
       "      <td>For any place of articulation, there may be se...</td>\n",
       "      <td>对于 任何 的 表达 地 可能 有 几种 表达 方式 因此 有 几种 有机 的 声音</td>\n",
       "      <td>对于 任何 的 表达 地 可能 有 几种 表达 方式 因此 有 几种 神圣 的 声音</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Speech</td>\n",
       "      <td>Normal human speech is pulmonic, produced with...</td>\n",
       "      <td>正常 的 人类 语言 是 肺 的 压力 产生 了 硫 酸 在 喉 的 凝 石 中 产生 了 ...</td>\n",
       "      <td>正常 的 人类 语言 是 肺 的 压力 产生 了 硫 酸 的 声音 并 被 声音 和 口 改...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Speech</td>\n",
       "      <td>However humans can pronounce words without the...</td>\n",
       "      <td>然而 人类 可以 在 犹太 语 中 不 使用 肺 和 glottis 的 语言 其中 有 三...</td>\n",
       "      <td>然而 人类 可以 在 耶路撒冷 的 演讲 中 不 使用 肺 和 glottis 其中 有 三...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Speech</td>\n",
       "      <td>Speech production is a complex activity, and a...</td>\n",
       "      <td>语音 制作 是 一项 复杂 的 活动, 结果 是 常见 的, 在 儿童 中 尤为 常见</td>\n",
       "      <td>语言 制作 是 一项 复杂 的 活动, 因此 特别 在 儿童 中 也 是 常见 的</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          article  \\\n",
       "0                    Abstract art   \n",
       "1                    Abstract art   \n",
       "2                    Abstract art   \n",
       "3                    Abstract art   \n",
       "4                     Alan Turing   \n",
       "5                     Alan Turing   \n",
       "6                     Alan Turing   \n",
       "7                     Alan Turing   \n",
       "8                     Alan Turing   \n",
       "9                     Alan Turing   \n",
       "10                    Alan Turing   \n",
       "11                    Alan Turing   \n",
       "12                    Alan Turing   \n",
       "13                    Alan Turing   \n",
       "14                    Alan Turing   \n",
       "15                    Alan Turing   \n",
       "16                    Alan Turing   \n",
       "17                    Alan Turing   \n",
       "18                    Alan Turing   \n",
       "19                    Alan Turing   \n",
       "20                    Alan Turing   \n",
       "21                         Talmud   \n",
       "22  Traditional African religions   \n",
       "23  Traditional African religions   \n",
       "24  Traditional African religions   \n",
       "25  Traditional African religions   \n",
       "26  Traditional African religions   \n",
       "27                         Speech   \n",
       "28                         Speech   \n",
       "29                         Speech   \n",
       "30                         Speech   \n",
       "31                         Speech   \n",
       "32                         Speech   \n",
       "33                         Speech   \n",
       "34                         Speech   \n",
       "35                         Speech   \n",
       "36                         Speech   \n",
       "\n",
       "                                            sentences  \\\n",
       "0   In Chinese painting, abstraction can be traced...   \n",
       "1   While none of his paintings remain, this style...   \n",
       "2   The Chan buddhist painter Liang Kai (??, c. 11...   \n",
       "3   A late Song painter named Yu Jian, adept to Ti...   \n",
       "4   When Turing was 39 years old in 1951, he turne...   \n",
       "5   He was interested in morphogenesis, the develo...   \n",
       "6   He suggested that a system of chemicals reacti...   \n",
       "7   He used systems of partial differential equati...   \n",
       "8   For example, if a catalyst A is required for a...   \n",
       "9   Turing discovered that patterns could be creat...   \n",
       "10  If A and B then diffused through the container...   \n",
       "11  To calculate the extent of this, Turing would ...   \n",
       "12  These calculations gave the right qualitative ...   \n",
       "13  The Russian biochemist Boris Belousov had perf...   \n",
       "14  Belousov was not aware of Turing's paper in th...   \n",
       "15  Although published before the structure and ro...   \n",
       "16  One of the early applications of Turing's pape...   \n",
       "17  Further research in the area suggests that Tur...   \n",
       "18                             In 2012, Sheth, et al.   \n",
       "19  found that in mice, removal of Hox genes cause...   \n",
       "20  Later papers were not available until Collecte...   \n",
       "21  Within Humanistic Judaism, Talmud is studied a...   \n",
       "22  One religious ceremony practiced in Gabon and ...   \n",
       "23  In this state, depending upon the region, drum...   \n",
       "24  When this trance-like state is witnessed and u...   \n",
       "25  This builds skills at separating the feelings ...   \n",
       "26  Such separation and subsequent contemplation o...   \n",
       "27  In linguistics, articulatory phonetics is the ...   \n",
       "28  Speech sounds are categorized by manner of art...   \n",
       "29  Place of articulation refers to where in the n...   \n",
       "30  Manner of articulation refers to the manner in...   \n",
       "31  pulmonic, implosive, ejectives, and clicks), w...   \n",
       "32  The concept is primarily used for the producti...   \n",
       "33  For any place of articulation, there may be se...   \n",
       "34  Normal human speech is pulmonic, produced with...   \n",
       "35  However humans can pronounce words without the...   \n",
       "36  Speech production is a complex activity, and a...   \n",
       "\n",
       "                                              no_anno  \\\n",
       "0   在 中国 的 画 中 抽象 可以 追溯 到 唐 时代 的 画 人 王 模 (? ) 他 被 ...   \n",
       "1   虽然 他 的 绘 画 都 没有 留下 但 这种 风格 在 一些 宋 时代 的 绘画 中 明显 可见   \n",
       "2   Chan buddist 画家 Liang Kai (?, c 1140 * 1210 ) ...   \n",
       "3   一位 已故 的 画 画 名为 于 建 的 专家 于 天 台 孟加拉 创建 了 一系列 被 喷...   \n",
       "4   当 1951 年 Turing 年 39 岁 时 他 转向 数学 生物学 最后 在 年 1 ...   \n",
       "5                     他 对 生物 生物 生物 的 形态 和 形状 的 发展 感兴趣   \n",
       "6   他 提出 一个 化学 系统 互相 反应 并 扩散 整个 空间 被 称为 一个 反应 扩散 系...   \n",
       "7                      他 使用 部分 差异 等 系统 来 模拟 催 化 化学 反应   \n",
       "8   例如 如果 某种 化学 反应 需要 一个 催化剂 A 而 如果 该 反应 产生 了 更多 的...   \n",
       "9   Turing 发现 如果 化学 反应 不仅 产生 了 催化剂 A 并且 也 产生 了 抑制 ...   \n",
       "10  如果 A 和 B 然后 以 不同 的 速度 在 容器 中 扩散 那么 你 可以 有 一些 A...   \n",
       "11  为 计算 这个 程度 的 程度, 图 灵 需要 一个 强大 的 计算机 但 这些 计算机 在...   \n",
       "12  这些 计算 给出 了 正确 的 质量 结果 并 产生 例如 一种 统一 的 混合物 奇怪 地...   \n",
       "13  俄罗斯 生物 化学 学家 Boris Belousov 已经 进行 了 类似 的 实验 但 ...   \n",
       "14        Belousov 并不知道 Turing 在 皇家 协会 的 哲学 交易 中 的 论文   \n",
       "15  尽管 在 DNA 的 结构 和 作用 被 理解 之前 已经 公布 了  图 灵 关于 形态 ...   \n",
       "16  图 灵 论文 的 早期 应用 之一 是 詹姆斯 默 的 作品 包括 大型 和 小型 猫 的 ...   \n",
       "17  这个 领域 的 进一步 研究 表明 图 灵 的 工作 可以 部分 延 于 1978 年 的 ...   \n",
       "18                                        2012 年 谢 等人   \n",
       "19  在 老鼠 中 发现 移 了 赫 克斯 基因 导致 数字 数量 增加 而 没有 增加 肢体 的...   \n",
       "20                 后来 的 论文 直到 1992 年 公布 了 收集 的 图 灵 工程   \n",
       "21  在 人类 犹太 内部 被 研究 成 一个 历史 的 文字 来 发现 它 如何 显示 与 今天...   \n",
       "22   在 加蓬 和 喀麦隆 举行 的 一个 宗教 仪式 是 由 一些 班图 民族 进行 的 Okuyi   \n",
       "23  在 这种 状态 中, 取决于 区域 的 区域, 受到 尊重 的 音乐 们 所 演奏 的 鼓 ...   \n",
       "24  当 这种 类似 的 国家 被 见证 和 理解 时, 信徒 也 被 了解 一种 方式 来 思考...   \n",
       "25  这 建立 了 技能 将 这种 思想 所 激发 的 情感 与 他们 在 日常生活 中 的 情景...   \n",
       "26  这种 分离 和 随后 对 纯 能源 或 情感 的 性质 和 来源 的 思考 有助于 参与者 ...   \n",
       "27  在 语言 上, 动 语 是 研究 舌 、 嘴 、 下 牙 、 声 带 和其他 语言 器官 如...   \n",
       "28                              声音 按 表达 方式 和 表达 地点 分类   \n",
       "29                 连接 的 地点 指 在 颈 或 口 中 空气 流 被 压缩 的 地方   \n",
       "30  表达 方式 指 语言 器官 互动 的 方式 例如 空气 被 限制 的 程度 以及 使用 的 ...   \n",
       "31  脉 性 性 性 性 性 性 和 点击 的 性 性 性 的 性 性 性 性 性 性 性 性 性...   \n",
       "32       这个 概念 主要 用于 制作 合成, 但 可以 用于 音 的 音, 如 发票 和 鼻 化   \n",
       "33         对于 任何 的 表达 地 可能 有 几种 表达 方式 因此 有 几种 有机 的 声音   \n",
       "34  正常 的 人类 语言 是 肺 的 压力 产生 了 硫 酸 在 喉 的 凝 石 中 产生 了 ...   \n",
       "35  然而 人类 可以 在 犹太 语 中 不 使用 肺 和 glottis 的 语言 其中 有 三...   \n",
       "36        语音 制作 是 一项 复杂 的 活动, 结果 是 常见 的, 在 儿童 中 尤为 常见   \n",
       "\n",
       "                                             pos_anno  \n",
       "0          在 中国 的 画 中, 抽象 可以 追溯 到 汤 时代 的 画 家 王 模 的 风格  \n",
       "1   虽然 他 的 绘 画 都 没有 留下 了 但 这种 风格 在 一些 宋 时代 的 绘画 中 ...  \n",
       "2   Chan Buddhist 画家 梁凯 (?, c 1140 * 1210 ) 运用 了 这...  \n",
       "3   一位 已故 的 画 画 人  看向 并 得 于 天 台 佛教 创建 了 一系列 被 喷 的 ...  \n",
       "4   当 1951 年 Turing 39 岁 时 他 转向 数学 生物学 最后 在 1 月 发表...  \n",
       "5                        他 对 生物 生物 的 形态 和 形状 的 发展 感兴趣  \n",
       "6   他 提议 一个 化学 系统 互相 反应 并 在 整个 空间 传播 称为 一个 反应 扩散 系...  \n",
       "7                      他 使用 部分 差异 等 系统 来 模拟 催 化 化学 反应  \n",
       "8   例如 如果 某种 化学 反应 需要 一个 催化剂 A 进行 并且 如果 该 反应 产生 了 ...  \n",
       "9   Turing 发现 如果 化学 反应 不仅 产生 催化剂 A 并且 还 产生 抑制 剂 B ...  \n",
       "10  如果 A 和 B 然后 以 不同 的 速度 在 集装箱 中 扩散 那么 你 可以 有 一些 ...  \n",
       "11  为 计算 其 程度, 图 灵 需要 一个 强大 的 计算机 但 这些 计算机 在 1951 ...  \n",
       "12  这些 计算 给出 了 正确 的 质量 结果 例如 产生 了 一个 统一 的 混合物 奇怪 地...  \n",
       "13  俄罗斯 生物 化学 学家 Boris Belousov 曾 进行 类似 的 实验 但 无法 ...  \n",
       "14          Belousov 并不知道 Turing 在 皇家 协会 哲学 交易 中 的 论文  \n",
       "15  尽管 在 DNA 的 结构 和 作用 被 理解 之前 已经 公布 了  图 灵 关于 摩 的...  \n",
       "16  图 灵 论文 的 早期 应用 之一 是 詹姆斯 默 的 著作 写 在 猫 的 皮 上 的 斑...  \n",
       "17  这个 领域 的 进一步 研究 表明 图 灵 的 工作 可以 部分 排除 了 心脏 的 生长 ...  \n",
       "18                                        2012 年 谢 等人  \n",
       "19  在 老鼠 中 发现 移 了 赫 克斯 基因 导致 数字 数量 增加 而 没有 增加 肢体 的...  \n",
       "20                 后来 的 论文 直到 1992 年 公布 了 收集 的 图 灵 工程  \n",
       "21  在 人类 犹太 内部 被 研究 成 一个 历史 文字 来 发现 它 如何 展示 与 今日 生...  \n",
       "22     在 加蓬 和 喀麦隆 举行 的 一个 宗教 仪式 是 由 几个 班图 民族 进行 的 奥 圭  \n",
       "23  在 这个 州, 取决于 区域 的 区域, 由 受 尊重 的 音乐 人 所 发挥 的 鼓 或 ...  \n",
       "24  当 这 类似 的 国家 被 见证 和 理解 时, 追随 者 也 具有 一种 思考 一种 方式...  \n",
       "25  这 建立 了 技能 将 这种 思想 所 激发 的 情感 与 他们 在 日常生活 中 的 情景...  \n",
       "26  这种 分离 和 随后 对 纯 能源 或 情感 的 性质 和 来源 的 思考 有助于 参与者 ...  \n",
       "27  在 语言 上, 脉 音 是 研究 舌 、 嘴 、 下 牙 、 声 带 和其他 语言 器官 如...  \n",
       "28                              声音 按 表达 方式 和 表达 地点 分类  \n",
       "29                 表达 的 地点 指 在 颈 或 口 中 空气 流 被 压缩 的 地方  \n",
       "30  表达 方式 指 语言 器官 互动 的 方式, 如 空气 如何 受 限制, 使用 了 何种 形...  \n",
       "31  脉 性 性 性 性 性 性 和 点击 的 性 性 性 的 性 性 性 性 性 性 性 性 性...  \n",
       "32      这个 概念 主要 用于 制作 合成 材料 但 可以 用于 音 和 鼻 音 等 品质 的 元  \n",
       "33         对于 任何 的 表达 地 可能 有 几种 表达 方式 因此 有 几种 神圣 的 声音  \n",
       "34  正常 的 人类 语言 是 肺 的 压力 产生 了 硫 酸 的 声音 并 被 声音 和 口 改...  \n",
       "35  然而 人类 可以 在 耶路撒冷 的 演讲 中 不 使用 肺 和 glottis 其中 有 三...  \n",
       "36          语言 制作 是 一项 复杂 的 活动, 因此 特别 在 儿童 中 也 是 常见 的  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with WA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 中国 的 画 中 的 抽象 可以 追溯 到 唐 的 画 人 Wang Mo (? ) 的 发明 了 被 认为 是 发明 了 被 喷 的 墨 的 风格\n",
      "虽然 他 的 作品 没有 留下 但 这种 风格 在 一些 宋 时代 的 绘画 中 明显 可见\n",
      "Chan buddist 画家 Liang Kai (?, c 1140 * 1210 ) 运用 了 这种 风格 来 绘制 他 的 “ 在 喷 墨 中 的 永恒 ” 其中 牺牲 了 准确 的 表述 来 增强 与 开 人 非 理性 的 思想 相联系 的 自 性\n",
      "一个 已故 的 画 人  beating 于 车站 并 得 于 天 台 佛教 并 创建 了 一系列 的 喷 墨 景观 最终 激励 许多 日本 犹太人 的 画\n",
      "当 图 灵 在 1951 年 39 岁 时 他 转向 数学 生物学 最后 在 1 年 1 月 12 月 发表 他 的 杰作 《 产生 的 化学 基础 》\n",
      "他 对 生物 生物 的 形态 和 形状 的 发展 感兴趣\n",
      "他 建议 一种 化学 系统 相互 反应 并 传播 于 整个 空间 的 系统 被 称为 反应 传播 系统 可以 解释 出 于 摩 的 主要 现象\n",
      "他 使用 部分 差异 等 系统 来 模拟 催 化 化学 反应\n",
      "例如 如果 需要 一个 催化剂 A 来 进行 某种 的 化学 反应 如果 该 反应 产生 了 更多 的 催化剂 A 那么 我们 就 说 该 反应 是 自动 催化 的, 有 积极 的 反馈 可以 以 非 线 差异 等 模式 来 模拟\n",
      "图 灵 发现 如果 化学 反应 不仅 产生 催化剂 A 并且 还 产生 一种 抑制 剂 B 减缓 A 的 生产\n",
      "如果 A 和 B 然后 以 不同 的 速度 在 容器 中 扩散 那么 你 可以 有 一些 A 统治 的 地区 和 一些 B 统治 的 地区\n",
      "为 计算 这个 程度 的 程度, 图 灵 需要 一个 强大 的 计算机 但 这些 计算机 在 1951 年 没有 如此 免费 的 使用 因此 他 必须 使用 线 近 来 解决 人工 的 等 式\n",
      "这些 计算 给出 了 正确 的 质量 结果 并 产生 例如 一种 统一 的 混合物 奇怪 地 经常 间 固定 的 红色 点\n",
      "俄罗斯 的 生物 化学 学家 Boris Belousov 已经 进行 了 类似 的 实验 但 无法 得到 他 的 论文 因为 当代 的 偏见 任何 这种 的 行为 都 违反 了 热 动力 的 第二项 法律\n",
      "Belousov 并不知道 Turing 在 皇家 协会 的 哲学 交易 中 的 论文\n",
      "尽管 在 DNA 的 结构和 作用 被 理解 之前 已经 公布 了  图 灵 关于 摩 的 工作 今天 仍然 重要 并且 被 认为 是 数学 生物学 中 的 重要 的 一项 工作\n",
      "图 灵 的 论文 的 早期 应用 之一 是 詹姆斯 默 的 前 年 的 工作. 在 猫 的 皮 上 的 斑点 和 条状. 无论 大小\n",
      "这个 领域 的 进一步 研究 表明 图 灵 的 工作 可以 部分 排除 了 心脏 的 生长 和 头发 的 生长 和 肺 的 支 型 甚至 将 心脏 放在 胸部 的 左边 的 左右 的 不对称\n",
      "2012 年 谢 等人\n",
      "在 老鼠 中 发现 移除 了 赫 的 基因 导致 数字 数量 增加 而 没有 增加 肢体 的 整体 大小 表明 赫 的 基因 通过 调 一种 图 灵 型 机制 的 波 长度 来 控制 数字 的 形成\n",
      "后来 的 论文 直到 1992 年 公布 之后 才能 得到 论文\n",
      "在 人类 犹太 内部 被 研究 成 一个 历史 的 文字 来 发现 它 如何 能 证明 实际 的 意义 于 今天 的 生活\n",
      "在 加蓬 和 喀麦隆 举行 的 一个 宗教 仪式 是 由 一些 班图 民族 进行 的 奥 圭\n",
      "在 这种 状态 中, 取决于 区域 的 区域, 被 尊重 的 音乐 人 所 发挥 的 鼓 或 工具 的 节奏 ( 每个 音乐 都 是 给 的 神 或 祖先 所 独 有 的 ) 参与者 通过 进行 不同 的 仪式 运动 或 舞蹈 来 进一步 增强 他们 的 意识 来 体现 一个 神圣 的 或 祖先 的 能量 或 思想 状态\n",
      "当 这种 类似 的 国家 被 见证 和 理解 时, 追随 者 被 了解 一种 思考 一种 方式 的 简单 或 象征性 的 体现 一种 特定 的 思想 或 参照 框架\n",
      "这 培养 了 将 这种 思想 所 产生 的 情感 与 他们 在 日常生活 中 的 情景 表现 区分 的 技能\n",
      "这种 分离 和 随后 对 纯 能源 或 情感 的 性质 和 来源 的 思考 有助于 参与者 在 常见 的 情况下 管理和 接受 它们\n",
      "在 语言 中, 动 语 是 研究 如何 使用 舌 、 嘴 、 下 牙 、 声 带 和其他 语言 器官 来 制造 声音\n",
      "声音 按 表达 方式 和 表达 地点 分类\n",
      "连接 的 地点 指 在 颈 或 口 中 空气 流 被 压缩 的 地点\n",
      "表达 方式 指 语言 器官 互动 的 方式 例如 空气 如何 受 限制, 使用 了 何种 形式 的 空气 流 ( 例如\n",
      "脉 性 性 性 性 性 和 点击 ) 无论 声 带 是否 在 振 动, 是否 向 空气 开放\n",
      "这个 概念 主要 用于 制作 调, 但 可以 用于 音 和 鼻 音 等 品质 的 元\n",
      "对于 任何 的 表达 地 可能 有 几种 的 表达 方式 因此 有 几种 神圣 的 声音\n",
      "正常 的 人类 讲话 是 肺 压力 产生 的, 这 在 喉 中 的 glottis 中 产生 了 磷 音 并 被 声 道 和 口 改变 成 不同 的 元 和 音\n",
      "然而 人类 可以 在 犹太 语 中 不 使用 肺 和 glottis 的 语言 其中 有 三种 类型 的 语言 : 食 语 语言 、 harynge 语言 和 Buccal 语言 ( 更 称 Donald Duck 的 语言 )\n",
      "语音 制作 是 一项 复杂 的 活动, 结果 是 常见 的, 在 儿童 中 尤为 常见\n"
     ]
    }
   ],
   "source": [
    "outputs_wa = []\n",
    "\n",
    "for input_sentence in vital[\"sentences\"]:\n",
    "    tokenized_sentence = tokenizer([input_sentence], return_tensors='np')\n",
    "    out = model_with_wa_trg_ids.generate(**tokenized_sentence, max_length=128)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        output_sentence = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "        print(output_sentence)\n",
    "        outputs_wa.append(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>sentences</th>\n",
       "      <th>no_anno</th>\n",
       "      <th>pos_anno</th>\n",
       "      <th>wa_anno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstract art</td>\n",
       "      <td>In Chinese painting, abstraction can be traced...</td>\n",
       "      <td>在 中国 的 画 中 抽象 可以 追溯 到 唐 时代 的 画 人 王 模 (? ) 他 被 ...</td>\n",
       "      <td>在 中国 的 画 中, 抽象 可以 追溯 到 汤 时代 的 画 家 王 模 的 风格</td>\n",
       "      <td>在 中国 的 画 中 的 抽象 可以 追溯 到 唐 的 画 人 Wang Mo (? ) 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract art</td>\n",
       "      <td>While none of his paintings remain, this style...</td>\n",
       "      <td>虽然 他 的 绘 画 都 没有 留下 但 这种 风格 在 一些 宋 时代 的 绘画 中 明显 可见</td>\n",
       "      <td>虽然 他 的 绘 画 都 没有 留下 了 但 这种 风格 在 一些 宋 时代 的 绘画 中 ...</td>\n",
       "      <td>虽然 他 的 作品 没有 留下 但 这种 风格 在 一些 宋 时代 的 绘画 中 明显 可见</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract art</td>\n",
       "      <td>The Chan buddhist painter Liang Kai (??, c. 11...</td>\n",
       "      <td>Chan buddist 画家 Liang Kai (?, c 1140 * 1210 ) ...</td>\n",
       "      <td>Chan Buddhist 画家 梁凯 (?, c 1140 * 1210 ) 运用 了 这...</td>\n",
       "      <td>Chan buddist 画家 Liang Kai (?, c 1140 * 1210 ) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract art</td>\n",
       "      <td>A late Song painter named Yu Jian, adept to Ti...</td>\n",
       "      <td>一位 已故 的 画 画 名为 于 建 的 专家 于 天 台 孟加拉 创建 了 一系列 被 喷...</td>\n",
       "      <td>一位 已故 的 画 画 人  看向 并 得 于 天 台 佛教 创建 了 一系列 被 喷 的 ...</td>\n",
       "      <td>一个 已故 的 画 人  beating 于 车站 并 得 于 天 台 佛教 并 创建 了 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>When Turing was 39 years old in 1951, he turne...</td>\n",
       "      <td>当 1951 年 Turing 年 39 岁 时 他 转向 数学 生物学 最后 在 年 1 ...</td>\n",
       "      <td>当 1951 年 Turing 39 岁 时 他 转向 数学 生物学 最后 在 1 月 发表...</td>\n",
       "      <td>当 图 灵 在 1951 年 39 岁 时 他 转向 数学 生物学 最后 在 1 年 1 月...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>He was interested in morphogenesis, the develo...</td>\n",
       "      <td>他 对 生物 生物 生物 的 形态 和 形状 的 发展 感兴趣</td>\n",
       "      <td>他 对 生物 生物 的 形态 和 形状 的 发展 感兴趣</td>\n",
       "      <td>他 对 生物 生物 的 形态 和 形状 的 发展 感兴趣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>He suggested that a system of chemicals reacti...</td>\n",
       "      <td>他 提出 一个 化学 系统 互相 反应 并 扩散 整个 空间 被 称为 一个 反应 扩散 系...</td>\n",
       "      <td>他 提议 一个 化学 系统 互相 反应 并 在 整个 空间 传播 称为 一个 反应 扩散 系...</td>\n",
       "      <td>他 建议 一种 化学 系统 相互 反应 并 传播 于 整个 空间 的 系统 被 称为 反应 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>He used systems of partial differential equati...</td>\n",
       "      <td>他 使用 部分 差异 等 系统 来 模拟 催 化 化学 反应</td>\n",
       "      <td>他 使用 部分 差异 等 系统 来 模拟 催 化 化学 反应</td>\n",
       "      <td>他 使用 部分 差异 等 系统 来 模拟 催 化 化学 反应</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>For example, if a catalyst A is required for a...</td>\n",
       "      <td>例如 如果 某种 化学 反应 需要 一个 催化剂 A 而 如果 该 反应 产生 了 更多 的...</td>\n",
       "      <td>例如 如果 某种 化学 反应 需要 一个 催化剂 A 进行 并且 如果 该 反应 产生 了 ...</td>\n",
       "      <td>例如 如果 需要 一个 催化剂 A 来 进行 某种 的 化学 反应 如果 该 反应 产生 了...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>Turing discovered that patterns could be creat...</td>\n",
       "      <td>Turing 发现 如果 化学 反应 不仅 产生 了 催化剂 A 并且 也 产生 了 抑制 ...</td>\n",
       "      <td>Turing 发现 如果 化学 反应 不仅 产生 催化剂 A 并且 还 产生 抑制 剂 B ...</td>\n",
       "      <td>图 灵 发现 如果 化学 反应 不仅 产生 催化剂 A 并且 还 产生 一种 抑制 剂 B ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>If A and B then diffused through the container...</td>\n",
       "      <td>如果 A 和 B 然后 以 不同 的 速度 在 容器 中 扩散 那么 你 可以 有 一些 A...</td>\n",
       "      <td>如果 A 和 B 然后 以 不同 的 速度 在 集装箱 中 扩散 那么 你 可以 有 一些 ...</td>\n",
       "      <td>如果 A 和 B 然后 以 不同 的 速度 在 容器 中 扩散 那么 你 可以 有 一些 A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>To calculate the extent of this, Turing would ...</td>\n",
       "      <td>为 计算 这个 程度 的 程度, 图 灵 需要 一个 强大 的 计算机 但 这些 计算机 在...</td>\n",
       "      <td>为 计算 其 程度, 图 灵 需要 一个 强大 的 计算机 但 这些 计算机 在 1951 ...</td>\n",
       "      <td>为 计算 这个 程度 的 程度, 图 灵 需要 一个 强大 的 计算机 但 这些 计算机 在...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>These calculations gave the right qualitative ...</td>\n",
       "      <td>这些 计算 给出 了 正确 的 质量 结果 并 产生 例如 一种 统一 的 混合物 奇怪 地...</td>\n",
       "      <td>这些 计算 给出 了 正确 的 质量 结果 例如 产生 了 一个 统一 的 混合物 奇怪 地...</td>\n",
       "      <td>这些 计算 给出 了 正确 的 质量 结果 并 产生 例如 一种 统一 的 混合物 奇怪 地...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>The Russian biochemist Boris Belousov had perf...</td>\n",
       "      <td>俄罗斯 生物 化学 学家 Boris Belousov 已经 进行 了 类似 的 实验 但 ...</td>\n",
       "      <td>俄罗斯 生物 化学 学家 Boris Belousov 曾 进行 类似 的 实验 但 无法 ...</td>\n",
       "      <td>俄罗斯 的 生物 化学 学家 Boris Belousov 已经 进行 了 类似 的 实验 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>Belousov was not aware of Turing's paper in th...</td>\n",
       "      <td>Belousov 并不知道 Turing 在 皇家 协会 的 哲学 交易 中 的 论文</td>\n",
       "      <td>Belousov 并不知道 Turing 在 皇家 协会 哲学 交易 中 的 论文</td>\n",
       "      <td>Belousov 并不知道 Turing 在 皇家 协会 的 哲学 交易 中 的 论文</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>Although published before the structure and ro...</td>\n",
       "      <td>尽管 在 DNA 的 结构 和 作用 被 理解 之前 已经 公布 了  图 灵 关于 形态 ...</td>\n",
       "      <td>尽管 在 DNA 的 结构 和 作用 被 理解 之前 已经 公布 了  图 灵 关于 摩 的...</td>\n",
       "      <td>尽管 在 DNA 的 结构和 作用 被 理解 之前 已经 公布 了  图 灵 关于 摩 的 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>One of the early applications of Turing's pape...</td>\n",
       "      <td>图 灵 论文 的 早期 应用 之一 是 詹姆斯 默 的 作品 包括 大型 和 小型 猫 的 ...</td>\n",
       "      <td>图 灵 论文 的 早期 应用 之一 是 詹姆斯 默 的 著作 写 在 猫 的 皮 上 的 斑...</td>\n",
       "      <td>图 灵 的 论文 的 早期 应用 之一 是 詹姆斯 默 的 前 年 的 工作. 在 猫 的 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>Further research in the area suggests that Tur...</td>\n",
       "      <td>这个 领域 的 进一步 研究 表明 图 灵 的 工作 可以 部分 延 于 1978 年 的 ...</td>\n",
       "      <td>这个 领域 的 进一步 研究 表明 图 灵 的 工作 可以 部分 排除 了 心脏 的 生长 ...</td>\n",
       "      <td>这个 领域 的 进一步 研究 表明 图 灵 的 工作 可以 部分 排除 了 心脏 的 生长 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>In 2012, Sheth, et al.</td>\n",
       "      <td>2012 年 谢 等人</td>\n",
       "      <td>2012 年 谢 等人</td>\n",
       "      <td>2012 年 谢 等人</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>found that in mice, removal of Hox genes cause...</td>\n",
       "      <td>在 老鼠 中 发现 移 了 赫 克斯 基因 导致 数字 数量 增加 而 没有 增加 肢体 的...</td>\n",
       "      <td>在 老鼠 中 发现 移 了 赫 克斯 基因 导致 数字 数量 增加 而 没有 增加 肢体 的...</td>\n",
       "      <td>在 老鼠 中 发现 移除 了 赫 的 基因 导致 数字 数量 增加 而 没有 增加 肢体 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>Later papers were not available until Collecte...</td>\n",
       "      <td>后来 的 论文 直到 1992 年 公布 了 收集 的 图 灵 工程</td>\n",
       "      <td>后来 的 论文 直到 1992 年 公布 了 收集 的 图 灵 工程</td>\n",
       "      <td>后来 的 论文 直到 1992 年 公布 之后 才能 得到 论文</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Talmud</td>\n",
       "      <td>Within Humanistic Judaism, Talmud is studied a...</td>\n",
       "      <td>在 人类 犹太 内部 被 研究 成 一个 历史 的 文字 来 发现 它 如何 显示 与 今天...</td>\n",
       "      <td>在 人类 犹太 内部 被 研究 成 一个 历史 文字 来 发现 它 如何 展示 与 今日 生...</td>\n",
       "      <td>在 人类 犹太 内部 被 研究 成 一个 历史 的 文字 来 发现 它 如何 能 证明 实际...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Traditional African religions</td>\n",
       "      <td>One religious ceremony practiced in Gabon and ...</td>\n",
       "      <td>在 加蓬 和 喀麦隆 举行 的 一个 宗教 仪式 是 由 一些 班图 民族 进行 的 Okuyi</td>\n",
       "      <td>在 加蓬 和 喀麦隆 举行 的 一个 宗教 仪式 是 由 几个 班图 民族 进行 的 奥 圭</td>\n",
       "      <td>在 加蓬 和 喀麦隆 举行 的 一个 宗教 仪式 是 由 一些 班图 民族 进行 的 奥 圭</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Traditional African religions</td>\n",
       "      <td>In this state, depending upon the region, drum...</td>\n",
       "      <td>在 这种 状态 中, 取决于 区域 的 区域, 受到 尊重 的 音乐 们 所 演奏 的 鼓 ...</td>\n",
       "      <td>在 这个 州, 取决于 区域 的 区域, 由 受 尊重 的 音乐 人 所 发挥 的 鼓 或 ...</td>\n",
       "      <td>在 这种 状态 中, 取决于 区域 的 区域, 被 尊重 的 音乐 人 所 发挥 的 鼓 或...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Traditional African religions</td>\n",
       "      <td>When this trance-like state is witnessed and u...</td>\n",
       "      <td>当 这种 类似 的 国家 被 见证 和 理解 时, 信徒 也 被 了解 一种 方式 来 思考...</td>\n",
       "      <td>当 这 类似 的 国家 被 见证 和 理解 时, 追随 者 也 具有 一种 思考 一种 方式...</td>\n",
       "      <td>当 这种 类似 的 国家 被 见证 和 理解 时, 追随 者 被 了解 一种 思考 一种 方...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Traditional African religions</td>\n",
       "      <td>This builds skills at separating the feelings ...</td>\n",
       "      <td>这 建立 了 技能 将 这种 思想 所 激发 的 情感 与 他们 在 日常生活 中 的 情景...</td>\n",
       "      <td>这 建立 了 技能 将 这种 思想 所 激发 的 情感 与 他们 在 日常生活 中 的 情景...</td>\n",
       "      <td>这 培养 了 将 这种 思想 所 产生 的 情感 与 他们 在 日常生活 中 的 情景 表现...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Traditional African religions</td>\n",
       "      <td>Such separation and subsequent contemplation o...</td>\n",
       "      <td>这种 分离 和 随后 对 纯 能源 或 情感 的 性质 和 来源 的 思考 有助于 参与者 ...</td>\n",
       "      <td>这种 分离 和 随后 对 纯 能源 或 情感 的 性质 和 来源 的 思考 有助于 参与者 ...</td>\n",
       "      <td>这种 分离 和 随后 对 纯 能源 或 情感 的 性质 和 来源 的 思考 有助于 参与者 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Speech</td>\n",
       "      <td>In linguistics, articulatory phonetics is the ...</td>\n",
       "      <td>在 语言 上, 动 语 是 研究 舌 、 嘴 、 下 牙 、 声 带 和其他 语言 器官 如...</td>\n",
       "      <td>在 语言 上, 脉 音 是 研究 舌 、 嘴 、 下 牙 、 声 带 和其他 语言 器官 如...</td>\n",
       "      <td>在 语言 中, 动 语 是 研究 如何 使用 舌 、 嘴 、 下 牙 、 声 带 和其他 语...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Speech</td>\n",
       "      <td>Speech sounds are categorized by manner of art...</td>\n",
       "      <td>声音 按 表达 方式 和 表达 地点 分类</td>\n",
       "      <td>声音 按 表达 方式 和 表达 地点 分类</td>\n",
       "      <td>声音 按 表达 方式 和 表达 地点 分类</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Speech</td>\n",
       "      <td>Place of articulation refers to where in the n...</td>\n",
       "      <td>连接 的 地点 指 在 颈 或 口 中 空气 流 被 压缩 的 地方</td>\n",
       "      <td>表达 的 地点 指 在 颈 或 口 中 空气 流 被 压缩 的 地方</td>\n",
       "      <td>连接 的 地点 指 在 颈 或 口 中 空气 流 被 压缩 的 地点</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Speech</td>\n",
       "      <td>Manner of articulation refers to the manner in...</td>\n",
       "      <td>表达 方式 指 语言 器官 互动 的 方式 例如 空气 被 限制 的 程度 以及 使用 的 ...</td>\n",
       "      <td>表达 方式 指 语言 器官 互动 的 方式, 如 空气 如何 受 限制, 使用 了 何种 形...</td>\n",
       "      <td>表达 方式 指 语言 器官 互动 的 方式 例如 空气 如何 受 限制, 使用 了 何种 形...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Speech</td>\n",
       "      <td>pulmonic, implosive, ejectives, and clicks), w...</td>\n",
       "      <td>脉 性 性 性 性 性 性 和 点击 的 性 性 性 的 性 性 性 性 性 性 性 性 性...</td>\n",
       "      <td>脉 性 性 性 性 性 性 和 点击 的 性 性 性 的 性 性 性 性 性 性 性 性 性...</td>\n",
       "      <td>脉 性 性 性 性 性 和 点击 ) 无论 声 带 是否 在 振 动, 是否 向 空气 开放</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Speech</td>\n",
       "      <td>The concept is primarily used for the producti...</td>\n",
       "      <td>这个 概念 主要 用于 制作 合成, 但 可以 用于 音 的 音, 如 发票 和 鼻 化</td>\n",
       "      <td>这个 概念 主要 用于 制作 合成 材料 但 可以 用于 音 和 鼻 音 等 品质 的 元</td>\n",
       "      <td>这个 概念 主要 用于 制作 调, 但 可以 用于 音 和 鼻 音 等 品质 的 元</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Speech</td>\n",
       "      <td>For any place of articulation, there may be se...</td>\n",
       "      <td>对于 任何 的 表达 地 可能 有 几种 表达 方式 因此 有 几种 有机 的 声音</td>\n",
       "      <td>对于 任何 的 表达 地 可能 有 几种 表达 方式 因此 有 几种 神圣 的 声音</td>\n",
       "      <td>对于 任何 的 表达 地 可能 有 几种 的 表达 方式 因此 有 几种 神圣 的 声音</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Speech</td>\n",
       "      <td>Normal human speech is pulmonic, produced with...</td>\n",
       "      <td>正常 的 人类 语言 是 肺 的 压力 产生 了 硫 酸 在 喉 的 凝 石 中 产生 了 ...</td>\n",
       "      <td>正常 的 人类 语言 是 肺 的 压力 产生 了 硫 酸 的 声音 并 被 声音 和 口 改...</td>\n",
       "      <td>正常 的 人类 讲话 是 肺 压力 产生 的, 这 在 喉 中 的 glottis 中 产生...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Speech</td>\n",
       "      <td>However humans can pronounce words without the...</td>\n",
       "      <td>然而 人类 可以 在 犹太 语 中 不 使用 肺 和 glottis 的 语言 其中 有 三...</td>\n",
       "      <td>然而 人类 可以 在 耶路撒冷 的 演讲 中 不 使用 肺 和 glottis 其中 有 三...</td>\n",
       "      <td>然而 人类 可以 在 犹太 语 中 不 使用 肺 和 glottis 的 语言 其中 有 三...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Speech</td>\n",
       "      <td>Speech production is a complex activity, and a...</td>\n",
       "      <td>语音 制作 是 一项 复杂 的 活动, 结果 是 常见 的, 在 儿童 中 尤为 常见</td>\n",
       "      <td>语言 制作 是 一项 复杂 的 活动, 因此 特别 在 儿童 中 也 是 常见 的</td>\n",
       "      <td>语音 制作 是 一项 复杂 的 活动, 结果 是 常见 的, 在 儿童 中 尤为 常见</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          article  \\\n",
       "0                    Abstract art   \n",
       "1                    Abstract art   \n",
       "2                    Abstract art   \n",
       "3                    Abstract art   \n",
       "4                     Alan Turing   \n",
       "5                     Alan Turing   \n",
       "6                     Alan Turing   \n",
       "7                     Alan Turing   \n",
       "8                     Alan Turing   \n",
       "9                     Alan Turing   \n",
       "10                    Alan Turing   \n",
       "11                    Alan Turing   \n",
       "12                    Alan Turing   \n",
       "13                    Alan Turing   \n",
       "14                    Alan Turing   \n",
       "15                    Alan Turing   \n",
       "16                    Alan Turing   \n",
       "17                    Alan Turing   \n",
       "18                    Alan Turing   \n",
       "19                    Alan Turing   \n",
       "20                    Alan Turing   \n",
       "21                         Talmud   \n",
       "22  Traditional African religions   \n",
       "23  Traditional African religions   \n",
       "24  Traditional African religions   \n",
       "25  Traditional African religions   \n",
       "26  Traditional African religions   \n",
       "27                         Speech   \n",
       "28                         Speech   \n",
       "29                         Speech   \n",
       "30                         Speech   \n",
       "31                         Speech   \n",
       "32                         Speech   \n",
       "33                         Speech   \n",
       "34                         Speech   \n",
       "35                         Speech   \n",
       "36                         Speech   \n",
       "\n",
       "                                            sentences  \\\n",
       "0   In Chinese painting, abstraction can be traced...   \n",
       "1   While none of his paintings remain, this style...   \n",
       "2   The Chan buddhist painter Liang Kai (??, c. 11...   \n",
       "3   A late Song painter named Yu Jian, adept to Ti...   \n",
       "4   When Turing was 39 years old in 1951, he turne...   \n",
       "5   He was interested in morphogenesis, the develo...   \n",
       "6   He suggested that a system of chemicals reacti...   \n",
       "7   He used systems of partial differential equati...   \n",
       "8   For example, if a catalyst A is required for a...   \n",
       "9   Turing discovered that patterns could be creat...   \n",
       "10  If A and B then diffused through the container...   \n",
       "11  To calculate the extent of this, Turing would ...   \n",
       "12  These calculations gave the right qualitative ...   \n",
       "13  The Russian biochemist Boris Belousov had perf...   \n",
       "14  Belousov was not aware of Turing's paper in th...   \n",
       "15  Although published before the structure and ro...   \n",
       "16  One of the early applications of Turing's pape...   \n",
       "17  Further research in the area suggests that Tur...   \n",
       "18                             In 2012, Sheth, et al.   \n",
       "19  found that in mice, removal of Hox genes cause...   \n",
       "20  Later papers were not available until Collecte...   \n",
       "21  Within Humanistic Judaism, Talmud is studied a...   \n",
       "22  One religious ceremony practiced in Gabon and ...   \n",
       "23  In this state, depending upon the region, drum...   \n",
       "24  When this trance-like state is witnessed and u...   \n",
       "25  This builds skills at separating the feelings ...   \n",
       "26  Such separation and subsequent contemplation o...   \n",
       "27  In linguistics, articulatory phonetics is the ...   \n",
       "28  Speech sounds are categorized by manner of art...   \n",
       "29  Place of articulation refers to where in the n...   \n",
       "30  Manner of articulation refers to the manner in...   \n",
       "31  pulmonic, implosive, ejectives, and clicks), w...   \n",
       "32  The concept is primarily used for the producti...   \n",
       "33  For any place of articulation, there may be se...   \n",
       "34  Normal human speech is pulmonic, produced with...   \n",
       "35  However humans can pronounce words without the...   \n",
       "36  Speech production is a complex activity, and a...   \n",
       "\n",
       "                                              no_anno  \\\n",
       "0   在 中国 的 画 中 抽象 可以 追溯 到 唐 时代 的 画 人 王 模 (? ) 他 被 ...   \n",
       "1   虽然 他 的 绘 画 都 没有 留下 但 这种 风格 在 一些 宋 时代 的 绘画 中 明显 可见   \n",
       "2   Chan buddist 画家 Liang Kai (?, c 1140 * 1210 ) ...   \n",
       "3   一位 已故 的 画 画 名为 于 建 的 专家 于 天 台 孟加拉 创建 了 一系列 被 喷...   \n",
       "4   当 1951 年 Turing 年 39 岁 时 他 转向 数学 生物学 最后 在 年 1 ...   \n",
       "5                     他 对 生物 生物 生物 的 形态 和 形状 的 发展 感兴趣   \n",
       "6   他 提出 一个 化学 系统 互相 反应 并 扩散 整个 空间 被 称为 一个 反应 扩散 系...   \n",
       "7                      他 使用 部分 差异 等 系统 来 模拟 催 化 化学 反应   \n",
       "8   例如 如果 某种 化学 反应 需要 一个 催化剂 A 而 如果 该 反应 产生 了 更多 的...   \n",
       "9   Turing 发现 如果 化学 反应 不仅 产生 了 催化剂 A 并且 也 产生 了 抑制 ...   \n",
       "10  如果 A 和 B 然后 以 不同 的 速度 在 容器 中 扩散 那么 你 可以 有 一些 A...   \n",
       "11  为 计算 这个 程度 的 程度, 图 灵 需要 一个 强大 的 计算机 但 这些 计算机 在...   \n",
       "12  这些 计算 给出 了 正确 的 质量 结果 并 产生 例如 一种 统一 的 混合物 奇怪 地...   \n",
       "13  俄罗斯 生物 化学 学家 Boris Belousov 已经 进行 了 类似 的 实验 但 ...   \n",
       "14        Belousov 并不知道 Turing 在 皇家 协会 的 哲学 交易 中 的 论文   \n",
       "15  尽管 在 DNA 的 结构 和 作用 被 理解 之前 已经 公布 了  图 灵 关于 形态 ...   \n",
       "16  图 灵 论文 的 早期 应用 之一 是 詹姆斯 默 的 作品 包括 大型 和 小型 猫 的 ...   \n",
       "17  这个 领域 的 进一步 研究 表明 图 灵 的 工作 可以 部分 延 于 1978 年 的 ...   \n",
       "18                                        2012 年 谢 等人   \n",
       "19  在 老鼠 中 发现 移 了 赫 克斯 基因 导致 数字 数量 增加 而 没有 增加 肢体 的...   \n",
       "20                 后来 的 论文 直到 1992 年 公布 了 收集 的 图 灵 工程   \n",
       "21  在 人类 犹太 内部 被 研究 成 一个 历史 的 文字 来 发现 它 如何 显示 与 今天...   \n",
       "22   在 加蓬 和 喀麦隆 举行 的 一个 宗教 仪式 是 由 一些 班图 民族 进行 的 Okuyi   \n",
       "23  在 这种 状态 中, 取决于 区域 的 区域, 受到 尊重 的 音乐 们 所 演奏 的 鼓 ...   \n",
       "24  当 这种 类似 的 国家 被 见证 和 理解 时, 信徒 也 被 了解 一种 方式 来 思考...   \n",
       "25  这 建立 了 技能 将 这种 思想 所 激发 的 情感 与 他们 在 日常生活 中 的 情景...   \n",
       "26  这种 分离 和 随后 对 纯 能源 或 情感 的 性质 和 来源 的 思考 有助于 参与者 ...   \n",
       "27  在 语言 上, 动 语 是 研究 舌 、 嘴 、 下 牙 、 声 带 和其他 语言 器官 如...   \n",
       "28                              声音 按 表达 方式 和 表达 地点 分类   \n",
       "29                 连接 的 地点 指 在 颈 或 口 中 空气 流 被 压缩 的 地方   \n",
       "30  表达 方式 指 语言 器官 互动 的 方式 例如 空气 被 限制 的 程度 以及 使用 的 ...   \n",
       "31  脉 性 性 性 性 性 性 和 点击 的 性 性 性 的 性 性 性 性 性 性 性 性 性...   \n",
       "32       这个 概念 主要 用于 制作 合成, 但 可以 用于 音 的 音, 如 发票 和 鼻 化   \n",
       "33         对于 任何 的 表达 地 可能 有 几种 表达 方式 因此 有 几种 有机 的 声音   \n",
       "34  正常 的 人类 语言 是 肺 的 压力 产生 了 硫 酸 在 喉 的 凝 石 中 产生 了 ...   \n",
       "35  然而 人类 可以 在 犹太 语 中 不 使用 肺 和 glottis 的 语言 其中 有 三...   \n",
       "36        语音 制作 是 一项 复杂 的 活动, 结果 是 常见 的, 在 儿童 中 尤为 常见   \n",
       "\n",
       "                                             pos_anno  \\\n",
       "0          在 中国 的 画 中, 抽象 可以 追溯 到 汤 时代 的 画 家 王 模 的 风格   \n",
       "1   虽然 他 的 绘 画 都 没有 留下 了 但 这种 风格 在 一些 宋 时代 的 绘画 中 ...   \n",
       "2   Chan Buddhist 画家 梁凯 (?, c 1140 * 1210 ) 运用 了 这...   \n",
       "3   一位 已故 的 画 画 人  看向 并 得 于 天 台 佛教 创建 了 一系列 被 喷 的 ...   \n",
       "4   当 1951 年 Turing 39 岁 时 他 转向 数学 生物学 最后 在 1 月 发表...   \n",
       "5                        他 对 生物 生物 的 形态 和 形状 的 发展 感兴趣   \n",
       "6   他 提议 一个 化学 系统 互相 反应 并 在 整个 空间 传播 称为 一个 反应 扩散 系...   \n",
       "7                      他 使用 部分 差异 等 系统 来 模拟 催 化 化学 反应   \n",
       "8   例如 如果 某种 化学 反应 需要 一个 催化剂 A 进行 并且 如果 该 反应 产生 了 ...   \n",
       "9   Turing 发现 如果 化学 反应 不仅 产生 催化剂 A 并且 还 产生 抑制 剂 B ...   \n",
       "10  如果 A 和 B 然后 以 不同 的 速度 在 集装箱 中 扩散 那么 你 可以 有 一些 ...   \n",
       "11  为 计算 其 程度, 图 灵 需要 一个 强大 的 计算机 但 这些 计算机 在 1951 ...   \n",
       "12  这些 计算 给出 了 正确 的 质量 结果 例如 产生 了 一个 统一 的 混合物 奇怪 地...   \n",
       "13  俄罗斯 生物 化学 学家 Boris Belousov 曾 进行 类似 的 实验 但 无法 ...   \n",
       "14          Belousov 并不知道 Turing 在 皇家 协会 哲学 交易 中 的 论文   \n",
       "15  尽管 在 DNA 的 结构 和 作用 被 理解 之前 已经 公布 了  图 灵 关于 摩 的...   \n",
       "16  图 灵 论文 的 早期 应用 之一 是 詹姆斯 默 的 著作 写 在 猫 的 皮 上 的 斑...   \n",
       "17  这个 领域 的 进一步 研究 表明 图 灵 的 工作 可以 部分 排除 了 心脏 的 生长 ...   \n",
       "18                                        2012 年 谢 等人   \n",
       "19  在 老鼠 中 发现 移 了 赫 克斯 基因 导致 数字 数量 增加 而 没有 增加 肢体 的...   \n",
       "20                 后来 的 论文 直到 1992 年 公布 了 收集 的 图 灵 工程   \n",
       "21  在 人类 犹太 内部 被 研究 成 一个 历史 文字 来 发现 它 如何 展示 与 今日 生...   \n",
       "22     在 加蓬 和 喀麦隆 举行 的 一个 宗教 仪式 是 由 几个 班图 民族 进行 的 奥 圭   \n",
       "23  在 这个 州, 取决于 区域 的 区域, 由 受 尊重 的 音乐 人 所 发挥 的 鼓 或 ...   \n",
       "24  当 这 类似 的 国家 被 见证 和 理解 时, 追随 者 也 具有 一种 思考 一种 方式...   \n",
       "25  这 建立 了 技能 将 这种 思想 所 激发 的 情感 与 他们 在 日常生活 中 的 情景...   \n",
       "26  这种 分离 和 随后 对 纯 能源 或 情感 的 性质 和 来源 的 思考 有助于 参与者 ...   \n",
       "27  在 语言 上, 脉 音 是 研究 舌 、 嘴 、 下 牙 、 声 带 和其他 语言 器官 如...   \n",
       "28                              声音 按 表达 方式 和 表达 地点 分类   \n",
       "29                 表达 的 地点 指 在 颈 或 口 中 空气 流 被 压缩 的 地方   \n",
       "30  表达 方式 指 语言 器官 互动 的 方式, 如 空气 如何 受 限制, 使用 了 何种 形...   \n",
       "31  脉 性 性 性 性 性 性 和 点击 的 性 性 性 的 性 性 性 性 性 性 性 性 性...   \n",
       "32      这个 概念 主要 用于 制作 合成 材料 但 可以 用于 音 和 鼻 音 等 品质 的 元   \n",
       "33         对于 任何 的 表达 地 可能 有 几种 表达 方式 因此 有 几种 神圣 的 声音   \n",
       "34  正常 的 人类 语言 是 肺 的 压力 产生 了 硫 酸 的 声音 并 被 声音 和 口 改...   \n",
       "35  然而 人类 可以 在 耶路撒冷 的 演讲 中 不 使用 肺 和 glottis 其中 有 三...   \n",
       "36          语言 制作 是 一项 复杂 的 活动, 因此 特别 在 儿童 中 也 是 常见 的   \n",
       "\n",
       "                                              wa_anno  \n",
       "0   在 中国 的 画 中 的 抽象 可以 追溯 到 唐 的 画 人 Wang Mo (? ) 的...  \n",
       "1      虽然 他 的 作品 没有 留下 但 这种 风格 在 一些 宋 时代 的 绘画 中 明显 可见  \n",
       "2   Chan buddist 画家 Liang Kai (?, c 1140 * 1210 ) ...  \n",
       "3   一个 已故 的 画 人  beating 于 车站 并 得 于 天 台 佛教 并 创建 了 ...  \n",
       "4   当 图 灵 在 1951 年 39 岁 时 他 转向 数学 生物学 最后 在 1 年 1 月...  \n",
       "5                        他 对 生物 生物 的 形态 和 形状 的 发展 感兴趣  \n",
       "6   他 建议 一种 化学 系统 相互 反应 并 传播 于 整个 空间 的 系统 被 称为 反应 ...  \n",
       "7                      他 使用 部分 差异 等 系统 来 模拟 催 化 化学 反应  \n",
       "8   例如 如果 需要 一个 催化剂 A 来 进行 某种 的 化学 反应 如果 该 反应 产生 了...  \n",
       "9   图 灵 发现 如果 化学 反应 不仅 产生 催化剂 A 并且 还 产生 一种 抑制 剂 B ...  \n",
       "10  如果 A 和 B 然后 以 不同 的 速度 在 容器 中 扩散 那么 你 可以 有 一些 A...  \n",
       "11  为 计算 这个 程度 的 程度, 图 灵 需要 一个 强大 的 计算机 但 这些 计算机 在...  \n",
       "12  这些 计算 给出 了 正确 的 质量 结果 并 产生 例如 一种 统一 的 混合物 奇怪 地...  \n",
       "13  俄罗斯 的 生物 化学 学家 Boris Belousov 已经 进行 了 类似 的 实验 ...  \n",
       "14        Belousov 并不知道 Turing 在 皇家 协会 的 哲学 交易 中 的 论文  \n",
       "15  尽管 在 DNA 的 结构和 作用 被 理解 之前 已经 公布 了  图 灵 关于 摩 的 ...  \n",
       "16  图 灵 的 论文 的 早期 应用 之一 是 詹姆斯 默 的 前 年 的 工作. 在 猫 的 ...  \n",
       "17  这个 领域 的 进一步 研究 表明 图 灵 的 工作 可以 部分 排除 了 心脏 的 生长 ...  \n",
       "18                                        2012 年 谢 等人  \n",
       "19  在 老鼠 中 发现 移除 了 赫 的 基因 导致 数字 数量 增加 而 没有 增加 肢体 的...  \n",
       "20                   后来 的 论文 直到 1992 年 公布 之后 才能 得到 论文  \n",
       "21  在 人类 犹太 内部 被 研究 成 一个 历史 的 文字 来 发现 它 如何 能 证明 实际...  \n",
       "22     在 加蓬 和 喀麦隆 举行 的 一个 宗教 仪式 是 由 一些 班图 民族 进行 的 奥 圭  \n",
       "23  在 这种 状态 中, 取决于 区域 的 区域, 被 尊重 的 音乐 人 所 发挥 的 鼓 或...  \n",
       "24  当 这种 类似 的 国家 被 见证 和 理解 时, 追随 者 被 了解 一种 思考 一种 方...  \n",
       "25  这 培养 了 将 这种 思想 所 产生 的 情感 与 他们 在 日常生活 中 的 情景 表现...  \n",
       "26  这种 分离 和 随后 对 纯 能源 或 情感 的 性质 和 来源 的 思考 有助于 参与者 ...  \n",
       "27  在 语言 中, 动 语 是 研究 如何 使用 舌 、 嘴 、 下 牙 、 声 带 和其他 语...  \n",
       "28                              声音 按 表达 方式 和 表达 地点 分类  \n",
       "29                 连接 的 地点 指 在 颈 或 口 中 空气 流 被 压缩 的 地点  \n",
       "30  表达 方式 指 语言 器官 互动 的 方式 例如 空气 如何 受 限制, 使用 了 何种 形...  \n",
       "31     脉 性 性 性 性 性 和 点击 ) 无论 声 带 是否 在 振 动, 是否 向 空气 开放  \n",
       "32         这个 概念 主要 用于 制作 调, 但 可以 用于 音 和 鼻 音 等 品质 的 元  \n",
       "33       对于 任何 的 表达 地 可能 有 几种 的 表达 方式 因此 有 几种 神圣 的 声音  \n",
       "34  正常 的 人类 讲话 是 肺 压力 产生 的, 这 在 喉 中 的 glottis 中 产生...  \n",
       "35  然而 人类 可以 在 犹太 语 中 不 使用 肺 和 glottis 的 语言 其中 有 三...  \n",
       "36        语音 制作 是 一项 复杂 的 活动, 结果 是 常见 的, 在 儿童 中 尤为 常见  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vital[\"wa_anno\"] = outputs_wa\n",
    "vital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at Helsinki-NLP/opus-mt-en-zh were not used when initializing TFMarianMTModel: ['final_logits_bias']\n",
      "- This IS expected if you are initializing TFMarianMTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFMarianMTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-zh.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在中国的绘画中,可以追溯到 唐朝画家王模( - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "{\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080}虽然他的绘画 {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080}但是 {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2\n",
      "{\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\\n",
      "{\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\\n",
      "{\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080}最后 {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080}\n",
      "他对生物生物机体的形态和形状的形成, - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "他用局部差异方程式 来模拟催化化学反应 {\\fn方正黑体简体\\fs18\\b1\\bord1\\shad1\\3cH2F2F2F} 化学反应 {\\fn方正黑体简体\\fs18\\b1\\bord1\\shad1\\3cH2F2F2F} {\\fn方正黑体简体\\fs18\\b1\\bord1\\shad1\\3cH2F2F2F} {\\fn方正黑体简体\\fs18\\b1\\bord1\\shad1\\3cH2F2F2F} {\\fn方正黑体\\fs18\\b1\\bord1\\shad\n",
      "举例说,如果某种化学反应需要催化剂 A,如果该反应产生更多的催化剂 A,那么,我们就说,该反应是自动催化的,而且,可以通过非线性差异方程来模拟积极的反馈。 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "Turing 发现,如果化学反应不仅产生催化剂A, 而且还产生抑制剂B, 减缓了A的生产, 就可能形成形态。...............................................\n",
      "如果 A 和 B 以 不同 的 速率 扩散 于 集装箱 中, 则 某些 区域, A 占主导地位, B 占主导地位, 某些 区域, B 占主导地位, 某些 区域 的, 你 也可以 分布..............................\n",
      "{\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080}图灵 {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080}但是 {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3cH808080} {\\fn黑体\\fs22\\bord1\\shad0\\3aHBE\\4aH00\\fscx67\\fscy66\\2cHFFFFFF\\3\n",
      "举例来说,这些计算得出了正确的质量结果, 产生了一种 奇异的 同一混合物 经常间距 固定的红点 。 - 红点 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "俄国生物化学家 鲍里斯 - 贝卢索夫 进行了 类似实验, 但由于 当代 的 偏见, 认为 任何 此类 事 都 违反了 热力 的 第二项 定律, 因而 无法 发表 论文............................... \n",
      "Belousov 并不知道图灵 的论文 皇家 {\\fn方正黑体简体\\fs18\\b1\\bord1\\shad1\\3cH2F2F2F} {\\fn方正黑体简体\\fs18\\b1\\bord1\\shad1\\3cH2F2F2F} {\\fn方正黑体简体\\fs18\\b1\\bord1\\shad1\\3cH2F2F2F} {\\fn方正黑体简体\\fs18\\b1\\bord1\\shad1\\3cH2F2F2F} {\\fn方正黑体\\fs18\\b1\\bord1\\shad1\\3cH\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-353-7c9121392596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvital\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtokenized_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'np'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_original\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtokenized_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_target_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/generation_tf_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, max_new_tokens, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, **model_kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_sample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m             return self._generate(\n\u001b[0m\u001b[1;32m    584\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                 \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/generation_tf_utils.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, input_ids, max_length, max_new_tokens, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, seed, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, **model_kwargs)\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m             \u001b[0;31m# 10. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1686\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1687\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m                 \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/generation_tf_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, max_length, pad_token_id, eos_token_id, length_penalty, early_stopping, logits_processor, num_return_sequences, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[1;32m   3001\u001b[0m         ):\n\u001b[1;32m   3002\u001b[0m             \u001b[0mmaximum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3003\u001b[0;31m             cur_len, running_sequences, running_scores, sequences, scores, is_sent_finished, _ = tf.while_loop(\n\u001b[0m\u001b[1;32m   3004\u001b[0m                 \u001b[0mbeam_search_cond_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3005\u001b[0m                 \u001b[0mbeam_search_body_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m   \"\"\"\n\u001b[0;32m-> 2507\u001b[0;31m   return while_loop(\n\u001b[0m\u001b[1;32m   2508\u001b[0m       \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m       \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2752\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2753\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2754\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2743\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2744\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2745\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2746\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/generation_tf_utils.py\u001b[0m in \u001b[0;36mbeam_search_body_fn\u001b[0;34m(cur_len, running_sequences, running_scores, sequences, scores, is_sent_finished, model_kwargs)\u001b[0m\n\u001b[1;32m   2824\u001b[0m                 \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2825\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_beam_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2826\u001b[0;31m             model_outputs = self(\n\u001b[0m\u001b[1;32m   2827\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m       \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/marian/modeling_tf_marian.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, decoder_position_ids, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[1;32m   1354\u001b[0m                 )\n\u001b[1;32m   1355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1357\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/marian/modeling_tf_marian.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, decoder_position_ids, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/marian/modeling_tf_marian.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, inputs_embeds, attention_mask, position_ids, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mpast_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m             hidden_states, layer_self_attn, layer_cross_attn, present_key_value = decoder_layer(\n\u001b[0m\u001b[1;32m   1032\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombined_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/marian/modeling_tf_marian.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, training)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# Fully Connected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/layers/core/dense.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m       \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   5122\u001b[0m     b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n\u001b[1;32m   5123\u001b[0m         b, b_axes, True)\n\u001b[0;32m-> 5124\u001b[0;31m     \u001b[0mab_matmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5126\u001b[0m       if (ab_matmul.get_shape().is_fully_defined() and\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3711\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[1;32m   3712\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3713\u001b[0;31m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[1;32m   3714\u001b[0m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[1;32m   3715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6011\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6012\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6013\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   6014\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6015\u001b[0m         transpose_b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "outputs_original = []\n",
    "\n",
    "model_original = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model_original.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "for input_sentence in vital[\"sentences\"]:\n",
    "    tokenized_sentence = tokenizer([input_sentence], return_tensors='np')\n",
    "    out = model_original.generate(**tokenized_sentence, max_length=128)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        output_sentence = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "        print(output_sentence)\n",
    "        outputs_original.append(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "vital.to_csv(\"translations_zh_models.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "fEL75VHb6Miv"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0524ec1e318841e39b54a61d250c6799": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65094228a62d4a14aa1ddc309546dbef",
      "max": 806435,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_583734d4fd3c43d6b5593a37f3561b52",
      "value": 806435
     }
    },
    "05d8367fa58a445cbcf860959d38f3e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0907f16279864bd48df6d4ec2b2b17cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_119301bd3069434cb2f2a2308536b096",
      "max": 1403,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_911f864acf124650a152b4db8245ee27",
      "value": 1403
     }
    },
    "0aafac33857a4c4ca7a6ee8abf32de8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d22e89479e947c888cc0505edcdad45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a0f8412de2b4c8b94cf9cd51827f40f",
      "placeholder": "​",
      "style": "IPY_MODEL_49894c5d38c54ee28d79cfaade6eb15e",
      "value": "Downloading: 100%"
     }
    },
    "0d2eabc03ac34121bab54748d92032c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e31cb1acb8f43c482707191555e53b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "102ffa5cc3774a2fa5c0da171bf8af88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5a2549f677e490fa4f22c8e82b8672b",
      "placeholder": "​",
      "style": "IPY_MODEL_5d77c0ac0e3643a7a314f86187fee512",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "119301bd3069434cb2f2a2308536b096": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12c4085c95a54102a9d79bba052d5a88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_846d5fa7a3234831b6ba846aee21a91c",
      "placeholder": "​",
      "style": "IPY_MODEL_c00b27a3745c459aae9e8a594665b572",
      "value": "100%"
     }
    },
    "12f5618901b04cc7a3367e412e4f525a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86733c8117da49658dd1e8d197759d3c",
      "max": 1617791,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e856733baf3434092ab5889cb30c6aa",
      "value": 1617791
     }
    },
    "14457006742049e29de9e2f9dd4af415": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1570b274a2fc44c3a40d0e34b02df66d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1625d5e0a9fc4f60913fa52c1c169c24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "182c9714756f4f919d8f370d7b674166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d22e89479e947c888cc0505edcdad45",
       "IPY_MODEL_12f5618901b04cc7a3367e412e4f525a",
       "IPY_MODEL_b8b146c4d0bc4117b432b33e932b9877"
      ],
      "layout": "IPY_MODEL_77022603cf7d4fbaa21ce3ca627293c7"
     }
    },
    "18368eb62d7c4ef2b6a5bc82e099dc97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "1a7fb058ad4e4974b7277c1c14be649c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2c85d14b6fb846459cef7759ca7d1468",
       "IPY_MODEL_0907f16279864bd48df6d4ec2b2b17cb",
       "IPY_MODEL_d26fefef32494d5da7b20f5cdcbef70f"
      ],
      "layout": "IPY_MODEL_86149699e693402caa772053da514b06"
     }
    },
    "1c9428203bcb44fbb306752e952caea8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1df11a486b9a4780ab54ff267d6dafc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20054fae2d9f4e42bb16950b192b4280",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1625d5e0a9fc4f60913fa52c1c169c24",
      "value": 1
     }
    },
    "1f9602dec6a8455cb0f25d6283e3a8a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20031c6fef51409f850dcba3b868a1bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70efe7b5094840b894ff61ccc6aed030",
      "max": 44,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a403937ec524de6b337665a78308fed",
      "value": 44
     }
    },
    "20054fae2d9f4e42bb16950b192b4280": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2061c2d630a34eba9870c21302be5016": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2222791718d74b89be49dc52a2c4df64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_5fd67795b114407b865e334d3e043fcb",
      "placeholder": "​",
      "style": "IPY_MODEL_931c89c5da334cb8b4ba35eb94658d11",
      "value": ""
     }
    },
    "2334406aa71d437093daf5c121b63af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2384f392f8544d27a8cf8af92d65b0b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "244c69abb61f4c11bdb55dc5866d1286": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25127df4fea7451281eca5d116a6b688": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_7d110c8373464d298702384b29dab14b",
      "style": "IPY_MODEL_d67e2ea73a9b4371adef225a84a3fd60",
      "tooltip": ""
     }
    },
    "25fd87d2ed6a4d9e8cd08425b3b7c45c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27284060931c496a9954d6678f0309c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2751ee9a4ae142a6b9e9f88166d8d390": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "286f168473df4744b41fe333ff06f5e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c6148ea304b457cb33674d77cc59c20",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b7664a7478f4d4a8d3680b9522ba48b",
      "value": 2
     }
    },
    "2aeb275a8ca14f42858e74ba42af6cb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_12c4085c95a54102a9d79bba052d5a88",
       "IPY_MODEL_286f168473df4744b41fe333ff06f5e9",
       "IPY_MODEL_c06c5377e71348ceab4ff26b14dd3557"
      ],
      "layout": "IPY_MODEL_1c9428203bcb44fbb306752e952caea8"
     }
    },
    "2c6148ea304b457cb33674d77cc59c20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c85d14b6fb846459cef7759ca7d1468": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d2eabc03ac34121bab54748d92032c5",
      "placeholder": "​",
      "style": "IPY_MODEL_7e8117c102274c9c8aaa86c918d5dd00",
      "value": "Downloading: 100%"
     }
    },
    "31678423b14b49aebdc272486ee932f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cad5b2ae2df40f3afd14437ee69c072",
      "placeholder": "​",
      "style": "IPY_MODEL_05d8367fa58a445cbcf860959d38f3e8",
      "value": "  0%"
     }
    },
    "33cad270c9b841d9a7af9e38b03f4f07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "378758016fc046c3883547505c883423": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "393f9c7c91304cba8852591f362a8a6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_31678423b14b49aebdc272486ee932f7",
       "IPY_MODEL_68fa49d7de8e4324bb8aceb6d37467d7",
       "IPY_MODEL_82d58697108546e697ef92413ecfeeab"
      ],
      "layout": "IPY_MODEL_25fd87d2ed6a4d9e8cd08425b3b7c45c"
     }
    },
    "3cad5b2ae2df40f3afd14437ee69c072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3dbf9ae2ad01407eb6d1f35f34ea31ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96eb996b9c804b9e9b8c6dc771792502",
      "placeholder": "​",
      "style": "IPY_MODEL_5692edda5470493799ae37277e968324",
      "value": "Downloading: 100%"
     }
    },
    "4056f31f319e4698977fbe02563f496b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44536a7805524265baf7bd3f9c857fa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f54c4a3f69db492383df94b59bdeadeb",
      "max": 312580600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c41570b336a4324840e6088d85d0a38",
      "value": 312580600
     }
    },
    "4589337588fd46deb82448cb5cddd114": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c684be315e9242b28213fd230c9de3ff",
      "placeholder": "​",
      "style": "IPY_MODEL_2334406aa71d437093daf5c121b63af9",
      "value": "Downloading: 100%"
     }
    },
    "4662851903844f9496171c2a83834605": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49894c5d38c54ee28d79cfaade6eb15e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ee97aed9b70428088829aa7b00b2f87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd046fa7a6154fda951901d2ca822f64",
      "max": 804600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2384f392f8544d27a8cf8af92d65b0b0",
      "value": 804600
     }
    },
    "52e4234c6adb42f09fd24bd4eeee1a2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53738098bfd6457caf45ddad9568e6c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5638df0c4eab47faa3dea137e63e302f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5692edda5470493799ae37277e968324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "583734d4fd3c43d6b5593a37f3561b52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5998028d41aa4031ab11850e1c8babba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a79ae84164049d39a9e3fc7cae0a8fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_ef6f751742c54800a465c41186f3f623",
      "style": "IPY_MODEL_6cb3ed3091ea46f6a08a03b9e91e6a46",
      "value": true
     }
    },
    "5d77c0ac0e3643a7a314f86187fee512": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e12fd7723794148b373dba092aea7cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fd67795b114407b865e334d3e043fcb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61846cdcb60b46d5b8221fcb702f40b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65094228a62d4a14aa1ddc309546dbef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68fa49d7de8e4324bb8aceb6d37467d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8106395016d34529bd2ea946421fd266",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2061c2d630a34eba9870c21302be5016",
      "value": 0
     }
    },
    "6b7664a7478f4d4a8d3680b9522ba48b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c41570b336a4324840e6088d85d0a38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6cb3ed3091ea46f6a08a03b9e91e6a46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70efe7b5094840b894ff61ccc6aed030": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72b1cd9045d244a487667e763d97c769": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "749e363a49a948788eb5f8c896084ff7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea3708c0edd1467596d1d173019ef1bc",
      "max": 8146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c1a5d057f6834c7191daceb38167d195",
      "value": 8146
     }
    },
    "77022603cf7d4fbaa21ce3ca627293c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a403937ec524de6b337665a78308fed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7d110c8373464d298702384b29dab14b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d81df6aca764daaaae0a123a2ab4ce1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e8117c102274c9c8aaa86c918d5dd00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7eb53ddfd0f9484883016e0f4831bb59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8106395016d34529bd2ea946421fd266": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82d58697108546e697ef92413ecfeeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8134e8f7af74efdb7ed9fc21670ce02",
      "placeholder": "​",
      "style": "IPY_MODEL_0aafac33857a4c4ca7a6ee8abf32de8b",
      "value": " 0/2 [00:00&lt;?, ?ba/s]"
     }
    },
    "846d5fa7a3234831b6ba846aee21a91c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84a1e68713764068a1cf98a2cbbeb21b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86149699e693402caa772053da514b06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86733c8117da49658dd1e8d197759d3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a0f8412de2b4c8b94cf9cd51827f40f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b8f7eb8638342d9a41fadd370192be2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e856733baf3434092ab5889cb30c6aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f99fbcd296c41f492c2383564e7a2d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "911f864acf124650a152b4db8245ee27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "931c89c5da334cb8b4ba35eb94658d11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93a91d53b4c34de5946fe08ab92d2783": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94bbd725b159412fb7a28d861ca7dc51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52e4234c6adb42f09fd24bd4eeee1a2d",
      "placeholder": "​",
      "style": "IPY_MODEL_84a1e68713764068a1cf98a2cbbeb21b",
      "value": "100%"
     }
    },
    "94e601c51f9e44ec8a5b99939eefbb7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72b1cd9045d244a487667e763d97c769",
      "placeholder": "​",
      "style": "IPY_MODEL_61846cdcb60b46d5b8221fcb702f40b6",
      "value": " 805k/805k [00:00&lt;00:00, 2.92MB/s]"
     }
    },
    "96eb996b9c804b9e9b8c6dc771792502": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97232d895f1d43be90ee49446a790e9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4589337588fd46deb82448cb5cddd114",
       "IPY_MODEL_44536a7805524265baf7bd3f9c857fa8",
       "IPY_MODEL_fd4ae36b9f4b44bca4e51281b12347f3"
      ],
      "layout": "IPY_MODEL_994899e2f5b740298b2d0852c7906914"
     }
    },
    "994899e2f5b740298b2d0852c7906914": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c9a34cc8ee14c8e85c3d0a584ec2b5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94bbd725b159412fb7a28d861ca7dc51",
       "IPY_MODEL_1df11a486b9a4780ab54ff267d6dafc3",
       "IPY_MODEL_de993462f296433e938eed9c6fd397fe"
      ],
      "layout": "IPY_MODEL_14457006742049e29de9e2f9dd4af415"
     }
    },
    "9e3c8c0436ca4391b13f412feb98482f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3dbf9ae2ad01407eb6d1f35f34ea31ec",
       "IPY_MODEL_0524ec1e318841e39b54a61d250c6799",
       "IPY_MODEL_c561eef4836b4255a4eb960ecba6b0a5"
      ],
      "layout": "IPY_MODEL_c9d4d468062b42f8a0aacaa4657667bf"
     }
    },
    "a101d5cf6b0249049e24c8a9b16d896f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a8134e8f7af74efdb7ed9fc21670ce02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a83a452b4afe49e7b8e17e8d9fd63485": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f99fbcd296c41f492c2383564e7a2d4",
      "placeholder": "​",
      "style": "IPY_MODEL_7eb53ddfd0f9484883016e0f4831bb59",
      "value": "Downloading: 100%"
     }
    },
    "ad13f142a3034624aecd0fa85db427c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e218550fb85f4b52b05e7058b8817449",
       "IPY_MODEL_2222791718d74b89be49dc52a2c4df64",
       "IPY_MODEL_5a79ae84164049d39a9e3fc7cae0a8fc",
       "IPY_MODEL_25127df4fea7451281eca5d116a6b688",
       "IPY_MODEL_102ffa5cc3774a2fa5c0da171bf8af88"
      ],
      "layout": "IPY_MODEL_18368eb62d7c4ef2b6a5bc82e099dc97"
     }
    },
    "b27b4221f5894332b994483261006b16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b516939c6dfc4fde929473a552ff3b5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b660541fd76f491db348829f3b5135c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6683e918c0e430c984fad9adb81b033": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a83a452b4afe49e7b8e17e8d9fd63485",
       "IPY_MODEL_4ee97aed9b70428088829aa7b00b2f87",
       "IPY_MODEL_94e601c51f9e44ec8a5b99939eefbb7f"
      ],
      "layout": "IPY_MODEL_8b8f7eb8638342d9a41fadd370192be2"
     }
    },
    "b8b146c4d0bc4117b432b33e932b9877": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4662851903844f9496171c2a83834605",
      "placeholder": "​",
      "style": "IPY_MODEL_33cad270c9b841d9a7af9e38b03f4f07",
      "value": " 1.62M/1.62M [00:00&lt;00:00, 5.89MB/s]"
     }
    },
    "baf79d06246d423f9fab5abf179a1a7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c00b27a3745c459aae9e8a594665b572": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c06c5377e71348ceab4ff26b14dd3557": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f134d321d064438e85cb619e6986ab4b",
      "placeholder": "​",
      "style": "IPY_MODEL_5638df0c4eab47faa3dea137e63e302f",
      "value": " 2/2 [00:01&lt;00:00,  2.09ba/s]"
     }
    },
    "c1a5d057f6834c7191daceb38167d195": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c561eef4836b4255a4eb960ecba6b0a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5998028d41aa4031ab11850e1c8babba",
      "placeholder": "​",
      "style": "IPY_MODEL_a101d5cf6b0249049e24c8a9b16d896f",
      "value": " 806k/806k [00:00&lt;00:00, 4.56MB/s]"
     }
    },
    "c684be315e9242b28213fd230c9de3ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6af1206fb0e4f0292a2584fcb87d030": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c90d886a7ff84c9c8e4a9a18a83b8441": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9d4d468062b42f8a0aacaa4657667bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d26fefef32494d5da7b20f5cdcbef70f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2751ee9a4ae142a6b9e9f88166d8d390",
      "placeholder": "​",
      "style": "IPY_MODEL_1570b274a2fc44c3a40d0e34b02df66d",
      "value": " 1.40k/1.40k [00:00&lt;00:00, 14.1kB/s]"
     }
    },
    "d67e2ea73a9b4371adef225a84a3fd60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "d9894f8558424c6bb6b1dcb726e33c2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_baf79d06246d423f9fab5abf179a1a7e",
      "placeholder": "​",
      "style": "IPY_MODEL_7d81df6aca764daaaae0a123a2ab4ce1",
      "value": " 8.15k/8.15k [00:00&lt;00:00, 5.25kB/s]"
     }
    },
    "dd046fa7a6154fda951901d2ca822f64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de993462f296433e938eed9c6fd397fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e12fd7723794148b373dba092aea7cd",
      "placeholder": "​",
      "style": "IPY_MODEL_c6af1206fb0e4f0292a2584fcb87d030",
      "value": " 1/1 [00:00&lt;00:00,  2.75ba/s]"
     }
    },
    "df17515c40504961b7e1b3e807c1e86d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53738098bfd6457caf45ddad9568e6c0",
      "placeholder": "​",
      "style": "IPY_MODEL_b27b4221f5894332b994483261006b16",
      "value": "Downloading: 100%"
     }
    },
    "e1577b81df0949228560afb795b43f92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27284060931c496a9954d6678f0309c8",
      "placeholder": "​",
      "style": "IPY_MODEL_93a91d53b4c34de5946fe08ab92d2783",
      "value": "Downloading builder script: 100%"
     }
    },
    "e218550fb85f4b52b05e7058b8817449": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b660541fd76f491db348829f3b5135c9",
      "placeholder": "​",
      "style": "IPY_MODEL_c90d886a7ff84c9c8e4a9a18a83b8441",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "e569b660e9ef4533b48460b6360e6874": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df17515c40504961b7e1b3e807c1e86d",
       "IPY_MODEL_20031c6fef51409f850dcba3b868a1bc",
       "IPY_MODEL_ec27ccf1d1fd419e969a3c10b25232b6"
      ],
      "layout": "IPY_MODEL_378758016fc046c3883547505c883423"
     }
    },
    "ea3708c0edd1467596d1d173019ef1bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec27ccf1d1fd419e969a3c10b25232b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4056f31f319e4698977fbe02563f496b",
      "placeholder": "​",
      "style": "IPY_MODEL_0e31cb1acb8f43c482707191555e53b6",
      "value": " 44.0/44.0 [00:00&lt;00:00, 453B/s]"
     }
    },
    "ef6f751742c54800a465c41186f3f623": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f134d321d064438e85cb619e6986ab4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2ea9af3be8e41039ca9a7bd896c5a5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e1577b81df0949228560afb795b43f92",
       "IPY_MODEL_749e363a49a948788eb5f8c896084ff7",
       "IPY_MODEL_d9894f8558424c6bb6b1dcb726e33c2d"
      ],
      "layout": "IPY_MODEL_244c69abb61f4c11bdb55dc5866d1286"
     }
    },
    "f54c4a3f69db492383df94b59bdeadeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5a2549f677e490fa4f22c8e82b8672b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd4ae36b9f4b44bca4e51281b12347f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b516939c6dfc4fde929473a552ff3b5f",
      "placeholder": "​",
      "style": "IPY_MODEL_1f9602dec6a8455cb0f25d6283e3a8a4",
      "value": " 313M/313M [00:08&lt;00:00, 42.0MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
