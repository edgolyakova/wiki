人工智能
目录
概论
发展史
研究课题
强人工智能和弱人工智能
研究方法
基本应用
实际应用
学科范畴
电视剧
应用领域
滥用
相关
参看
参见
参考文献
扩展阅读
外部连结
导航菜单
演绎、推理和解决问题
知识表示法
规划
学习
自然语言处理
运动和控制
知觉
社交
创造力
伦理管理
经济冲击
AI对人类的威胁
AI与管理
强人工智能
弱人工智能
对强人工智能的哲学争论
控制论与大脑模拟
符号处理
子符号方法
统计学方法
集成方法
感知能力（Perception）
认知能力（Cognition）
创造力（Creativity）
智慧（Wisdom）
涉及学科
研究范畴
引用
来源
个人工具
命名空间
查看
搜索
导航
帮助
工具
打印/导出
在其他项目中
其他语言
悲观学派
乐观学派
人工智能（英语：artificial intelligence，缩写为AI）亦称智械、机器智能，指由人制造出来的机器所表现出来的智慧。
通常人工智能是指通过普通电脑程式来呈现人类智能的技术。
该词也指出研究这样的智能系统是否能够实现，以及如何实现。
同时，通过医学、神经科学、机器人学及统计学等的进步，常态预测则认为人类的很多职业也逐渐被其取代。
人工智能于一般教材中的定义领域是“智慧主体（intelligent agent）的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。
约翰·麦卡锡于1955年的定义是「制造智能机器的科学与工程」。
安德烈亚斯·卡普兰（Andreas Kaplan）和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。
 人工智能可以定义为模仿人类与人类思维相关的认知功能的机器或计算机，如学习和解决问题。
人工智能是计算机科学的一个分支，它感知其环境并采取行动，最大限度地提高其成功机会。
此外，人工智能能够从过去的经验中学习，做出合理的决策，并快速回应。
因此，人工智能研究人员的科学目标是通过构建具有象征意义的推理或推理的计算机程式来理解智慧。
人工智能的四个主要组成部分是：
人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及范围极广。
人工智能的研究可以分为几个技术问题。
其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。
AI的核心问题包括建构能够跟人类似甚至超卓的推理、知识、规划、学习、交流、感知、移物、使用工具和操控机械的能力等。
人工智能目前仍然是该领域的长远目标。
目前弱人工智慧已经有初步成果，甚至在一些影像辨识、语言分析、棋类游戏等等单方面的能力达到了超越人类的水平，而且人工智慧的通用性代表着，能解决上述的问题的是一样的AI程式，无须重新开发算法就可以直接使用现有的AI完成任务，与人类的处理能力相同，但达到具备思考能力的统合强人工智慧还需要时间研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。
目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。
而基于仿生学、认知心理学，以及基于概率论和经济学的演算法等等也在逐步探索当中。
人工智能的定义可以分为两部分，即「人工」和「智能」。
「人工」即由人设计，为人创造、制造。
关于什么是「智能」，较有争议性。
这涉及到其它诸如意识、自我、心灵，包括无意识的精神等等问题。
人唯一了解的智能是人本身的智能，这是普遍认同的观点。
但是我们对我们自身智能的理解都非常有限，对构成人的智能必要元素的了解也很有限，所以就很难定义什么是「人工」制造的「智能」。
因此人工智能的研究往往涉及对人智能本身的研究。
其它关于动物或其它人造系统的智能也普遍被认为是人工智能相关的研究课题。
人工智慧目前在电脑领域内，得到了愈加广泛的发挥。
并在机器人、经济政治决策、控制系统、仿真系统中得到应用。
目前人工智慧的研究方向已经被分成几个子领域，研究人员希望一个人工智慧系统应该具有某些特定能力，以下将这些能力列出并说明。
早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。
到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。
对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。
寻找更有效的演算法是优先的人工智慧研究项目。
人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。
人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。
神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。
知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。
有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。
事先存储的先验知识指：人类通过某种方式告诉给机器的知识。
通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。
首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。
比如：今天没有太阳，没有太阳就是阴天。
那么以命题逻辑语言，这些知识可以被表示为：今天-->没有太阳， 没有太阳-->阴天。
这些知识是先验知识，那么通过推理可以得到新知识：今天-->阴天。
由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。
另外如果人工智慧能看出太阳，除了该如何判断的这件问题，在这个前提之下，应该也能判断出阴天与晴天的差异。
逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。
可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。
目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。
智能Agent必须能够制定目标和实现这些目标。
他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。
在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。
但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。
如果不符合，它必须改变它的计划。
因此智能代理必须具有在不确定结果的状态下推理的能力。
在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。
机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。
这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。
对于人工智能来说，机器学习从一开始就很重要。
1956年，在最初的达特茅斯夏季会议上，雷蒙德·索洛莫诺夫[来源请求]写了一篇关于不监视的概率性机器学习：一个归纳推理的机器。
机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。
监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。
监督学习根据输出结果的离散性和连续性，分为分类和回归两类。
非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。
无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。
自然语言处理探讨如何处理及运用自然语言，自然语言认知则是指让电脑「懂」人类的语言。
自然语言生成系统把计算机数据转化为自然语言。
自然语言理解系统把自然语言转化为计算机程序更易于处理的形式。
机器感知是指能够使用感测器所输入的资料（如照相机、麦克风、声纳以及其他的特殊感测器）然后推断世界的状态。
电脑视觉能够分析影像输入。
另外还有语音识别、人脸辨识和物体辨识。
情感和社交技能对于一个智能agent是很重要的。
首先，通过了解他们的动机和情感状态，代理人能够预测别人的行动（这涉及要素 博弈论、决策理论以及能够塑造人的情感和情绪感知能力检测）。
此外，为了良好的人机互动，智慧代理人也需要表现出情绪来。
至少它必须出现礼貌地和人类打交道。
至少，它本身应该有正常的情绪。
一个人工智慧的子领域，代表了理论（从哲学和心理学的角度）和实际（通过特定的实现产生的系统的输出是可以考虑的创意，或系统识别和评估创造力）所定义的创造力。
相关领域的研究包括了人工直觉和人工想像。
史蒂芬·霍金、比尔盖兹、马斯克、 Jaan Tallinn 以及 Nick Bostrom 等人都对于人工智慧技术的未来公开表示忧心，人工智慧若在许多方面超越人类智慧水平的智能、不断更新、自我提升，进而取得控制管理权，人类是否有足够的能力及时停止人工智慧领域的「军备竞赛」，能否保有最高掌控权，现有事实是：机器常失控导致人员伤亡，这样的情况是否会更加扩大规模出现，历史显然无法给出可靠的乐观答案。
特斯拉电动车马斯克（Elon Musk）在麻省理工学院（MIT）航空航天部门百年纪念研讨会上称人工智能是「召唤恶魔」行为，英国发明家Clive Sinclair认为一旦开始制造抵抗人类和超越人类的智能机器，人类可能很难生存，盖兹同意马斯克和其它人所言，且不知道为何有些人不担忧这个问题。
DeepMind的人工智慧（AI）系统在2016年「AlphaGo」对战南韩棋王李世乭获胜，开发商表示在内部设立伦理委员会，针对人工智慧的应用制定政策，防范人工智慧沦为犯罪开发者。
科技进步，人工智慧科技产生「自主武器」军备竞赛已悄悄展开，英国、以色列与挪威，都已部署自主飞弹与无人操控的无人机，具「射后不理」（fire-and-forget）能力的飞弹，多枚飞弹还可互相沟通，分享找到攻击目标。
这些武器还未被大量投入，但很快就会出现在战场上，且并非使用人类所设计的程序，而是完全利用机器自行决策。
 霍金等人在英国独立报发表文章警告未来人工智慧可能会比人类金融市场、科学家、人类领袖更能操纵人心、甚至研发出人们无法理解的武器。
专家恐发展到无法控制的局面，援引联合国禁止研发某些特定武器的「特定常规武器公约」加以限制。
新南威尔斯大学人工智慧的沃尔什（Toby Walsh）教授认为这是一种欺骗，因为机器无区别战敌和平民的技术。
据CNN财经网数字媒体未来学家兼Webbmedia集团创始人艾米·韦伯（Amy Webb）；美国在线...等纷纷预测一些即将被机器人取代的职业，日本野村总合研究所也与英国牛津大学的研究学者共同调查指出，10至20年后，日本有49%的职业(235种职业)可能会被机械和人工智慧取代而消失，直接影响约达2500万人，例如：超市店员、一般事务员、计程车司机、收费站运营商和收银员、市场营销人员、客服人员、制造业工人、金融中间人和分析师、新闻记者、电话公司职员、麻醉师、士兵和保安、律师、医生、软体开发者和操盘手、股票交易员等等高薪酬的脑力职业将最先受到冲击。
2017年6月份马云在美国底特律举行「链结世界」（Gateway 17）产业大会，会上提出人工智慧可能导致第三次世界大战，因为前两次产业革命都导致两次大战，战争原因并非这些创新发明本身，而是发明对社会上许多人的生活方式冲击处理不当，新科技在社会上产生新工作也取代旧工作，产生了新的输家和赢家，若是输家的人数太多将造成一股社会不稳的能量而这股能量被有心人利用可能导致各种事件。
他认为各国应该强制订定规定AI机器只能用于人类不能做的工作，避免短时间大量人类被取代的失业大潮，但马云没有提出这种世界性规定将如何实现并确保遵守的细节方案。
数据科学和人工智能被哈佛商业评论称为《二十一世纪最Sexy的职业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。
硅谷和纽约为主的《The Data Incubator（英语：The Data Incubator）》公司于2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。
此议题目前分成两个学派：
此学派的代表是天文物理学家史蒂芬·霍金(Stephen Hawking)，以及特斯拉执行长伊隆·马斯克(Elon Musk)。
霍金认为AI对人类将来有很大的威胁，主要有以下理由：
主要是Google、Facebook等AI的主要技术发展者，他们对AI持乐观看法的理由：
AI逐渐普及后，将会在企业管理中扮演很重要的角色，而人类的管理者应如何适度的调整自己的工作职能，有以下几点建议：
人工智能的一个比较流行的定义，也是该领域较早的定义，是由当时麻省理工学院的约翰·麦卡锡在1956年的达特矛斯会议上提出的：人工智能就是要让机器的行为看起来就像是人所表现出的智能行为一样。
但是这个定义似乎忽略了强人工智能的可能性（见下）。
另一个定义指人工智能是人造机器所表现出来的智能。
总体来讲，目前对人工智能的定义大多可划分为四类，即机器「像人一样思考」、「像人一样行动」、「理性地思考」和「理性地行动」。
这里「行动」应广义地理解为采取行动，或制定行动的决策，而不是肢体动作。
强人工智能观点认为「有可能」制造出「真正」能推理和解决问题的智能机器，并且，这样的机器将被认为是具有知觉、有自我意识的。
强人工智能可以有两类：
弱人工智能观点认为「不可能」制造出能「真正」地推理和解决问题的智能机器，这些机器只不过「看起来」像是智能的，但是并不真正拥有智能，也不会有自主意识。
弱人工智能是对比强人工智能才出现的，因为人工智能的研究一度处于停滞不前的状态下，直到类神经网路有了强大的运算能力加以模拟后，才开始改变并大幅超前。
但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解强人工智能和弱人工智能的内容与差别，对定义争论不休。
就当下的人工智能研究领域来看，研究者已大量造出「看起来」像是智能的机器，取得相当丰硕的理论上和实质上的成果，如2009年康乃尔大学教授Hod Lipson 和其博士研究生Michael Schmidt 研发出的 Eureqa电脑程式，只要给予一些资料，这电脑程式自己只用几十个小时计算就推论出牛顿花费多年研究才发现的牛顿力学公式，等于只用几十个小时就自己重新发现牛顿力学公式，这电脑程式也能用来研究很多其他领域的科学问题上。
这些所谓的弱人工智慧在神经网路发展下已经有巨大进步，但对于要如何整合成强人工智慧，现在还没有明确定论。
主条目：人工智能哲学、图灵测试、物理符号系统、皇帝新脑、德雷福斯对人工智能的看法（英语：Hubert Dreyfus's views on artificial intelligence）、AI效应（英语：AI effect）
「强人工智能」一词最初是约翰·罗杰斯·希尔勒针对电脑和其它信息处理机器创造的，其定义为：
「强人工智能观点认为计算机不仅是用来研究人的思维的一种工具；相反，只要运行适当的程序，计算机本身就是有思维的。
」（J Searle in Minds Brains and Programs.
The Behavioral and Brain Sciences, vol. 3, 1980）
关于强人工智能的争论，不同于更广义的一元论和二元论的争论。
其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？希尔勒认为这是不可能的。
他举了个中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。
基于这一论点，希尔勒认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有自我思维和自由意识。
也有哲学家持不同的观点。
丹尼尔·丹尼特在其着作《意识的解释（英语：Consciousness Explained）》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：「人可以有智能，而普通机器就不能」呢？他认为像上述的数据转换机器是有可能有思维和意识的。
有的哲学家认为如果弱人工智能是可实现的，那么强人工智能也是可实现的。
比如西蒙·布莱克本（英语：Simon Blackburn）（Simon Blackburn）在其哲学入门教材Think里说道，一个人的看起来是「智能」的行动并不能真正说明这个人就真的是智能的。
我永远不可能知道另一个人是否真的像我一样是智能的，还是说她／他仅仅是「看起来」是智能的。
基于这个论点，既然弱人工智能认为可以令机器「看起来」像是智能的，那就不能完全否定这机器是真的有智能的。
布莱克本认为这是一个主观认定的问题。
需要指出的是，弱人工智能并非和强人工智能完全对立，也就是说，即使强人工智能是可能的，弱人工智能仍然是有意义的。
至少，今日的计算机能做的事，像算术运算等，在一百多年前是被认为很需要智能的。
并且，即使强人工智能被证明为可能的，也不代表强人工智能必定能被研制出来。
目前没有统一的原理或范式指导人工智能研究。
许多问题上研究者都存在争论。
其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？
智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？
约翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence（英语：synthetic intelligence），这个概念后来被某些非GOFAI研究者采纳。
20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。
其中还造出一些使用电子网络构造的初步智能，如格雷·华特（W. Grey Walter）的乌龟（turtle）和约翰霍普金斯野兽。
这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。
直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。
当20世纪50年代，数位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。
研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工学院，而各自有独立的研究风格。
约翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。
60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。
基于控制论或神经网络的方法则置于次要。
60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。
1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。
很多研究者开始关注子符号方法解决特定的人工智能问题。
1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。
这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。
共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。
Stuart J. Russell和Peter Norvi指出这些进步不亚于“革命”和“neats的成功”。
有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。
人工智慧基本的应用可分为四大部分：
指的是人类透过感官所收到环境的刺激，察觉讯息的能力，简单的说就是人类五官的看、听、说、读、写等能力，学习人类的感知能力是AI目前主要的焦点之一，包括：
指的是人类透过学习、判断、分析等等心理活动来了解讯息、获取知识的过程与能力，对人类认知的模仿与学习也是目前AI第二个焦点领域，主要包括：
指的是人类产生新思想，新发现，新方法，新理论，新设计，创造新事物的能力，它是结合知识、智力、能力、个性及潜意识等各种因素优化而成，这个领域目前人类仍遥遥领先AI，但AI也试着急起直追，主要领域包括：AI作曲、AI作诗、AI小说、AI绘画、AI设计等。
指的是人类深刻了解人、事、物的真相，能探求真实真理、明辨是非，指导人类可以过着有意义生活的一种能力，这个领域牵涉人类自我意识、自我认知与价值观，是目前AI尚未触及的一部分，也是人类最难以模仿的一个领域。
机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、无人载具等。
人工智能是一门边缘学科，属于自然科学和社会科学的交叉。
2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。
随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。
据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。
截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。
而恶用该技术则可能涉嫌违反《着作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。
