Atome
Structure
Classification
Propriétés
Formation et évolution des atomes
Histoire du concept d'atome
Historique des modèles de l'atome
Noyau atomique
Notation
Notes et références
Voir aussi
Ordres de grandeur
Particules subatomiques
Nuage électronique
Noyau atomique
Noyaux atomiques
Nuage électronique
Nucléosynthèse
Sur Terre
Atomes de Rydberg
Formes atomiques rares ou hypothétiques
Antiquité : un concept philosophique
La chimie du XVIIIe siècle — les éléments
La physique du XVIIIe siècle — les particules
XIXe siècle — le triomphe de l'atome
Bilan
Modèles obsolètes
Modèles approchés couramment employés
Modèle actuel : modèle de Schrödinger
Notes
Références
Bibliographie
Filmographie
Articles connexes
Liens externes
Introduction au modèle de Schrödinger
Principe d'exclusion de Pauli
Orbitales moléculaires
Moment magnétique nucléaire
Énergie de liaison nucléaire
Stabilité nucléaire
Radioactivité
Îlot de stabilité
Limite à la taille des noyaux
Taille des atomes
Liaisons chimiques
Électronégativité et affinité électronique
Magnétisme
Fluorescence et phosphorescence
Raies spectrales
États de la matière
Modèle de J.J. Thomson ou modèle de l'électron élastiquement lié à l'atome
Modèle planétaire de Rutherford
Modèle des sphères dures
Modèle de Bohr
Pages pour les contributeurs déconnectés en savoir plus
Sommaire
				déplacer vers la barre latérale
masquer

Pour les articles homonymes, voir Atome (homonymie).
Un atome (grec ancien ἄτομος [átomos], « insécable »)[1] est la plus petite partie d'un corps simple pouvant se combiner chimiquement avec un autre. Les atomes sont les constituants élémentaires de toutes les substances solides, liquides ou gazeuses. Les propriétés physiques et chimiques de ces substances sont déterminées par les atomes qui les constituent ainsi que par l'arrangement tridimensionnel de ces atomes.
Contrairement à ce que leur étymologie suggère, les atomes ne sont pas indivisibles, mais sont constitués de particules subatomiques[2]. Ils comprennent un noyau, qui concentre plus de 99,9 % de leur masse, autour duquel se distribuent des électrons, qui forment un nuage 10 000 à 100 000 fois plus étendu que le noyau lui-même[3],[4], de sorte que le volume d'un atome, grossièrement sphérique, est presque entièrement vide. Le noyau est formé de protons, porteurs d'une charge électrique positive, et de neutrons, électriquement neutres ; l'hydrogène fait exception, car le noyau de son isotope 1H ne contient aucun neutron. Les protons et neutrons, également appelés nucléons, sont maintenus ensemble dans le noyau par la liaison nucléaire, qui est une manifestation de l'interaction forte. Les électrons occupent des orbitales atomiques en interaction avec le noyau via la force électromagnétique. Le nuage électronique est stratifié en niveaux d'énergie quantifiés autour du noyau, niveaux qui définissent des couches et des sous-couches électroniques ; les nucléons se distribuent également selon des couches nucléaires, bien qu'un modèle approché assez commode popularise la structure nucléaire d'après le modèle de la goutte liquide.
Plusieurs atomes peuvent établir des liaisons chimiques entre eux grâce à leurs électrons. D'une manière générale, les propriétés chimiques des atomes sont déterminées par leur configuration électronique, laquelle découle du nombre de protons de leur noyau. Ce nombre, appelé numéro atomique, définit un élément chimique. 118 éléments chimiques sont reconnus par l'Union internationale de chimie pure et appliquée (IUPAC) depuis le 18 novembre 2016. Les atomes d'éléments différents ont des tailles différentes, ainsi généralement que des masses différentes, bien que les atomes d'un élément chimique donné puissent avoir des masses différentes selon les isotopes considérés. Les atomes les plus lourds, ou dont le noyau présente un déséquilibre trop important entre les deux types de nucléons, tendent à devenir plus instables, et sont alors radioactifs ; le plomb 208 est l'isotope stable le plus lourd.
La théorie atomiste, qui soutient l'idée d'une matière composée de « grains » indivisibles (contre l'idée d'une matière indéfiniment sécable), est connue depuis l'Antiquité, et a été notamment défendue par Leucippe et son disciple Démocrite, philosophes de la Grèce antique, ainsi qu'en Inde, plus antérieurement, par l'une des six écoles de philosophie hindoue, le vaisheshika, fondé par Kanada. Elle fut disputée jusqu'à la fin du XIXe siècle et n'a plus été remise en cause depuis lors. L'observation directe d'atomes n'est devenue possible qu'au milieu du XXe siècle avec la microscopie électronique en transmission et l'invention du microscope à effet tunnel. C'est ainsi sur les propriétés des atomes que reposent toutes les sciences des matériaux modernes, tandis que l'élucidation de la nature et de la structure des atomes a contribué de manière décisive au développement de la physique moderne, et notamment de la mécanique quantique.
Le diamètre estimé d'un atome « libre » (hors liaison covalente ou cristalline) est compris entre 62 pm (6,2 × 10−11 m) pour l'hélium et 596 pm (5,96 × 10−10 m) pour le césium[5], tandis que celui d'un noyau atomique est compris entre 2,4 fm (2,4 × 10−15 m) pour l'isotope 1H et 14,8 fm (1,48 × 10−14 m) environ pour le nucléide 238U[6] : le noyau d'un atome d'hydrogène est donc environ 40 000 fois plus petit que l'atome d'hydrogène lui-même.
Le noyau concentre cependant l'essentiel de la masse de l'atome[a] : le noyau du lithium 7, par exemple, est environ 4 300 fois plus massif que les trois électrons qui l'entourent, l'atome de 7Li ayant une masse de l'ordre de 1,172 × 10−26 kg. Pour fixer les idées, la masse des atomes est comprise entre 1,674 × 10−27 kg pour le protium et 3,953 × 10−25 kg pour l'uranium 238, en s'en tenant aux isotopes qui ont une abondance significative dans le milieu naturel — il existe des noyaux plus lourds mais aussi bien plus instables que le nucléide 238U.
Cette masse est généralement exprimée en unités de masse atomique (« uma », ou « u »), définie comme la douzième partie de la masse d'un atome de 12C non lié, immobile et à son état fondamental, soit 1 uma = 1,660 54 × 10−27 kg ; dans cette unité, la masse du nucléide 238U vaut 238,050 782 6 uma. Une unité alternative également très employée en physique des particules est l'électron-volt divisé par le carré de la vitesse de la lumière (eV/c2), qui est homogène à une masse en vertu de la fameuse équation E = mc2 de la relativité restreinte, et qui vaut 1 eV/c2 = 1,783 × 10−36 kg ; dans cette unité, la masse du noyau 238U est égale à 221,7 GeV/c2.
Compte tenu de leur taille et de leur masse singulièrement réduites, les atomes sont toujours en très grand nombre dès qu'on manipule une quantité de matière macroscopique. On définit ainsi la mole comme étant la quantité de matière constituée par autant d'unités élémentaires (atomes, molécules, électrons, etc.) qu'il y a d'atomes dans 12 g de carbone 12, soit pas moins de 6,022 × 1023 unités élémentaires, ce qu'on appelle le nombre d'Avogadro.
Bien que son étymologie signifie « indivisible » en grec ancien, un atome est en réalité constitué de particules élémentaires plus petites, et peut donc être divisé ; mais il constitue bien la plus petite unité indivisible d'un élément chimique en tant que tel : en brisant, par exemple, un atome d'hélium, on obtiendra des électrons, des protons et des neutrons, mais on n'aura plus un corps simple ayant les propriétés de l'hélium.
Le modèle standard de la physique des particules décrit les nucléons comme des baryons composés de particules élémentaires appelées quarks :
Les électrons, quant à eux, sont des leptons qui constituent, avec les quarks, le groupe des fermions. La grande différence entre quarks et leptons est que seuls les premiers connaissent toutes les interactions élémentaires, y compris l'interaction nucléaire forte, dont les médiateurs sont des bosons de jauge appelés gluons ; les leptons ne connaissent que l'interaction faible (via les bosons Z0 et W+) et l'interaction électromagnétique (via les photons).
Toutes ces particules connaissent a priori également l'interaction gravitationnelle, mais cette dernière n'a pas pu être intégrée au modèle standard de la physique des particules ; son intensité à l'échelle atomique est, quoi qu'il en soit, insignifiante comparée à l'intensité des trois autres interactions.
L'essentiel des propriétés physiques et chimiques des atomes est dû à leur nuage électronique. C'est la compréhension de la nature et de la structure de ce nuage électronique qui a ouvert la voie à la compréhension de la structure de l'atome et, in fine, a conduit au développement de la physique des particules.
Le noyau atomique étant chargé positivement, il forme un puits de potentiel pour les électrons, qui sont chargés négativement. Ce puits de potentiel est constitué de niveaux d'énergie définis par des nombres quantiques dont la combinaison détermine des orbitales atomiques conférant aux fonctions d'onde correspondantes des dimensions et des formes caractéristiques.
L'électron manifeste, comme tout objet quantique, une dualité onde-corpuscule, en vertu de laquelle il se comporte tantôt comme une particule géométriquement délimitée occupant une position déterminée, tantôt comme une onde susceptible de présenter, par exemple, des phénomènes d'interférences. Ces deux aspects de l'électron coexistent dans l'atome, bien que le modèle de Schrödinger soit exclusivement ondulatoire[7] :
Par conséquent, un électron ne peut pas « tomber sur le noyau » comme un objet tombe par terre, car cela signifierait que l'extension spatiale de sa fonction d'onde serait réduite à un point, ce qui n'est le cas d'aucune fonction propre de l'équation de Schrödinger : cette dernière impose, au contraire, qu'un électron, au voisinage du noyau, se « dilue » dans un volume (une orbitale) à la géométrie déterminée par les nombres quantiques qui satisfont cette équation. On peut donc considérer qu'un électron dans un atome est déjà tombé sur le noyau, dans la mesure où il est confiné dans son voisinage par le puits de potentiel électrostatique.
De surcroît, la fonction d'onde d'un électron n'est pas nulle à l'intérieur du noyau, bien que sa probabilité de s'y trouver soit faible, car le noyau est de taille très réduite comparée à celle des orbitales atomiques. Les fonctions d'ondes possibles pour les électrons d'un atome étant centrées sur le noyau, on peut donc dire que l'électron est en fait tombé dans le noyau, bien qu'il ne s'y trouve que très rarement : du point de vue quantique, plusieurs particules peuvent en effet occuper le même espace en vertu de leur nature ondulatoire. Une façon imagée — mais approchée — de voir les choses est d'imaginer, par analogie, que la fonction d'onde de l'électron serait comme « diffractée » par le noyau atomique, ce qui lui donnerait différentes formes, selon son état quantique, par lesquelles la probabilité de présence de l'électron atteindrait son maximum en certaines zones plus ou moins éloignées du noyau — typiquement, plusieurs dizaines de milliers de fois le rayon nucléaire[8].
Chaque électron est décrit, dans un atome, par un quadruplet de nombres quantiques (n, ℓ, mℓ, ms) satisfaisant l'équation de Schrödinger et appelés respectivement :
Le principe d'exclusion de Pauli stipule que deux fermions appartenant au même système de fermions (ici, au même atome) ne peuvent avoir tous leurs nombres quantiques égaux en même temps. Ce principe est fondamental car il est à l'origine de la configuration électronique des atomes : les électrons qui « s'empilent » dans l'atome doivent avoir chacun un état quantique distinct des autres, ce qui explique que toutes les orbitales atomiques sont progressivement occupées de la plus liée à la moins liée au noyau au fur et à mesure qu'on ajoute des électrons à l'atome ; c'est le principe d'Aufbau (« édification » en allemand) matérialisé par la règle de Klechkowski (appelée aussi règle de Madelung), qui sous-tend l'agencement du tableau périodique des éléments chimiques en blocs et en périodes :
Sa structure électronique confère à l'atome ses propriétés chimiques et magnétiques. Ainsi, les éléments chimiques sont communément classés dans un tableau périodique organisé en fonction de leurs propriétés chimiques et dont l'agencement est en réalité déterminé par la distribution des électrons sur les niveaux d'énergie des atomes.
Le recouvrement de deux orbitales atomiques appartenant chacune à un atome distinct peut conduire à la formation d'une orbitale moléculaire constituant une liaison chimique entre deux atomes ; si les orbitales atomiques en recouvrement appartiennent au même atome, on dit qu'il y a hybridation.
Une orbitale moléculaire est dite liante lorsque les phases d'électron des orbitales atomiques sont de même signe (interférence constructive) ; elle est dite antiliante lorsque les orbitales atomiques ont des phases de signe opposé (interférence destructive).
Protons et neutrons forment un noyau atomique de dimension femtométrique. Le rayon nucléaire d'un atome dont le nombre de masse est A vaut environ 








1
,
2


A

3










{\displaystyle {\begin{smallmatrix}1,2{\sqrt[{3}]{A}}\end{smallmatrix}}}

  fm, alors que l'atome lui-même a un rayon de l'ordre de la centaine de picomètres (environ 35 000  à   40 000 fois plus grand). Les protons étant chargés positivement, ils se repoussent au sein du noyau, mais l'intensité de cette répulsion électrostatique est très inférieure à celle de l'attraction entre nucléons induite par l'interaction nucléaire forte à des distances inférieures à 2,5 fm.
La géométrie des noyaux atomiques est généralement sphérique, bien que certains noyaux stables suffisamment massifs adoptent également des formes sphéroïdes étirées en ballon de rugby ou, au contraire, aplaties. Certains noyaux instables, dits noyaux à halo, sont caractérisés par un ou plusieurs nucléons aux fonctions d'ondes très distendues, qui donnent au noyau des contours flous et un volume apparent très augmenté ; ces noyaux ont une cohésion nucléaire à la limite extrême du champ d'action de l'interaction forte.
Dans le modèle de la goutte liquide, les protons tendent à se repousser les uns les autres et, par conséquent, à se concentrer vers l'extérieur des noyaux (aux « pôles » ou à l'« équateur » dans le cas de sphéroïdes), tandis que les neutrons tendent à s'accumuler au centre du noyau. Des dizaines de modèles ont été proposés afin d'expliquer les données expérimentales sur la nature et la structure des noyaux atomiques, mais aucun, à ce jour, ne suffit seul à rendre compte de l'ensemble des observations[9].
Le volume nucléaire, estimé expérimentalement par des techniques de diffraction de faisceaux d'électrons, correspond à peu près à l'empilement de sphères dures représentant les nucléons, avec une densité nucléaire constante, ce qui se conceptualise très bien avec le modèle de la goutte liquide. Néanmoins, certaines propriétés quantiques de la structure nucléaire semblent mieux décrites par le modèle en couches, élaboré par les physiciens allemands Maria Goeppert-Mayer et Hans Daniel Jensen, qui ont obtenu le prix Nobel de physique en 1963 pour cette avancée. Leur modèle considère les nucléons comme des fermions soumis au principe d'exclusion de Pauli et répartis sur des niveaux d'énergie quantifiés — les « couches nucléaires » — de façon similaire aux électrons à l'échelle de l'atome. Dans le noyau, protons et neutrons constituent deux populations de fermions distinctes vis-à-vis du principe d'exclusion de Pauli.
L'analogie avec les électrons a cependant ses limites, car, si les électrons interagissent entre eux et avec le noyau via l'interaction électromagnétique, les nucléons interagissent entre eux essentiellement via l'interaction nucléaire forte et l'interaction faible. Les niveaux d'énergie au sein du noyau ont ainsi une distribution différente de celle des niveaux d'énergie des électrons d'un atome. De plus, les phénomènes de couplage spin-orbite sont bien plus sensibles pour les nucléons que pour les électrons, ce qui redistribue les sous-couches nucléaires en fonction du spin (indiqué en indice dans le tableau ci-dessous)[10] :
La saturation d'une couche nucléaire confère au noyau atomique une stabilité supérieure à celle calculée par la formule de Weizsäcker, issue du modèle de la goutte liquide — ce qui n'est pas sans rappeler l'inertie chimique des gaz rares, caractérisés par la saturation de leur sous-couche électronique p périphérique. Le nombre de nucléons d'une population donnée correspondant à la saturation d'une couche nucléaire est appelé « nombre magique » ; le noyau du plomb 208, qui est le plus lourd des isotopes stables, est ainsi constitué de 82 protons et 126 neutrons : 82 et 126 sont deux nombres magiques, ce qui explique la stabilité de ce nucléide par rapport à ceux qui n'en diffèrent que d'un ou deux nucléons.
Chimie et physique se rejoignent sur ce point, de sorte que les notions relatives à ces deux domaines des sciences se recouvrent à leur sujet. Ainsi, en physique nucléaire, on appelle nucléide un noyau atomique défini par un nombre déterminé de protons et de neutrons, terme souvent confondu avec la notion équivalente d'isotope, qui relève davantage de la chimie.
Un élément chimique se définit comme l'ensemble des atomes et des ions dont le noyau comporte un nombre donné de protons. Ce nombre est le numéro atomique, noté Z, de l'atome ou de l'élément chimique correspondant. Ainsi, tous les atomes n'ayant qu'un seul proton dans leur noyau (Z = 1) correspondent à l'élément chimique hydrogène. Il en existe trois variétés principales : le protium 1H, couramment appelé hydrogène (seul nucléide stable dépourvu de neutron), le deutérium 2H (stable, dont le noyau est constitué d'un proton et d'un neutron), le tritium 3H (radioactif, dont le noyau est constitué d'un proton et de deux neutrons). Ces nucléides sont des isotopes, car leur noyau compte le même nombre de protons mais un nombre différent de neutrons.
La classification des atomes suit celle des éléments chimiques, dont les propriétés chimiques — mais aussi physiques — présentent une périodicité découverte au XIXe siècle et à l'origine du tableau périodique des éléments. On emploie indifféremment les termes isotope stable et nucléide stable, radioisotope et radionucléide, ou encore élément superlourd et atome superlourd.
Les particules élémentaires possèdent un nombre quantique appelé spin, analogue à un moment angulaire et mesuré en unités de constante de Planck réduite (parfois appelée « constante de Dirac ») désignée par le symbole ℏ, qui se lit « h barre ». C'est également le cas des protons et des neutrons du noyau atomique, dont la résultante des spins se manifeste par un moment magnétique nucléaire. La valeur de ce dernier est spécifique à chaque noyau ; à l'état fondamental, elle est nulle pour les nucléides ayant à la fois un nombre pair de protons et un nombre pair de neutrons.
Cette propriété est mise à profit en imagerie par résonance magnétique (IRM), fondée sur la résonance magnétique nucléaire (RMN) : un matériau soumis d'une part à un rayonnement électromagnétique, et d'autre part à un champ magnétique intense (de l'ordre du tesla) qui oriente les noyaux atomiques dans une direction privilégiée (mais en les séparant en deux populations correspondant aux deux sens de cette direction), absorbe une partie du rayonnement électromagnétique à une fréquence déterminée par le rapport gyromagnétique du noyau ciblé, ce qui permet de déterminer par spectroscopie la concentration spatiale de ce noyau — typiquement dans le domaine des radiofréquences pour les champs magnétiques ne dépassant pas 20 T.
La liaison nucléaire est généralement décrite comme une manifestation résiduelle entre nucléons de l'interaction nucléaire forte qui maintient ensemble les quarks constituant les nucléons. L'énergie de liaison nucléaire est définie comme l'énergie nécessaire pour arracher un nucléon quelconque au noyau considéré. Elle est de l'ordre de quelques mégaélectron-volts par nucléon, partant de 0 (par définition) pour le protium 1H pour atteindre 7,57 MeV/A avec l'uranium 238 en passant par un maximum à 8,795 MeV/A pour le nickel 62[11]. Cette propriété fondamentale explique pourquoi ce sont uniquement les atomes légers qui libèrent de l'énergie par fusion nucléaire tandis que ce sont uniquement les atomes lourds qui libèrent de l'énergie par fission nucléaire :
La physique des noyaux atomiques est gouvernée par les trois interactions fondamentales du modèle standard de la physique des particules : l'interaction forte, l'interaction faible et l'l'interaction électromagnétique. Chaque noyau atomique est défini par le nombre de protons et de neutrons qu'il contient, ainsi que par son énergie totale, l'ensemble définissant les différents « arrangements » des particules selon lesquels l'énergie totale du système peut être distribuée. Plus il y a d'arrangements possibles et plus le système est stable : l'état présentant le plus grand nombre d'arrangements possibles est appelé état fondamental ; c'est celui vers lequel tendent tous les autres états de ce système.
Toute transition d'un état du système vers un autre requiert une énergie d'activation, fournie, dans le cas des noyaux atomiques, par les fluctuations du vide quantique. Lorsque de telles fluctuations suffisent à faire basculer un noyau atomique d'un état donné vers un état d'énergie inférieure, ce noyau est dit instable : on a affaire à un radionucléide. Jusqu'au calcium (Z = 20), les éléments chimiques ont des isotopes stables pour lesquels le nombre N de neutrons est à peu près égal au nombre Z de protons, tandis qu'au-delà de Z = 20 le ratio N/Z tend vers 3/2. Les isotopes instables, appelé radioisotopes, connaissent une désintégration radioactive qui leur permet de se rapprocher d'un état de plus grande stabilité.
La radioactivité désigne l'ensemble des phénomènes physiques par lesquels un nucléide instable réorganise sa structure nucléaire afin de gagner en stabilité. Ces phénomènes de désintégration radioactive peuvent être les suivants :
Chaque radioisotope est caractérisé par une période radioactive, qui correspond au temps nécessaire pour que la moitié des atomes de cet isotope se soit désintégrée. Un même nucléide peut connaître plusieurs modes de désintégration, la proportion relative de chacun de ces modes étant appelée rapport de branchement.
Certaines théories extrapolent les résultats du modèle en couches et les propriétés des nombres magiques en prédisant l'existence d'un îlot de stabilité parmi les nucléides superlourds, pour un nombre magique de 184 neutrons et — selon les théories et les modèles — 114, 120, 122 ou 126 protons. Une approche plus moderne de la stabilité nucléaire montre toutefois, par des calculs fondés sur l'effet tunnel, que, si de tels noyaux superlourds doublement magiques seraient probablement stables du point de vue de la fission spontanée, ils devraient cependant connaître des désintégrations α avec une période radioactive de quelques microsecondes[12],[13],[14] Un îlot de relative stabilité pourrait néanmoins exister autour du darmstadtium 293, correspondant aux nucléides définis par Z compris entre 104 et 116, et N compris entre 176 et 186 : ces éléments pourraient avoir des isotopes présentant des périodes radioactives atteignant quelques minutes.
Le plus lourd des nucléides synthétisés jusqu'à présent est l'isotope 294Og[15],[16],[17],[18],[19] et les recherches se poursuivent au GSI afin de produire l'isotope 302120. On ignore précisément jusqu'à combien de nucléons un noyau atomique peut contenir : on estime habituellement la limite d'observabilité expérimentale à environ Z ≈ 130[20] et la limite théorique à Z = 173 : un 174e proton (ou neutron) conférerait à la couche nucléaire 1s1/2 une énergie de −511 keV, égale à la masse au repos d'un électron ou d'un positron ; un tel noyau serait donc instable par rapport à la désintégration β[21],[22].
Si les propriétés nucléaires de l'atome (masse, énergie nucléaire, radioactivité, etc.) relèvent de la physique, et particulièrement de la physique nucléaire et de la physique des particules, les propriétés des nuages électroniques des atomes (taille, énergie d'ionisation, conductivité électrique, valence, etc.) relèvent essentiellement de la chimie et de la science des matériaux.
Le nuage électronique d'un atome n'a pas de dimensions bien définies car il consiste en une superposition d'orbitales atomiques de nature probabiliste. Il n'existe donc pas de définition unique ni de mesure définitive de la taille des atomes : celle-ci est généralement définie en termes de distance moyenne entre noyaux d'atomes liés entre eux, mais cette distance varie en fonction de la nature chimique des atomes environnants, du nombre et de la géométrie des liaisons dans lesquelles l'atome est engagé, ou encore de la nature de ces liaisons (métallique, covalente, ionique, etc.). Une valeur théorique de l'extension des orbitales atomiques peut néanmoins être calculée pour chaque noyau atomique, ce qui donne une valeur en excès par rapport aux méthodes empiriques fondées sur la géométrie des mailles cristallines, ou aux mesures effectuées sur des molécules :


Au-delà des valeurs numériques, qui ne doivent être vues ici que comme indicatives, ce tableau permet d'illustrer deux tendances :
La contraction des lanthanides illustre bien ce dernier phénomène, et est à l'origine du fait que les atomes des métaux de transition des cinquième et sixième périodes ont des tailles à peu près égales : à peine deux picomètres de plus pour le hafnium et le tantale que pour le zirconium et le niobium ; il s'ensuit une augmentation sensible de la masse volumique des métaux correspondants, par exemple 6,5 et 13,3 g/cm3 respectivement pour le zirconium et le hafnium — soit plus qu'un doublement.
L'une des propriétés les plus remarquables des atomes est leur propension à former toute une variété de liaisons chimiques avec d'autres atomes, afin de constituer des édifices moléculaires, des cristaux, voire des agrégats atomiques (clusters, « superatomes »). Ces liaisons résultent du recouvrement d'orbitales atomiques appartenant à deux atomes pour former une orbitale moléculaire occupée par deux électrons provenant chacun d'un des deux atomes engagés dans la liaison (on parle dans ce cas de liaison covalente), mais peuvent aussi provenir de l'attraction électrostatique entre atomes de charge électrique opposée (un cation positif et un anion négatif : on parle alors de liaison ionique).
La réactivité chimique des atomes dépend du nombre d'électrons qu'ils possèdent dans leurs sous-couches électroniques périphériques (sous-couches s et p) — les électrons de valence. En vertu de la règle de l'octet, chaque atome tend en effet à atteindre un état où ses sous-couches s et p périphériques sont saturées d'électrons : deux électrons dans la sous-couche s et six électrons dans la sous-couche p. Par exemple, l'hydrogène n'a qu'un unique électron dans sa sous-couche 1s, de sorte qu'il s'associe avec un autre atome pour acquérir le second électron qu'il manque à cette sous-couche pour être saturée : on dit que l'hydrogène est monovalent. L'oxygène, lui, a quatre électrons dans sa sous-couche 2p, et s'associe donc avec deux autres atomes pour acquérir les deux électrons qui manquent à cette sous-couche pour être saturée : l'oxygène est donc divalent. Le carbone, ayant deux électrons dans sa sous-couche 2p, est tétravalent. Les gaz rares les plus légers tels que l'hélium et le néon, avec respectivement deux électrons dans la sous-couche 1s et six électrons dans la sous-couche 2p, sont à peu près inertes chimiquement car leur configuration électronique est déjà saturée d'électrons de valence — mais il existe une chimie des gaz rares concernant les gaz rares plus lourds, qui présentent une réactivité chimique non nulle en raison de l'écrantage du noyau par les électrons de cœur qui rend les électrons périphériques plus mobilisables.
La liaison covalente est une liaison forte : celle qui unit les deux atomes d'iode de la molécule I2 n'est que de 151 kJ/mol, mais atteint 436 kJ/mol pour la molécule H2, 498 kJ/mol pour O2, et 945 kJ/mol pour N2.
Un autre type de liaison chimique s'observe dans les métaux : la liaison métallique. Les atomes métalliques ont en effet la propriété, lorsqu'ils s'assemblent, de faire apparaître, par recouvrement de leurs orbitales atomiques périphériques, une « bande de conduction » qui peut être occupée par des électrons délocalisés (on parle « d'aromaticité métallique ») issus des orbitales les moins liées de ces atomes ; la conductivité électrique des métaux résulte du fait qu'il existe un nombre bien plus élevé de configurations électroniques possibles (on parle de densité d'états électroniques) qu'il y a d'électrons dans cette bande de conduction, de sorte que ces derniers y constituent un « gaz d'électrons ».
Des atomes appartenant à des molécules distinctes peuvent également interagir avec leur nuage électronique autrement que par liaison covalente ou ionique. Ainsi, un atome d'halogène déficitaire en électrons et facilement polarisable peut former une liaison halogène avec les atomes ou groupements fonctionnels riches en électrons, tels que des dérivés oxygénés ou azotés. De même, une molécule ayant un atome d'hydrogène acide peut former une liaison faible (de 5 à 20 kJ/mol) avec un atome électronégatif ayant des doublets non liants. Enfin, l'interaction des moments dipôlaires de deux atomes est à l'origine de la force de van der Waals, dont la force est du même ordre de grandeur que celle de la liaison hydrogène.
Compte tenu de leur configuration électronique, certains atomes auront davantage tendance que d'autres à attirer des électrons en formant des liaisons chimiques covalentes. Cette propriété est appelée l'électronégativité d'un atome. Elle dépend en premier lieu de leur nombre de masse et, corrélativement, de l'intensité de la liaison entre le noyau atomique et des électrons de valence. Elle est généralement évaluée à l'aide de l'échelle de Pauling, du nom de Linus Pauling qui la mit au point en 1932[24]. D'autres méthodes d'évaluation donnent des résultats légèrement différents, mais toutes révèlent les mêmes tendances à travers le tableau périodique.

La lecture de ce tableau permet de dégager deux tendances principales :
Le cas des gaz rares eux-mêmes est particulier car les plus légers d'entre eux sont chimiquement inertes, une véritable chimie des gaz rares n'existant que pour le krypton et, surtout, le xénon — le radon est trop radioactif pour présenter une chimie significative.
L'électronégativité n'est pas une notion atomique absolue, mais plutôt une propriété chimique relative aux atomes engagés dans une liaison avec d'autres atomes. La propriété atomique stricto sensu correspondant à l'électronégativité est appelée affinité électronique et correspond à l'énergie libérée par l'adjonction d'un électron à un atome neutre pour former un anion. Il s'agit donc d'une grandeur physique mesurable, contrairement à l'électronégativité.


Les valeurs représentées par un astérisque dans le tableau ci-dessus sont voisines de zéro d'après l'interprétation quantique de la configuration électronique des atomes correspondants. On note que l'affinité électronique ne présente pas la périodicité régulière de l'électronégativité, mais qu'elle est tout de même la plus élevée pour les halogènes et sensiblement plus faible pour les métaux alcalins et, surtout, alcalino-terreux.
Comme les nucléons, les électrons possèdent un spin, analogue à un moment angulaire, intrinsèque à chaque électron, auquel se superpose un moment angulaire orbital, représenté par le nombre quantique secondaire, généré par la distribution probabiliste de l'électron dans son orbitale atomique, qui s'assimile à un « mouvement ». Ces deux moments angulaires se combinent pour constituer un champ magnétique autour de l'atome. Lorsque deux électrons occupent une case quantique de l'atome, ils ont chacun un spin opposé en vertu du principe d'exclusion de Pauli, ce qui annule le moment angulaire résultant ; mais les atomes et les ions qui ont un nombre impair d'électrons ont par conséquent un moment magnétique résultant non nul provenant du spin de leurs électrons.
Les matériaux ferromagnétiques ont la particularité d'orienter dans la même direction les moments magnétiques de leurs atomes par interaction d'échange, ce qui crée un champ magnétique macroscopique : c'est le cas, par exemple, de la magnétite Fe3O4. Certains matériaux orientent au contraire les moments magnétiques de leur atomes dans des directions alternativement opposées, ce qu'on appelle « antiferromagnétisme ».
Les matériaux paramagnétiques révèlent leur magnétisme intrinsèque uniquement sous l'effet d'un champ magnétique extérieur, qui aligne le moment magnétique de leurs atomes tant qu'il est présent (susceptibilité magnétique positive) ; dès que ce champ magnétique extérieur cesse d'être appliqué, la magnétisation d'un matériau paramagnétique disparaît. Les atomes ayant des électrons non appariés dans leurs sous-couches d et f ont des propriétés magnétiques intenses car ces électrons sont fortement localisés ; en particulier, les lanthanides font des aimants particulièrement puissants en raison de leur moment magnétique induit par jusqu'à sept électrons non appariés — notamment le néodyme et le samarium. Il existe une méthode d'analyse spectroscopique sous champ magnétique analogue à la résonance magnétique nucléaire (RMN) qui fait intervenir le spin des électrons au lieu de celui des noyaux : la résonance paramagnétique électronique (également appelée de façon plus propre « résonance de spin électronique »).
Le diamagnétisme, quant à lui, est un phénomène assez général dû au moment angulaire orbital des électrons et non au spin de ces derniers, qui consiste en l'apparition d'un champ magnétique de direction opposée à tout champ magnétique extérieur ; c'est un phénomène généralement de faible intensité, hormis quelques cas particuliers tels que, par exemple, l'or, le mercure, le bismuth et surtout les matériaux supraconducteurs (effet Meissner).
Un électron d'un atome peut être excité par absorption d'un photon incident, ce qui le fait occuper une orbitale atomique d'énergie supérieure à celle de son état fondamental. De nombreuses molécules aromatiques ou présentant des liaisons π conjuguées sont susceptibles d'être ainsi excitées simplement par éclairage ; leur relaxation vers l'état fondamental se traduit alors par l'émission d'un ou plusieurs photons, selon deux mécanismes distincts :
L'interaction d'atomes avec un rayonnement électromagnétique peut également se traduire par l'apparition de raies d'absorption ou d'émission à certaines longueurs d'onde particulières sur un spectre par ailleurs continu. Ces longueurs d'onde correspondent à l'énergie de transition entre couches électroniques et sous-couches électroniques : lorsqu'un atome est atteint par un photon ayant une énergie égale à l'une de ces transitions entre niveaux d'énergie électroniques, un électron peut absorber ce photon et passer à un niveau d'énergie supérieur, laissant une longueur d'onde déficitaire en photons, ce qui se matérialise dans le spectre par une raie d'absorption.
Chaque atome, chaque ion, et même chaque molécule ou radical libre, possède ainsi une signature spectrale caractéristique, très employée par exemple en astrophysique pour détecter leur présence et déterminer leur concentration dans le milieu interstellaire, voire l'espace intergalactique : la disposition des raies spectrales, leur éventuel décalage (décalage vers le rouge), leur largeur, leur netteté et leur éventuelle séparation en plusieurs composantes (ce qu'on appelle leur structure fine) sont ainsi des paramètres riches d'informations sur le milieu traversé par le rayonnement analysé entre sa source et sa détection par les instruments de spectroscopie.
La matière baryonique peut exister à l'état solide, liquide ou gazeux selon sa température et sa pression : les transitions entre ces états surviennent à des niveaux de température et de pression directement en rapport avec les propriétés des atomes et de leurs arrangements moléculaires qui constituent chaque matériau. Les états solide et liquide sont qualifiés d’états condensés, tandis que les états liquide et gazeux sont qualifiés d’états fluides. Les cristaux liquides (une mésophase) sont un état intermédiaire entre solide et liquide.
Il existe par ailleurs des états de la matière moins courants sur Terre et qui dérivent des précédents :
Les atomes constituent environ 4 % de l'énergie totale observable de l'univers, avec une concentration moyenne d'un atome pour quatre mètres cubes[27]. Dans le milieu interstellaire d'une galaxie telle que la Voie lactée, la concentration d'atomes varie selon les régions entre cent mille et un milliard d'atomes par mètre cube, bien que l'environnement immédiat du Soleil soit bien plus ténu : à peine cinquante mille atomes par mètre cube, ce qui définit précisément la bulle locale comme une cavité dans le milieu interstellaire formée par l'explosion de supernovas voisines il y a deux à quatre millions d'années[28]. Les étoiles se forment à partir de nuages denses, et les réactions de fusion nucléaire qui se déroulent en leur sein conduisent à la formation d'éléments chimiques plus lourds que l'hydrogène, l'hélium et le lithium produits à la suite du Big Bang.
Plus de 95 % des atomes de la Voie lactée se trouvent dans les étoiles, et les atomes « visibles » de notre galaxie représentent environ 10 % de sa masse : le reste de cette masse serait constitué d'une mystérieuse matière noire.
Dans les premières minutes de l'existence de l'univers, les quatre éléments les plus légers se sont formés au cours de la nucléosynthèse primordiale : environ 75 % d'hydrogène 1H, 25 % d'hélium 4He, 0,01 % de deutérium 2H, et des traces (de l'ordre de 10-10) de lithium 7Li. Cette nucléosynthèse aurait été trop brève pour permettre la synthèse d'éléments plus lourds que le lithium et pour permettre la fusion du deutérium. Les atomes proprement dits, avec leur nuage électronique, se seraient formés lors de la recombinaison, environ 377 000 ans après le Big Bang, et les premiers quasars et étoiles se seraient formés après 150 millions d'années.
La nucléosynthèse stellaire aurait alors pris le relais pour former tous les éléments chimiques jusqu'au fer par fusion successive de noyaux d'hélium :
À ce stade, la fusion cesse d'être exothermique et des réactions nécessitant un milieu très énergétique interviennent pour former les éléments plus lourds : capture neutronique (processus r, processus s), protonique (processus rp), et photodésintégration (processus p), qui interviennent tout à la fin de vie des étoiles, même peu massives, et surtout lors de l'explosion de supernovas.
Selon toute vraisemblance, la grande majorité des atomes qui constituent la Terre étaient déjà présents dans la nébuleuse solaire, dont l'effondrement gravitationnel aurait engendré le système solaire. Les atomes apparus depuis proviennent le plus souvent de la désintégration radioactive d'éléments primordiaux instables, et les rapports isotopiques des éléments correspondants offrent le moyen d'évaluer l'âge de la Terre par datation radiométrique[29]. Par ailleurs, l'abondance naturelle de l'hélium 3 sur Terre par rapport à l'hélium 4 des gisements de gaz naturel permet de déduire que 99 % de l'hélium 4 terrestre provient de la radioactivité α[30]. D'autres atomes, qualifiés de « cosmogéniques, » proviennent de l'interaction des rayons cosmiques avec l'atmosphère terrestre : c'est le cas bien connu du carbone 14, mais aussi, par exemple, du béryllium 10. Enfin, de très nombreux atomes synthétiques sont produits en laboratoire à des fins essentiellement scientifiques, parfois militaires, rarement industrielles (en raison du coût prohibitif des matériaux ainsi produits), tels que le silicium 42 (pour valider certaines hypothèses sur le modèle en couches décrivant la structure nucléaire), le plutonium 239 (matériau de choix pour les armes nucléaires), le technétium 99m (très utilisé en médecine nucléaire) ou encore l'américium 241 (employé industriellement dans les détecteurs de fumée).
Sous certaines conditions, il est possible d'exciter des atomes, par exemple avec un laser à colorant, pour placer certains de leurs électrons dans des orbitales atomiques correspondant à un nombre quantique principal n égal à plusieurs dizaines d'unités, voire supérieur à 100[31]. De tels atomes sont appelés atomes de Rydberg. Ils ont des propriétés remarquables, telles qu'une très grande susceptibilité électrique et magnétique[32], une relative stabilité, et des fonctions d'onde électroniques approchant, dans une certaine mesure, l'orbite décrite par un électron en mécanique classique autour du noyau. Les électrons de cœur écrantent le champ électrostatique du noyau du point de vue de l'électron périphérique, pour lequel le potentiel du noyau est identique à celui d'un atome d'hydrogène[33]. Le comportement de cet électron particulier est particulièrement bien décrit par le modèle de Bohr, pourtant très insuffisant pour modéliser les atomes « conventionnels ».
Les atomes de Rydberg ont une taille très supérieure à celle des atomes à l'état fondamental : l'état d'excitation jusqu'à n = 137 d'un atome d'hydrogène correspond à un rayon atomique d'environ 1 μm, soit cinq ordres de grandeur au-dessus du rayon d'un atome d'hydrogène à l'état fondamental (n = 1). Ils ne peuvent exister dans le milieu naturel terrestre car leur énergie d'ionisation y est bien inférieure à l'énergie thermique, mais représentent une partie importante de la matière du milieu interstellaire, où ils peuvent persister longtemps sans interaction avec d'autres atomes ni avec des champs électriques ou magnétiques susceptible de provoquer leur retour à l'état fondamental. La raie spectrale à 2,4 GHz révélatrice de la transition de nombre quantique principal entre n = 109 et n = 108 de l'atome d'hydrogène est ainsi très fréquemment observée par les astronomes[34].
Compte tenu de leur susceptibilité électrique et magnétique très élevée, les propriétés électriques et magnétiques des milieux contenant une proportion significative d'atomes de Rydberg sont sensiblement altérées par leur présence.
Différentes formes d'atomes exotiques ont été conjecturées, et parfois observées. C'est le cas, par exemple, des atomes muoniques, dans lesquels un électron est remplacé par un muon : ce dernier étant plus massif qu'un électron, il présente des orbitales plus proches du noyau, ce qui donne des « atomes » plus petits. De la même façon, un électron peut être remplacé par un hadron, tel qu'un méson, une particule Σ−, voire un antiproton. Le seul atome exotique ayant une durée de vie significative — qui n'excède cependant pas 2,2 μs — est le muonium, résultant de l'interaction d'un électron avec un muon μ+ servant de « noyau ». Ces formes d'atomes sont utiles pour vérifier certains aspects du modèle standard de la physique des particules, notamment les interactions élémentaires.
L'interaction d'un positron avec un antiproton donne un atome d'antihydrogène, qui est un atome d'antimatière. Il existe a priori un « antiatome » pour chaque atome ; la production d'antimatière demeure néanmoins une expérience particulièrement coûteuse en énergie, et seul l'antihydrogène 1H a été synthétisé à ce jour.
Il existe également tout une variété d'atomes « conventionnels » mais néanmoins absents du milieu naturel et donc produits artificiellement. Ces éléments synthétiques sont, à deux exceptions près[35], des transuraniens, qui sont de plus en plus instables à mesure que leur numéro atomique augmente.
La notion d'atome est particulièrement bien admise par le grand public, pourtant, paradoxalement, les atomes ne peuvent pas être observés par des moyens optiques et seuls quelques rares physiciens manipulent des atomes isolés. L'atome est donc un modèle essentiellement théorique. Bien que ce modèle ne soit plus aujourd'hui remis en cause, il a beaucoup évolué au cours du temps pour répondre aux exigences des nouvelles théories physiques et rendre compte des résultats expérimentaux obtenus au fil du temps.
Il est possible que divers peuples aient développé la notion de « grain composant la matière », tant ce concept peut sembler évident lorsque l'on morcelle une motte de terre, ou en regardant une dune. Dans la culture européenne, ce concept apparaît pour la première fois dans la Grèce antique au Ve siècle av. J.-C., chez les philosophes présocratiques, notamment Leucippe (environ 460-370 av. J.-C.), Démocrite et plus tard Épicure. La théorie atomiste sera ensuite magnifiquement exposée par le Romain Lucrèce dans son œuvre De rerum natura[36], qu’il résume en affirmant que « les corps premiers sont [...] d’une simplicité impénétrable, et forment un ensemble homogène et étroitement cohérent de particules irréductibles [...] dont la nature ne permet pas qu’on puisse encore rien retrancher ni soustraire[37]. » Un des arguments majeurs développé par les atomistes est la permanence de l'univers qui suggère l'existence d'objets ultimement insécables rendant nécessaire une certaine quantité d'énergie pour disséquer la matière. Dans le cas contraire, toute énergie non nulle suffirait à dégrader la matière et userait l'univers qui prendrait peu à peu la forme de poussières impalpables. L'univers étant pensé ancien par les Grecs, cette idée d'une continuité de la matière était donc incompatible avec la stabilité du monde observée[38].
Il s'agit d'une conception du monde qui fait partie de la recherche des principes de la réalité, recherche qui caractérise les premiers philosophes : on suppose que la matière ne peut se diviser indéfiniment, qu'il y a donc une conservation des éléments du monde, qui se transforment ou se combinent selon des processus variés. La décomposition du monde en quatre éléments (eau, air, terre, feu) peut donc compléter cette thèse. L'atomisme est une solution concurrente, qui naît de l'opposition de l'être et du néant : l'atome est une parcelle d'être qui se conserve éternellement, sans quoi les choses finiraient par disparaître. Les atomes sont indivisibles ; ils composent la matière comme les lettres composent les mots. Ce fut sans doute un tournant philosophique majeur, à l'origine du matérialisme et de la séparation de la science et de la religion. Cependant, même si l'empirisme épicurien tente d'établir cette hypothèse sur des bases scientifiques, l'atome demeure une intuition sans confirmation.
Depuis des millénaires, on a remarqué que les produits se transforment : le feu, la métallurgie, la corrosion, la vie, la cuisson des aliments, la décomposition de la matière organique, etc. Par exemple, pour Empédocle, les transformations de la matière s'expliquaient de la manière suivante : il y avait quatre types d'éléments (eau, air, terre, feu) qui s'associaient et se dissociaient, en fonction de l'amour ou de la haine qu'ils se portaient — les fameux « atomes crochus ». Au Moyen Âge, les alchimistes ont étudié ces transformations et remarqué qu'elles suivent des règles bien précises. Vers 1760, des chimistes britanniques commencent à s'intéresser aux gaz produits par les réactions, afin d'en mesurer le volume et de les peser. Ainsi, Joseph Black, Henry Cavendish et Joseph Priestley découvrent différents « airs » (c'est-à-dire gaz) : l'« air fixe » (le dioxyde de carbone), l'« air inflammable » (le dihydrogène), l'« air phlogistiqué » (le diazote), l'« air déphlogistiqué » (le dioxygène)… (Le terme « phlogistique » provient de la théorie du chimiste allemand Georg Ernst Stahl, au début du XVIIIe siècle, pour expliquer la combustion ; cette théorie fut balayée par Lavoisier.)
Antoine Lavoisier énonce en 1775 que[d] : « Rien ne se perd, rien ne se crée, tout se transforme » (formulé d'une manière légèrement différente à l'époque) signifiant par là que :
Cette observation marque la naissance de la chimie. Les scientifiques commencent donc à recenser les éléments dont sont composées toutes les substances et à créer une nomenclature systématique — oxygène : qui produit des acides (οξυs signifie « acide » en grec) — hydrogène : qui produit de l'eau… Par exemple, en 1774, Lavoisier, en suivant les travaux des chimistes britanniques, établit que l'air se compose d'« air vital » (dioxygène) et d'« air vicié et méphitique, mofette » (diazote) ; en 1785, il décompose l'eau (en faisant passer de la vapeur d'eau sur du fer chauffé au rouge) et montre donc que ce n'est pas un élément, mais que l'eau est décomposable en éléments (c'est en fait une pyrolyse). Le terme d'« analyse » provient d'ailleurs de cette notion de décomposition, lusis (λυσιs) signifie « dissolution » en grec : on décompose les produits (par attaque acide, en les brûlant, en les distillant, etc.) jusqu'à obtenir des substances simples reconnaissables facilement (l'hydrogène, l'oxygène, le carbone, le fer, etc.).
On a donc la première constatation expérimentale de la décomposition de la matière en substances élémentaires.
Un autre pas, fait en parallèle, vient de l'étude des propriétés des gaz et de la chaleur (thermodynamique).
Les fluides (liquides et gaz) sont étudiés en Europe depuis l'Antiquité, mais c'est au milieu du XVIIe siècle que l'on commence vraiment à cerner leurs propriétés, avec l'invention du thermomètre (thermoscope de Santorre Santario, 1612), du baromètre et du vide pompé (Evangelista Torricelli, 1643), l'étude de l'expansion des gaz (Gilles Personne de Roberval, 1647), la pression atmosphérique (Blaise Pascal et Florin Perrier, 1648), les relations entre pression et volume (Robert Boyle en 1660, Edme Mariotte en 1685), la notion de zéro absolu (Guillaume Amontons, 1702), etc.
René Descartes (mathématicien, physicien et philosophe français) émet l'idée, en 1644, que les gaz sont composés de particules tourbillonnantes. Mais il ne s'agit là encore que d'une conception imagée, sans appui expérimental ; dans le même ordre d'idées, Descartes pensait que c'était aussi un tourbillon de « matière subtile » qui entraînait la rotation des planètes (ceci fut mis en défaut par Isaac Newton avec l'attraction universelle en 1687).
Cependant, cette notion de corpuscules inspire d'autres scientifiques. Les mathématiciens suisses Jakob Hermann (1716) et Leonhard Euler (1729), mais surtout le physicien suisse Daniel Bernoulli (1733), effectuent des calculs en supposant que les gaz sont formés de particules s'entrechoquant, et leurs résultats sont en accord avec l'expérience. C'est la conception « cinétique » des gaz, c'est-à-dire l'explication de la température et de la pression par des particules en mouvement.
Une autre science se développe à la fin du XVIIIe siècle : la cristallographie. Ce qui intrigue les scientifiques, c'est l'observation des formes géométriques des cristaux naturels, et leur capacité à se cliver selon des plans lisses respectant ces symétries. Reprenant l'idée de classification des êtres vivants de Carl von Linné, on commence à rechercher et classer les minéraux (Jean-Baptiste Romé de L'Isle, 1772). L'abbé René Just Haüy, en 1781, suppose que la forme des cristaux reflète la symétrie d'une « brique élémentaire », le cristal étant un assemblage de ces briques. On retrouve ici cette notion de composant élémentaire de la matière.
À ce stade, ressortent trois notions :
Ces notions ont en commun le fait que la matière homogène est composée de corpuscules tous semblables entre eux, mais trop petits pour être visibles. Les découvertes du XIXe siècle permettent de faire converger ces trois notions, et d'établir les notions de molécule et d'atome.
John Dalton, en 1804, mesure les masses des réactifs et des produits de réaction, et en déduit que les substances sont composées d'atomes sphériques, identiques pour un élément, mais différents d'un élément à l'autre, notamment par la masse de ces atomes. Il découvre également la notion de pression partielle (dans un mélange de gaz, la contribution d'un gaz donné à la pression totale). Il fut le premier à émettre les idées de la théorie atomique.
En 1807, Joseph Louis Gay-Lussac, établit la loi reliant la température et la pression d'un gaz. En 1808, il établit que les gaz réagissent en proportions déterminées ; les rapports des volumes des réactifs et des produits de réaction sont des nombres entiers petits. Le fait que ce soit des nombres entiers, a induit fortement à penser que la matière n'est pas « continue » (pensée dominante à cette époque), mais faite d'éléments discontinus.
Amedeo Avogadro (physicien italien), en 1811, énonce, sans preuve, que pour une température et une pression fixées, un volume donné de gaz contient toujours le même nombre de molécules, et ce quel que soit le gaz. Il fait également l'hypothèse que les gaz sont polyatomiques, et définit nettement molécules et atomes. André-Marie Ampère (1814), Jean-Baptiste Dumas (1827) et William Prout (1834) arrivent à la même conclusion.
En 1813, Jöns Jacob Berzelius inventa et fit admettre universellement des formules chimiques analogues aux formules algébriques pour exprimer la composition des corps ; le système actuel de notation fut adopté grâce à lui qui le proposa.
En 1821, John Herapath (en) publie une théorie cinétique des gaz pour expliquer la propagation des sons, les changements de phase (vaporisation, liquéfaction) et la diffusion des gaz.
Robert Brown, en 1827, observe le mouvement de particules à l'intérieur de grains de pollen ; ceux-ci vont en ligne droite, et ne changent de direction que lors d'un choc avec un autre grain ou bien contre une paroi. C'est de ce comportement, le « mouvement brownien », que s'inspireront les physiciens pour décrire le mouvement des molécules de gaz.
Gabriel Delafosse, en 1840, suppose que l'on peut dissocier la composante élémentaire du cristal et son organisation ; ainsi, la brique élémentaire de Haüy pourrait être un réseau aux nœuds duquel se trouveraient des « molécules » ; ce serait la forme du réseau qui donnerait la forme au cristal et non pas nécessairement la forme des molécules.
Louis Pasteur, en 1847, établit le lien entre la forme des molécules et la forme des cristaux (en fait, la molécule donne sa forme au réseau, et le réseau sa forme au cristal). Auguste Bravais, en 1849, détermine les 32 réseaux cristallins possibles.
En 1858, Stanislao Cannizzaro insiste sur la distinction, précédemment émise par Avogadro sous forme d'hypothèse, entre le poids moléculaire et atomique et montre comment le poids atomique des éléments contenus dans des composés volatils peut être déduit de la connaissance de leur chaleur spécifique et comment le poids atomique des composés dont la densité de vapeur est inconnue peut aussi être déduite de la chaleur spécifique. La même année, Rudolf Clausius (physicien allemand) définit le libre parcours moyen d'une molécule dans un gaz (distance moyenne parcourue entre deux chocs). Partant de là, en 1859, James Clerk Maxwell introduit la notion de dispersion statistique des vitesses des molécules dans la cinétique des gaz. Ceci permet à Ludwig Boltzmann, en 1858, d'estimer la taille des molécules et de définir la répartition statistique des vitesses dans un gaz.
En 1863, John Newlands publie le premier tableau périodique des éléments, ordonnés en fonction de leur masses atomiques relatives, et émet l'hypothèse, en 1865, de la « loi des octaves » selon laquelle les propriétés chimiques d'un élément de la table se retrouvent tous les huit éléments. Personne n'y croit à l'époque.
Dimitri Ivanovitch Mendeleïev (chimiste russe), en 1869, classe les atomes par masse croissante, et remarque qu'il y a bien une périodicité dans leurs propriétés chimiques. Il établit donc un tableau classant les éléments ; les trous dans ce tableau donnent l'élan à des scientifiques de rechercher les éléments manquants.
La notion d'atome et de molécule a donc permis le succès de la thermodynamique statistique, de la chimie et de la cristallographie. À cette notion, vont correspondre des modèles qui seront affinés au cours du développement de la physique et particulièrement précisés par les découvertes de la physique quantique durant le XXe siècle, et notamment :
Cet article ne cite pas suffisamment ses sources (mars 2009).
Si vous disposez d'ouvrages ou d'articles de référence ou si vous connaissez des sites web de qualité traitant du thème abordé ici, merci de compléter l'article en donnant les références utiles à sa vérifiabilité et en les liant à la section « Notes et références »
En pratique : Quelles sources sont attendues ? Comment ajouter mes sources ?
Dans l'histoire des sciences, plusieurs modèles de l'atome ont été développés, au fur et à mesure des découvertes des propriétés de la matière. Aujourd'hui encore, on utilise plusieurs modèles différents ; en effet, le modèle le plus récent est assez complexe, l'utilisation de modèles « anciens » ou partiellement faux, mais plus simples, facilite la compréhension, donc l'apprentissage et la réflexion.
Depuis l'antiquité grecque, on supposait que la matière pouvait se fractionner en petits morceaux jusqu'à obtenir des grains indivisibles, qu'elle était comme « de la poussière dans la lumière ». C'est avec l'expérience de Rutherford que l'on atteint enfin ce grain : les particules α, en traversant la matière, voient leur trajectoire perturbée, ce qui va permettre enfin de savoir comment est organisée cette « poussière »…
Les modèles présentés dans cette section sont trop éloignés de la réalité pour pouvoir être utilisés. Ils ne sont présentés ici qu'à titre historique.
Avec la découverte de l’électron en 1897, on savait que la matière était composée de deux parties : une négative, les électrons, et une positive, le noyau. Dans le modèle imaginé alors par Joseph John Thomson, les électrons, particules localisées, baignaient dans une « soupe » positive, à l’image des pruneaux dans le far breton (ou dans le plum-pudding pour les Britanniques ou encore comme des raisins dans un gâteau). Ce modèle fut invalidé en 1911 par l'expérience d’un de ses anciens étudiants, Ernest Rutherford.
L'expérience de Rutherford met en évidence que les charges positives ne sont pas « étalées » entre les électrons, mais sont concentrées en de petits points. Il bombarda une fine feuille d'or par un faisceau de particules alpha (particules de charges électriques positives). Il observa que les particules étaient déviées faiblement, ce qui ne correspondait pas au résultat prévu par le modèle de Thomson, pour lequel, elles n'auraient pas dû la traverser.
Rutherford imagine donc un modèle planétaire : l'atome est constitué d'un noyau positif autour duquel tournent des électrons négatifs. Entre le noyau — très petit par rapport à l'atome (environ 100 000 fois) — et ses électrons, un très grand vide existe.
Ce modèle fut très vite mis en défaut par les équations de Maxwell d'une part, qui prédisent que toute charge accélérée rayonne de l'énergie, et par les expériences montrant la quantification des niveaux d'énergie d'autre part.
Le modèle le plus simple pour représenter un atome est une boule indéformable. Ce modèle est très utilisé en cristallographie. Une molécule peut se voir comme plusieurs boules accolées, un cristal comme des boules empilées. On utilise parfois une représentation « éclatée » : les atomes sont représentés comme des petites boules espacées, reliées par des traits, permettant de faire ressortir les directions privilégiées, les angles et de visualiser le nombre des liaisons.
Ce modèle correspond bien à certaines propriétés de la matière, comme la difficulté de comprimer les liquides et les solides, ou bien le fait que les cristaux ont des faces bien lisses. En revanche, il ne permet pas d'expliquer d'autres propriétés, comme la forme des molécules : si les atomes n'ont pas de direction privilégiée, comment expliquer que les liaisons chimiques révèlent des angles bien définis ?
Un modèle fut développé par Niels Bohr en 1913 à partir des propriétés mises en évidence par Planck et Rutherford. Dans le modèle des sphères dures, l’atome est un objet entier, indécomposable. Or, on sait depuis le milieu du XIXe siècle que l’on peut en « arracher » des particules portant une charge électrique négative, les électrons. Dans le modèle de Bohr, l’atome est composé d’un noyau chargé positivement, et d’électrons tournant autour, les rayons des orbites des électrons ne pouvant prendre que des valeurs bien précises.
Le noyau est très compact, d’un diamètre d’environ 10-15 à 10-14 m, c’est-à-dire que le noyau est cent mille à un million de fois plus petit que l’atome ; il porte une charge électrique positive. C’est aussi la partie la plus lourde de l’atome, puisque le noyau représente au moins 99,95 % de la masse de l’atome. Les électrons sont ponctuels, c’est-à-dire que leur rayon est admis quasi nul (tout du moins plus petit que ce que l’on peut estimer). Ils portent une charge négative. Pour des raisons de lisibilité, le schéma ci-dessous n’est donc pas à l’échelle, en ce qui concerne les dimensions du noyau et des électrons, ni aussi pour les rayons des différentes orbites (on notera ici que le nombre d’électrons sur les orbites n’est pas prédit par le modèle).
Cette vision permet de décrire les phénomènes spectroscopiques fondamentaux, c’est-à-dire le fait que les atomes absorbent ou émettent seulement certaines longueurs d’onde (ou couleur) de lumière ou de rayons X. En effet, le système {noyau+électrons} étant stable et confiné, d’énergie négative, il ne possède qu’un ensemble discret d’états (et donc de niveaux) d’énergie : c’est le passage d’un état à l’autre de l’atome qui provoque une émission discrète d’énergie, ce qui explique donc les raies spectroscopiques des atomes. Le modèle de Bohr, décomposant l’atome en deux parties, un noyau et un nuage d'électrons, est plus précis que le modèle des sphères dures, pour lequel la surface de la sphère correspond à l’orbite des électrons extérieurs.
Cependant, très vite, le modèle de l’atome de Bohr ne permettra pas d’expliquer l’ensemble des observations (effet Zeeman, etc.). Il faut attendre 1924-1926 pour qu’avec Schrödinger, les orbites deviennent orbitales avec des énergies stationnaires : la mécanique quantique est née.
La naissance de la mécanique ondulatoire de Louis de Broglie en 1924, généralisée par Erwin Schrödinger en 1926 amène à proposer un nouveau modèle, dont les aspects relativistes furent décrits par Paul Dirac en 1928 ; il permet d'expliquer la stabilité de l'atome et la description des termes spectroscopiques.
Dans ce modèle, les électrons ne sont plus des billes localisées en orbite, mais des nuages de probabilité de présence. Ce point de vue, révolutionnaire, peut choquer en première approche. Cependant la représentation que l'on pouvait se faire d'un électron — une petite bille ? — était dictée par les formes observées dans le monde macroscopique, transposées sans preuves dans le monde microscopique. Il faut bien se douter du fait que ce que l'on connaît de l'électron ne repose que sur des manifestations indirectes : courant électrique, tube cathodique (télévision)…
Depuis les années 1930, on modélise ainsi l'électron par une « fonction d'onde », généralement notée Ψ, dont le carré de la norme représente la densité de probabilité de présence. Pour représenter fidèlement les propriétés de l'électron, on ne dispose que de fonctions mathématiques compliquées ; cette abstraction rebute encore bien des physiciens. Nous essayons ci-dessous de donner une image de la notion de fonction d'onde, image nécessairement imparfaite.
De manière un peu plus exacte : un électron, hors d'un atome, est représenté par un paquet d'ondes, qui peut être considéré, dans certaines limites, comme une petite bille. La mécanique quantique démontre qu'un tel paquet d'ondes s'étale au cours du temps ; au contraire, un électron d'un atome conserve la structure de la fonction d'onde associée à l'orbite qu'il occupe (tant qu'il n'est pas éjecté de l'atome). La mécanique quantique postule donc, non la conservation de la forme (non connue) de l'électron, mais la conservation de l'intégrale de la probabilité de présence.
Dans le modèle de Schrödinger, les nuages correspondant aux différents électrons s'interpénètrent ; il n'est pas question de se donner une représentation individuelle des électrons chacun sur son orbite, comme cela était dans le cas du modèle de Bohr. Cela est d'autant plus vrai que les électrons sont des particules identiques indiscernables. Les effets d'échange amènent à considérer que chaque électron de l'atome est à la fois sur chaque orbitale occupée (correspondant à une configuration électronique donnée). L'ionisation de l'atome (l'arrachement d'un électron de l'atome) peut alors être représentée par le schéma simplifié ci-dessous.
Pour éviter des complications inutiles, on considérera l'atome le plus simple afin de montrer quelques schémas dévoilant les points fondamentaux du modèle :
Soit ρ(r, θ, φ) la densité de probabilité de présence au point de coordonnées sphériques (r, θ, φ). Pour l'état fondamental, la densité de probabilité, ρ, est maximale au centre de l'atome. Considérons maintenant la densité radiale de probabilité de présence (à la distance r du noyau, toutes les directions confondues) :
cette densité radiale est maximale pour r = r1 de la première orbite du modèle de Bohr (dans l'expression ci-dessus, on a tenu compte de la symétrie sphérique de ρ, identique pour toutes les directions). On a en fait :
En fonction de l'état quantique de l'électron (fondamental, excité…) ces nuages peuvent prendre différentes formes, qui sont décrites en particulier par les harmoniques sphériques. La forme la plus simple est la symétrie sphérique, montrée en particulier, ci-dessus, dans le cas de l'état fondamental, |1s>.
Des combinaisons linéaires de fonctions d'onde, utilisant des harmoniques sphériques distinctes, permettent l'apparition d'une anisotropie qui va devenir essentielle pour le passage de la notion d'atome à celle de molécule. Le schéma ci-contre montre une coupe de la densité de probabilité de présence de l'orbitale hybride |



2
s

p

z




{\displaystyle 2sp_{z}}

 > de l'atome d'hydrogène, coupe contenant Oz axe de symétrie de l'orbitale atomique. Pour cet exemple, l'axe Oz devient une direction privilégiée, mais de plus la densité de probabilité de présence s'étale plus loin pour une orientation donnée.
Ce modèle permet d'expliquer :
On notera pour terminer que des corrections relativistes sont à apporter, dans le cas des atomes de numéro atomique élevé, pour la détermination des niveaux internes (les vitesses des électrons sur les orbites du modèle de Bohr sont alors importantes).
Si la mécanique quantique permit d'expliquer rapidement les caractéristiques spectroscopiques des atomes et des molécules, le cœur de l'atome, son noyau, fut plus difficile à comprendre. Les difficultés sont ici de deux ordres : l'une correspondant à l'importance de l'énergie des particules sondes permettant d'atteindre les dimensions de l'ordre du fermi, l'autre à la nécessaire invention d'au moins une interaction supplémentaire permettant la stabilité d'un noyau constitué de protons (qui se repoussent électriquement) et de neutrons.
Cette compréhension de la cohésion du noyau devait aussi expliquer les phénomènes de radioactivité alpha, bêta et gamma, dont les premières observations dataient de la dernière décennie du XIXe siècle.
La décennie qui précéda la Seconde Guerre mondiale mena à la découverte des deux interactions maîtresses de la stabilité du cœur : l'interaction forte et l'interaction faible. La petitesse de la portée de ces deux interactions, respectivement 10-15 m et 10-18 m explique les difficultés expérimentales rencontrées. Les difficultés théoriques ne manquent pas, non plus ; il ne s'agit pas de lois physiques aussi simples que celles de l'électromagnétisme, même compliquées par la mécanique quantique, mais de la compréhension de toutes les particules élémentaires… L'invention des quarks et des gluons donne ainsi la vision actuelle de l'interaction qui maintient ensemble les nucléons.
Cette physique nucléaire mène aussi à l'explication de la nucléosynthèse, expliquant les aspects nucléaires du tableau de Mendeleïev. On se retrouve là dans le foisonnement de la naissance de l'univers et de la dynamique des étoiles.
Un atome est couramment désigné par son symbole chimique, complété par son nombre de masse A (égal au nombre de nucléons de l'atome) placé en haut et à gauche du symbole.
Exemple : le carbone 12 de nombre de masse 12 est noté 







12



C




{\displaystyle {}^{12}\mathrm {C} \,}

.
Il est d'usage de compléter cette écriture par le numéro atomique Z, placé en bas et à gauche du symbole, pour décrire une réaction nucléaire dans laquelle intervient un isotope.
Le carbone 12 est ainsi noté 







 
6


12



C




{\displaystyle {}_{\ 6}^{12}\mathrm {C} \,}

.
Ainsi, le carbone 14 







 
6


14



C




{\displaystyle {}_{\ 6}^{14}\mathrm {C} \,}

 et le carbone 12 







 
6


12



C




{\displaystyle {}_{\ 6}^{12}\mathrm {C} \,}

 sont deux isotopes.
Sur les autres projets Wikimedia :
