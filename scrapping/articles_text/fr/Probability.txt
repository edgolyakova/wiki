



Probabilité — Wikipédia




































Aller au contenu





Afficher / masquer la barre latérale












Rechercher















Créer un compte





Outils personnels


 Créer un compte
 Se connecter


		Pages pour les contributeurs déconnectés en savoir plus


DiscussionContributions










Navigation


AccueilPortails thématiquesArticle au hasardContact




Contribuer


Débuter sur WikipédiaAideCommunautéModifications récentesFaire un don




Outils


Pages liéesSuivi des pages liéesTéléverser un fichierPages spécialesLien permanentInformations sur la pageCiter cette pageÉlément Wikidata




Imprimer / exporter


Créer un livreTélécharger comme PDFVersion imprimable




Dans d’autres projets


Wikimedia Commons




Langues

Sur cette version linguistique de Wikipédia, les liens interlangues sont placés en haut à droite du titre de l’article.Aller en haut.















				Sommaire
				déplacer vers la barre latérale
masquer





Début





1Historique







2Terminologies


					Afficher / masquer la sous-section Terminologies
				




2.1Probabilité et certitude







2.2Probabilités d'un événement







2.3Théorie des probabilités





2.3.1Axiomatique







2.3.2Variables aléatoires, lois et caractérisations







2.3.3Convergence et théorèmes limites







2.3.4Calcul stochastique









2.4Doctrine des probabilités









3Interprétation des probabilités







4Vulgarisation







5Applications


					Afficher / masquer la sous-section Applications
				




5.1Liens avec la statistique





5.1.1Exemple 1







5.1.2Exemple 2







5.1.3Exemple 3











6Notes et références


					Afficher / masquer la sous-section Notes et références
				




6.1Notes







6.2Références





6.2.1Ouvrages







6.2.2Articles et autres sources











7Voir aussi


					Afficher / masquer la sous-section Voir aussi
				




7.1Bibliographie







7.2Articles connexes







7.3Liens externes














						Basculer la table des matières
					
Probabilité



107 langues


AfrikaansAlemannischአማርኛAragonésالعربيةঅসমীয়াAsturianuAymar aruAzərbaycancaتۆرکجهБашҡортсаBoarischБеларускаяБеларуская (тарашкевіца)БългарскиবাংলাBosanskiБуряадCatalàНохчийнکوردیČeštinaЧӑвашлаCymraegDanskDeutschΕλληνικάEnglishEsperantoEspañolEestiEuskaraفارسیSuomiNordfriiskGaeilge贛語Kriyòl gwiyannenGalegoעבריתहिन्दीHrvatskiՀայերենInterlinguaBahasa IndonesiaIlokanoIdoÍslenskaItaliano日本語PatoisქართულიKabɩyɛҚазақшаಕನ್ನಡ한국어LatinaLëtzebuergeschLietuviųLatviešuМакедонскиമലയാളംBahasa MelayuMaltiမြန်မာဘာသာNederlandsNorsk nynorskNorsk bokmålOccitanਪੰਜਾਬੀPicardPolskiPiemontèisپنجابیپښتوPortuguêsRomânăРусскийSicilianuScotsSrpskohrvatski / српскохрватскиSimple EnglishSlovenčinaSlovenščinaSoomaaligaShqipСрпски / srpskiSundaSvenskaKiswahiliதமிழ்ТоҷикӣไทยTagalogTürkçeТатарча/tatarçaУкраїнськаاردوOʻzbekcha/ўзбекчаVènetoTiếng ViệtWinaray吴语ייִדיש中文Bân-lâm-gú粵語
Modifier les liens









ArticleDiscussion





français











LireModifierModifier le codeVoir l’historique







Plus


LireModifierModifier le codeVoir l’historique










Un article de Wikipédia, l'encyclopédie libre.



Pour les articles homonymes, voir Probabilité (homonymie).



Cet article présente les notions générales concernant les probabilités ; pour une approche  élémentaire du calcul des probabilités voir Probabilités (mathématiques élémentaires) ; pour la théorie mathématique rigoureuse correspondante, voir Théorie des probabilités ; pour l'historique de ces notions, voir Histoire des probabilités ; pour l'analyse des concepts de probabilité et l'interprétation des probabilités, voir Interprétations de probabilité.


 Quatre dés à six faces de quatre couleurs différentes. Les six faces possibles sont visibles.
Le terme probabilité possède plusieurs sens : venu historiquement du latin probabilitas, il désigne l'opposé du concept de certitude ; il est également une évaluation du caractère probable d'un événement, c'est-à-dire qu'une valeur permet de représenter son degré de certitude ; récemment, la probabilité est devenue une science mathématique et est appelée théorie des probabilités ou plus simplement probabilités ; enfin une doctrine porte également le nom de probabilisme.
La probabilité d'un événement est un nombre réel compris entre 0 et 1. Plus ce nombre est grand, plus le risque, ou la chance, que l'événement se produise est grand. L'étude scientifique des probabilités est relativement récente dans l'histoire des mathématiques. L'étude des probabilités a connu de nombreux développements depuis le XVIIIe siècle grâce à l'étude de l'aspect aléatoire et en partie imprévisible de certains phénomènes, en particulier les jeux de hasard. Ceux-ci ont conduit les mathématiciens à développer une théorie qui a ensuite eu des implications dans des domaines aussi variés que la météorologie, la finance ou la chimie.


Historique[modifier | modifier le code]
Article détaillé : Histoire des probabilités.
À l'origine, dans les traductions d'Aristote, le mot « probabilité » ne désigne pas une quantification du caractère aléatoire d'un fait, mais la perception qu'une idée est communément admise par tous. Ce n'est qu'au cours du Moyen Âge, puis de la Renaissance, autour des commentaires successifs et des imprécisions de traduction de l'œuvre d'Aristote, que ce terme connaîtra un glissement sémantique pour finir par désigner la vraisemblance d'une idée. 
L'apparition de la notion de « risque », préalable à l'étude des probabilités, n'est apparue qu'au XIIe siècle, pour l'évaluation de contrats commerciaux avec le Traité des contrats de Pierre de Jean Olivi[1], et s'est développée au XVIe siècle, avec la généralisation des contrats d'assurance maritime[2]. À part quelques considérations élémentaires par Girolamo Cardano[3] au début du XVIe siècle, et par Galilée au début du XVIIe siècle, le véritable début de la théorie des probabilités date de la correspondance entre Pierre de Fermat et Blaise Pascal, en 1654.
C'est dans la deuxième moitié du XVIIe siècle, à la suite des travaux de Blaise Pascal, Pierre de Fermat et Christian Huygens[b 1],[a 1] sur le problème des partis, que le terme « probabilité » prend peu à peu son sens actuel, avec les développements du traitement mathématique du sujet par Jakob Bernoulli. 
Au XVIIIe siècle, Gabriel Cramer donne un cours sur la logique probabiliste qui deviendra une base à l'article probabilité de l'encyclopédie de Diderot, écrite à la fin de ce même siècle[a 2]. Ce n'est alors qu'au XIXe siècle qu'apparaît ce qui peut être considéré comme la théorie moderne des probabilités en mathématiques. 
Le calcul des probabilités prend un nouvel essor au début du XXe siècle, avec l'axiomatique de Kolmogorov; commence alors la théorie des probabilités. Les probabilités deviennent une science et une théorie, comme branche des mathématiques[4].

Terminologies[modifier | modifier le code]
Ainsi, il existe plusieurs notions que nous détaillerons dans les sections suivantes : 

la probabilité d'un fait caractérise la possibilité que ce fait se produise, une vraisemblance, une apparence de vérité[a 3]. (définition 2 du Larousse[a 4]). Le probable, la connaissance probable ou la logique probabiliste[a 2] sont des termes utilisés, notamment au XVIIIe siècle, pour désigner une connaissance intermédiaire entre la certitude de la vérité et la certitude de la fausseté.
Voir l'article du wiktionnaire : probable ;

les probabilités d'un fait donnent le pourcentage de chance qu'un fait se produise, c'est-à-dire qu'elles donnent une ou plusieurs valeurs (ou pourcentages) de la possibilité qu'il se produise. Cette notion se rapproche de la notion mathématique de loi de probabilité (définition 1 du Larousse[a 4]). Plus formellement, c'est le rapport du nombre de cas favorables au nombre de cas possibles[a 3].
Voir l'article : probabilités (mathématiques élémentaires) ;

les probabilités ou le calcul des probabilités ou la théorie des probabilités sont la théorie mathématique qui étudie le caractère probable des événements (définition 1 du Larousse[a 4]).
Voir l'article : théorie des probabilités ;

la doctrine des probabilités ou probabilisme est une doctrine de théologie morale qui enseigne qu'on peut suivre une opinion, pourvu qu'elle soit probable[a 3].Voir l'article : probabilisme.
Probabilité et certitude[modifier | modifier le code]
Le premier usage du mot probabilité apparaît en 1370 avec la traduction de l'éthique à Nicomaque d'Aristote par Oresme, et désigne alors « le caractère de ce qui est probable »[a 3]. Le concept de probable chez Aristote (ενδοξον, en grec) est ainsi défini dans les Topiques[5] :


« Sont probables les opinions qui sont reçues par tous les hommes, ou par la plupart d'entre eux, ou par les sages, et parmi ces derniers, soit par tous, soit par la plupart, soit enfin par les plus notables et les plus illustres. »


Ce qui rend une opinion probable chez Aristote est son caractère généralement admis[a 5]; ce n'est qu'avec la traduction de Cicéron des Topiques d'Aristote, qui traduit par probabilis ou par verisimilis, que la notion de vraisemblance est associée à celle de « probabilité », ce qui aura un impact au cours du Moyen Âge puis de la Renaissance, avec les commentaires successifs de l'œuvre d'Aristote[a 6].
Une phrase, situation ou proposition est vraie ou fausse. Sa probabilité est la « connaissance évidente de la vérité ou de la fausseté d'une proposition »[a 2]. La notion d'incertitude est quant à elle le défaut de cette connaissance. Pour une proposition, il existe alors trois cas[a 2] :

la proposition est reconnue comme vraie avec certitude ;
la proposition est reconnue comme fausse avec certitude ;
elle est probable si on ne peut la reconnaître vraie ou fausse. Dans ce cas, il est possible de mesurer une certaine vraisemblance par la connaissance du nombre de conditions requises pour être reconnue vraie.
Cette représentation développée par Cramer permet de faire apparaître une manière de mesurer la notion d'incertitude ou de probabilité. Il donne alors la définition suivante de la probabilité :


Définition (Gabriel Cramer)[a 2] — Puisque la certitude entière naît de l'assurance que l'on a de l'existence de toutes les conditions requises pour certaines vérités, et la probabilité de la connaissance qu'on a de l'existence de quelques-unes de ces conditions, on regarde la certitude comme un tout et la probabilité comme une partie. Le juste degré de probabilité d'une proposition sera donc exactement connu quand on pourra dire et prouver que cette probabilité monte à demi certitude ou au trois quarts de la certitude entière, ou seulement au tiers de la certitude, etc.


Probabilités d'un événement[modifier | modifier le code]
Articles détaillés : probabilités (mathématiques élémentaires) et loi de probabilité.
Comme précisé précédemment, la notion de probabilité permet de quantifier le hasard. La formalisation du début du XXe siècle est aujourd'hui unanimement utilisée. (par exemple, voir l'ouvrage de Jacod et Protter[6] pour cette section)
La probabilité d'un certain événement A, notée 




P

(
A
)


{\displaystyle \mathbb {P} (A)}

, associe une valeur entre 0 et 1 que l'événement se réalise. Lorsque 




P

(
A
)
=
1


{\displaystyle \mathbb {P} (A)=1}

, l'événement est dit presque sûr (ou quasi certain), c'est-à-dire qu'il a « toutes les chances » de se réaliser. À l'inverse si 




P

(
A
)
=
0


{\displaystyle \mathbb {P} (A)=0}

, A est dit négligeable (ou quasi impossible), c'est-à-dire qu'il a une chance nulle de se réaliser.
La probabilité d'un événement A peut s'obtenir de manière fréquentiste, notamment lorsqu'il est possible de faire une expérience plusieurs fois et de compter le nombre de succès de l'expérience. En effet, si on effectue n fois une expérience indépendamment et que dans nA fois des cas, l'événement A est réalisé, alors, la probabilité de A est donnée par : 





P

(
A
)
=

lim

n
→
∞





n

A


n




{\displaystyle \mathbb {P} (A)=\lim _{n\rightarrow \infty }{\frac {n_{A}}{n}}}

.
De manière plus probabiliste, lorsque le nombre de résultats possibles de l'expérience est fini et que ces résultats sont équiprobables, la probabilité de A est obtenue par :





P

(
A
)
=




nombre de cas o




u
`




 

A

 se r




e
´




alise


nombre de cas possibles




{\displaystyle \mathbb {P} (A)={\frac {{\text{nombre de cas o}}\mathrm {\grave {u}} {\text{ }}A{\text{ se r}}\mathrm {\acute {e}} {\text{alise}}}{\text{nombre de cas possibles}}}}

.
Mathématiquement, l'événement A est un sous-ensemble d'un ensemble Ω qui représente toutes les éventualités possibles. Pour obtenir une théorie, des axiomes ont été proposés par Kolmogorov : la probabilité 




P



{\displaystyle \mathbb {P} }

 doit vérifier :

pour tout événement A, 



0
≤

P

(
A
)
≤
1


{\displaystyle 0\leq \mathbb {P} (A)\leq 1}

,





P

(
Ω
)
=
1


{\displaystyle \mathbb {P} (\Omega )=1}

,





P

(
A
∪
B
)
=

P

(
A
)
+

P

(
B
)


{\displaystyle \mathbb {P} (A\cup B)=\mathbb {P} (A)+\mathbb {P} (B)}

 pour 



A
∩
B
=
∅


{\displaystyle A\cap B=\emptyset }

.
Grâce à cette description, plusieurs notions peuvent s'écrire de manière mathématique.

Article détaillé : Indépendance (probabilités).
Deux événements sont dits indépendants si le fait de connaître la probabilité du premier événement ne nous aide pas pour prévoir la probabilité du second et inversement. Mathématiquement, cela s'écrit : 




P

(
A
∩
B
)
=

P

(
A
)

P

(
B
)


{\displaystyle \mathbb {P} (A\cap B)=\mathbb {P} (A)\mathbb {P} (B)}

. Par exemple, la probabilité d'obtenir un as à un premier jeté de dé et d'obtenir un as au deuxième jeté de dé est la multiplication des deux probabilités et vaut 1/36.

Article détaillé : Probabilité conditionnelle.
Il est possible de considérer la probabilité d'un événement (notons le A) conditionnellement à un autre (noté B). Lorsque les deux événements ne sont pas indépendants, le fait de connaître la probabilité de l'un influence la probabilité de l'autre par la formule : 




P

(
A
∣
B
)
=

P

(
A
∩
B
)

/


P

(
B
)


{\displaystyle \mathbb {P} (A\mid B)=\mathbb {P} (A\cap B)/\mathbb {P} (B)}

. Par exemple, la probabilité d'obtenir la somme des deux dés égale à 12 lorsque le premier dé a donné 6 vaut 1/6.

Articles détaillés : Formule de Poincaré, Formule des probabilités totales et Théorème de Bayes.
Des formules existent pour pouvoir calculer tout type de probabilité. C'est le cas de la formule de Poincaré, de la formule des probabilités totales ou du théorème de Bayes.

Théorie des probabilités[modifier | modifier le code]
Article détaillé : théorie des probabilités.
Encouragé par Pascal, Christian Huygens publie De ratiociniis in ludo aleae (raisonnements sur les jeux de dés) en 1657. Ce livre est le premier ouvrage important sur les probabilités. Il y définit la notion d'espérance et y développe plusieurs problèmes de partages de gains lors de jeux ou de tirages dans des urnes[7]. Deux ouvrages fondateurs sont également à noter : Ars Conjectandi de Jacques Bernoulli (posthume, 1713) qui définit la notion de variable aléatoire et donne la première version de la loi des grands nombres[8], et Théorie de la probabilité d'  Abraham de Moivre (1718) qui généralise l'usage de la combinatoire[9].
La théorie de la probabilité classique ne prend réellement son essor qu'avec les notions de mesure et d'ensembles mesurables qu'Émile Borel introduit en 1897. Cette notion de mesure est complétée par Henri Léon Lebesgue et sa théorie de l'intégration[10]. La première version moderne du théorème central limite est donnée par Alexandre Liapounov en 1901[11] et la première preuve du théorème moderne est donnée par Paul Lévy en 1910. En 1902, Andrei Markov introduit les chaînes de Markov[12] pour entreprendre une généralisation de la loi des grands nombres pour une suite d'expériences dépendant les unes des autres. Ces chaînes de Markov connaîtront de nombreuses applications, entre autres pour modéliser la diffusion ou pour l'indexation de sites internet sur Google.
Il faudra attendre 1933 pour que la théorie des probabilités sorte d'un ensemble de méthodes et d'exemples divers et devienne une véritable théorie, axiomatisée par Kolmogorov[13].
Kiyoshi Itô met en place une théorie et un lemme qui porte son nom dans les années 1940[14]. Ceux-ci permettent de relier le calcul stochastique et les équations aux dérivées partielles, faisant ainsi le lien entre analyse et probabilités. Le mathématicien Wolfgang Doeblin avait de son côté ébauché une théorie similaire avant de se suicider à la défaite de son bataillon en juin 1940. Ses travaux furent envoyés à l'Académie des sciences dans un pli cacheté qui ne fut ouvert qu'en 2000[15].

Axiomatique[modifier | modifier le code]
Articles détaillés : Axiomes des probabilités et Espace probabilisé.
Au début du XXe siècle, Kolmogorov définit des axiomes mathématiques afin de pouvoir étudier le hasard. Ainsi il construit l'espace des possibles, appelé univers, qui contient tous les hasards possibles, il le munit d'un ensemble qui contient les sous-ensembles de l'univers, appelés tribu, et d'une mesure de probabilité qui permet de calculer les probabilités correspondantes. L'espace 



(
Ω
,


A


,

P

)


{\displaystyle (\Omega ,{\mathcal {A}},\mathbb {P} )}

 ainsi construit vérifie les trois axiomes des probabilités[16] :

(Positivité) la probabilité d'un événement est une valeur entre 0 et 1 : pour tout 



A
∈


A




{\displaystyle A\in {\mathcal {A}}}

, 



0
≤

P

(
A
)
≤
1


{\displaystyle 0\leq \mathbb {P} (A)\leq 1}

 ;
(Masse unitaire) la probabilité de l'univers est 1 : 




P

(
Ω
)
=
1


{\displaystyle \mathbb {P} (\Omega )=1}

 ;
(Additivité) pour toute suite dénombrable d'événements 




A

1


,

A

2


,
⋯
∈


A




{\displaystyle A_{1},A_{2},\dots \in {\mathcal {A}}}

 disjoints deux à deux, c'est-à-dire tels que 




A

i


∩

A

j


=
∅


{\displaystyle A_{i}\cap A_{j}=\emptyset }

 pour tous 



i
≠
j


{\displaystyle i\neq j}

, alors : 




P


(


⋃

i
≥
1



A

i



)

=

∑

i
≥
1



P

(

A

i


)


{\displaystyle \mathbb {P} \left(\bigcup _{i\geq 1}A_{i}\right)=\sum _{i\geq 1}\mathbb {P} (A_{i})}

.
Variables aléatoires, lois et caractérisations[modifier | modifier le code]
Article détaillé : Variable aléatoire.
Afin de pouvoir mieux manipuler le hasard, il est commode d'utiliser une variable aléatoire. Elle peut être réelle, mais peut aussi être multidimensionnelle, ou même plus générale. Cette variable réelle est, en théorie, une application : 



X
:
Ω
→

R



{\displaystyle X:\Omega \rightarrow \mathbb {R} }

 [17] qui à chaque aléa 



ω
∈
Ω


{\displaystyle \omega \in \Omega }

, associe le résultat de l'expérience : 



X
(
ω
)


{\displaystyle X(\omega )}

.

Article détaillé : Loi de probabilité.
Cette variable possède une répartition de ses valeurs donnée par sa loi de probabilité, qui est une mesure. Cette dernière peut être représentée de nombreuses manières, les plus communes étant par l'utilisation de la fonction de répartition, la densité de probabilité (si elle existe) ou la fonction de masse, le cas échéant. De nombreuses propriétés des lois de probabilité, et donc des variables aléatoires, peuvent être étudiées : espérance, moments, indépendance entre plusieurs variables, etc.

Convergence et théorèmes limites[modifier | modifier le code]
Article détaillé : Convergence de variables aléatoires.
Il est possible de considérer une infinité de variables aléatoires : 



(

X

n


,
n
∈

N

)


{\displaystyle (X_{n},n\in \mathbb {N} )}

. Dans ce cas, y a-t-il une limite possible? La question de notion de convergence aléatoire se pose alors. Il existe plusieurs types de convergences[18] : la convergence en loi qui est la convergence de la loi de la variable (en tant que mesure), la convergence en probabilité, la convergence presque sûre ou encore la convergence en moyenne.

Articles détaillés : Loi des grands nombres et Théorème central limite.
De nombreux théorèmes limites existent alors. Les plus connus sont : la loi des grands nombres qui annonce que la moyenne des n premières variables aléatoires converge vers la moyenne théorique de la loi commune des variables aléatoires[19] ; le théorème central limite, qui donne la bonne renormalisation de la somme des variables aléatoires pour avoir une limite non triviale[20].

Calcul stochastique[modifier | modifier le code]
Articles détaillés : calcul stochastique, Marche aléatoire, Chaîne de Markov, Processus stochastique, Processus de Markov et Martingale (calcul stochastique).
Le calcul stochastique est l'étude des phénomènes qui évoluent au cours du temps de manière aléatoire[21]. Le temps peut être modélisé de manière discrète, c'est-à-dire par les valeurs entières : 



0
,
1
,
2
,
…


{\displaystyle 0,1,2,\dots }

, dans ce cas le phénomène est représenté par une suite (infinie) de variables aléatoires : 



(

X

n


,
n
≥
0
)


{\displaystyle (X_{n},n\geq 0)}

, c'est une marche aléatoire. Le temps peut également être modélisé de manière continue, c'est-à-dire par des valeurs réelles 



t
∈


R


+




{\displaystyle t\in \mathbb {R} _{+}}

 ou 



t
∈

R



{\displaystyle t\in \mathbb {R} }

, il s'agit alors d'un processus stochastique 



(

X

t


,
t
≥
0
)


{\displaystyle (X_{t},t\geq 0)}

.
Plusieurs propriétés sont alors liées au calcul stochastique : la propriété de Markov annonce que le mouvement futur du phénomène ne dépend que de l'état présent et non pas du mouvement passé ; la récurrence et la transience d'une chaîne de Markov assurent le retour ou le passage unique en un état donné ; une martingale est un processus tel que l'état futur est déterminé en moyenne par l'état présent, etc.

Doctrine des probabilités[modifier | modifier le code]
Article détaillé : probabilisme.
La doctrine de la probabilité, autrement appelée probabilisme, est une théologie morale catholique qui s'est développée au cours du XVIe siècle, sous l'influence, entre autres, de Bartolomé de Medina et des jésuites. Avec l'apparition de la doctrine de la probabilité, ce terme connaîtra un glissement sémantique pour finir par désigner, au milieu du XVIIe siècle, le caractère vraisemblable d'une idée.
La probabilité d'une opinion désigne alors, au milieu du XVIIe siècle, la probabilité qu'une opinion soit vraie. Ce n'est qu'à partir de la fin du XVIIe siècle, avec l'émergence de la probabilité mathématique, que la notion de probabilité ne concernera plus seulement les opinions et les idées, mais aussi les faits, et se rapprochera de la notion de hasard[b 2] que l'on connaît aujourd'hui.

Interprétation des probabilités[modifier | modifier le code]
Article détaillé : Interprétations de probabilité.
Lors de l'étude d'un phénomène aléatoire, il existe plusieurs façons d'aborder la notion de probabilité liée à ce phénomène[a 7].

La conception subjective de la probabilité d'un événement s'applique dans le cas où il est difficile, voire impossible, de connaître les différentes probabilités des résultats d'une expérience aléatoire. Notamment dans le cas où l'expérience ne peut se réaliser plusieurs fois dans les mêmes conditions. Les probabilités attribuées ne correspondent alors pas exactement à la réalité, et leurs estimations peuvent varier selon les personnes et les situations. On parle dans ce cas de probabilité épistémique ou de probabilité bayésienne. Il s'agit d'une probabilité s'appliquant au jugement que l'on porte plus que sur l'événement lui-même[22],[23].
Par exemple : quelle est la probabilité de réussir à un examen ? Pour connaître les chances d'obtenir une note donnée à un examen, il faut l'estimer suivant le candidat et sa situation par rapport à l'examen. Il n'est pas possible de réaliser plusieurs fois l'expérience puisqu'un examen ne peut se passer plus d'une fois dans la même configuration. Les probabilités estimées et choisies pour chaque note vérifient les axiomes de Kolmogorov mais sont subjectives.

La conception fréquentiste des probabilités d'un événement est plus historique. Elle permet d'attribuer les chances de réalisation de chaque événement par une méthode statistique, c'est-à-dire en réalisant plusieurs fois l'expérience et d'en déduire les probabilités liées aux événements. Idéalement il faudrait répéter l'expérience à l'infini pour obtenir les probabilités réelles de l'expérience, cependant, puisque ce n'est pas possible, les méthodes expérimentales donnent des probabilités empiriques. (voir la section Les probabilités d'un événement ci-dessus). Cette notion s'appelle également probabilité statistique ou probabilité a posteriori[a 3].Par exemple : un joueur possède un dé pipé dont il ne connaît pas le biais, c'est-à-dire que les valeurs du dé n'ont pas les mêmes chances d'apparaître. Une méthode possible est de réaliser un grand nombre de lancers et de compter les résultats obtenus. Les résultats sont alors approchés pour vérifier l'axiomatique de Kolmogorov.
La conception classique de la probabilité s'utilise dans le cas de situations prédéfinies considérées comme connues. Beaucoup de situations sont considérées comme aléatoires et équiprobables, c'est-à-dire que chaque événement élémentaire à la même chance d'apparaître. Cette conception est également appelée objective, probabilité mathématique ou probabilité a priori[a 3].Par exemple : un dé (non pipé) est supposé équilibré, c'est-à-dire que chaque valeur a une chance sur six d'apparaître. Lors d'une distribution de cartes, chaque donne est supposée apparaître avec les mêmes chances.
Une notion philosophique apparaît alors : puisque nous ne connaissons la nature et le monde autour de nous que par notre expérience et notre point de vue, nous ne le connaissons que de manière subjective et ne pouvons estimer précisément les lois objectives qui les dirigent.

Vulgarisation[modifier | modifier le code]
Le Giec utilise pour les résumés pour décideurs de ses rapports un langage naturel calibré[24]. 
« Les qualificatifs ci-après ont été utilisés pour indiquer la probabilité évaluée d’un résultat : quasiment certain (probabilité de 99 à 100 %), très probable (90 à 100 %), probable (66 à 100 %), à peu près aussi probable qu’improbable (33 à 66 %), improbable (0 à 33 %), très improbable (0 à 10 %), exceptionnellement improbable (0 à 1 %). La probabilité évaluée est indiquée en italique : par exemple très probable... D’autres qualificatifs peuvent également être utilisés le cas échéant : extrêmement probable (95 à 100 %), plus probable qu’improbable (> 50 à 100 %), plus improbable que probable (0 à < 50 %) et extrêmement improbable (0 à 5 %). Enfin, ce Rapport utilise également les expressions «  fourchette probable » et « fourchette très probable » qui signifient que la probabilité évaluée d’un résultat se situe dans la fourchette de 17 à 83 % ou de 5 à 95 %. »

Applications[modifier | modifier le code]
Les jeux de hasard sont l'application la plus naturelle des probabilités mais de nombreux autres domaines s'appuient ou se servent des probabilités. Citons entre autres :

la statistique est un vaste domaine qui s'appuie sur les probabilités pour le traitement et l'interprétation des données ;
La théorie des jeux s'appuie fortement sur la probabilité et est utile en économie et plus précisément en micro-économie ;
l'estimation optimale par usage de la loi de Bayes, qui sert de fondement à une grande partie des applications de décision automatique (imagerie médicale, astronomie, reconnaissance de caractères, filtres anti-pourriel) ;
en physique ainsi qu'en biologie moléculaire l'étude du mouvement brownien pour de petites particules ainsi que les équations de Fokker-Planck font intervenir des concepts s'appuyant sur le calcul stochastique et la marche aléatoire ;
les mathématiques financières font un large usage de la théorie des probabilités pour l'étude des cours de la bourse et des produits dérivés. Par exemple le Modèle de Black-Scholes pour déterminer le prix de certains actifs financiers (notamment les options) ;
les études probabilistes de sûreté où l'on évalue la probabilité d'occurrence d'un événement indésirable. C'est devenu un outil d'évaluation des risques dans bon nombre d'installations industrielles.
Liens avec la statistique[modifier | modifier le code]
Article détaillé : Interconnexions entre la théorie des probabilités et la statistique.
Il existe plusieurs façons d'aborder les probabilités : le calcul a priori et le calcul a posteriori[25]. (voir la section interprétation des probabilités ci-dessus). Le calcul des probabilités a posteriori correspond à une attribution des valeurs des probabilités inconnues grâce au théorème de Bayes. 
Pour estimer les probabilités, les estimateurs statistiques sont utilisés afin de mieux approcher la variable recherchée[26]. Un estimateur est une valeur calculée à partir d'un échantillon de la population totale étudiée. Un estimateur est bien choisi, c'est-à-dire qu'il donnera une bonne estimation des valeurs recherchées, si c'est un estimateur sans biais et convergent ; autrement dit la moyenne empirique approche la moyenne théorique et l'estimateur converge vers la bonne variable aléatoire lorsque la taille de l'échantillon augmente. La méthode du maximum de vraisemblance permet de choisir un bon estimateur.
Par ces méthodes, il est possible de retrouver les paramètres inconnus d'une loi de probabilité associée au phénomène étudié[27].
La révision bayésienne est une autre méthode pour le calcul des probabilités a posteriori[a 8]. Celle-ci se fait grâce au théorème de Bayes :




P

(


hypothese



|



preuve


)
=




P

(


preuve



|



hypothese


)
×

P

(


hypothese


)



P

(


preuve


)



.


{\displaystyle \mathbb {P} ({\textrm {hypothese}}|{\textrm {preuve}})={\frac {\mathbb {P} ({\textrm {preuve}}|{\textrm {hypothese}})\times \mathbb {P} ({\textrm {hypothese}})}{\mathbb {P} ({\textrm {preuve}})}}.}


Dans cette formule, l'hypothèse représente ce que l'on suppose a priori sur le phénomène aléatoire, la preuve est une partie du phénomène que l'on connaît et que l'on peut mesurer. Le terme 




P

(


preuve



|



hypothese


)


{\displaystyle \mathbb {P} ({\textrm {preuve}}|{\textrm {hypothese}})}

 est appelé vraisemblance. Ainsi 




P

(


hypothese



|



preuve


)


{\displaystyle \mathbb {P} ({\textrm {hypothese}}|{\textrm {preuve}})}

 permet de mesurer la probabilité a posteriori de l'hypothèse que l'on fixe en tenant compte de la preuve.

Exemple 1[modifier | modifier le code]
La fréquence empirique permet d'estimer les probabilités. Dans un échantillon de n individus, il suffit de compter le nombre de fois où l'individu appartient à la catégorie A recherchée[28]. En notant 




n

A




{\displaystyle n_{A}}

 ce nombre parmi les n tirages, la fréquence 






n

A


n




{\displaystyle {\frac {n_{A}}{n}}}

 est proche de la probabilité 




P

(
A
)


{\displaystyle \mathbb {P} (A)}

 recherchée. Lors de 400 lancers de pièces, s'il apparaît 198 fois le côté face, alors on en déduit que la probabilité d'obtenir face est approximativement 




P

(

obtenir face

)
≃


198
400


=
0
,
495


{\displaystyle \mathbb {P} ({\text{obtenir face}})\simeq {\frac {198}{400}}=0,495}

. C'est un cas particulier de la loi des grands nombres. 0,495 est la valeur estimée de  




P

(

obtenir face

)


{\displaystyle \mathbb {P} ({\text{obtenir face}})}

.

Exemple 2[modifier | modifier le code]
Une liste de valeurs 




x

1


,

x

2


,
…
,

x

n




{\displaystyle x_{1},x_{2},\dots ,x_{n}}

 est connue, elle est supposée de loi normale dont la moyenne m est connue[27]. La question est de trouver l'écart type σ de la loi normale. La statistique T définie par 




T

2


=


1
n



∑

i
=
1


n


(

x

i


−
m

)

2




{\displaystyle T^{2}={1 \over n}\sum _{i=1}^{n}(x_{i}-m)^{2}}

 est un estimateur de σ, c'est-à-dire qu'il tend vers σ lorsque n tend vers l'infini.

Exemple 3[modifier | modifier le code]
On se demande quel temps il fera demain, la météo permet d'obtenir des informations supplémentaires. Certaines données sont alors connues : la probabilité que la météo annonce un beau temps sachant qu'il fera effectivement beau : 




P

(
M

|


beau

)
=
0
,
9


{\displaystyle \mathbb {P} (M|{\text{beau}})=0,9}

, la probabilité que la météo annonce un beau temps sachant qu'il pleuvra : 




P

(
M

|


pleut

)
=
0
,
2


{\displaystyle \mathbb {P} (M|{\text{pleut}})=0,2}

.
Une hypothèse est choisie : par exemple 




P

(

beau

)
=
1

/

2


{\displaystyle \mathbb {P} ({\text{beau}})=1/2}

, c'est-à-dire que l'on considère, a priori, qu'il y a une chance sur deux qu'il fera beau demain.
Il est alors possible de calculer la probabilité que la météo annonce un beau temps :




P

(
M
)
=

P

(
M

|


beau

)

P

(

beau

)
+

P

(
M

|


pleut

)

P

(

pleut

)
=
0
,
9
×
1

/

2
+
0
,
2
×
1

/

2
=
0
,
55.


{\displaystyle \mathbb {P} (M)=\mathbb {P} (M|{\text{beau}})\mathbb {P} ({\text{beau}})+\mathbb {P} (M|{\text{pleut}})\mathbb {P} ({\text{pleut}})=0,9\times 1/2+0,2\times 1/2=0,55.}


c'est-à-dire que la météo annonce un beau temps dans 55 % des cas. La probabilité qu'il fera beau demain sachant que la météo a annoncé beau temps est alors donnée par :




P

(

b
e
a
u


|

M
)
=




P

(
M

|



beau


)

P

(


beau


)



P

(
M
)



=
0
,
9
×
0
,
5

/

0
,
55.
≈
82
%
.


{\displaystyle \mathbb {P} (\mathrm {beau} |M)={\frac {\mathbb {P} (M|{\textrm {beau}})\mathbb {P} ({\textrm {beau}})}{\mathbb {P} (M)}}=0,9\times 0,5/0,55.\approx 82\%.}


Il est alors possible de réviser une deuxième fois l'hypothèse qu'il fera beau en regardant un deuxième bulletin météo d'une source différente. On prendrait alors comme nouvelle hypothèse la probabilité d'avoir un beau temps nouvellement calculée.

Notes et références[modifier | modifier le code]
Notes[modifier | modifier le code]

↑ Ces trois auteurs n'ont jamais utilisé le terme « probabilité » dans le sens qu'il prend par la suite avec le « calcul des probabilités ». 

↑ Pour désigner cette mathématique du probable, Pascal, en 1654, parle de « Géométrie du hasard ».



Références[modifier | modifier le code]
Ouvrages[modifier | modifier le code]

↑ SYLVAIN PIRON, « Le traitement de l’incertitude commerciale dans la scolastique médiévale », sur Journ@l Électronique d'Histoire des Probabilités et de la Statistique, juin 2007.

↑ (en) GIOVANNI CECCARELLI, « The Price for Risk-Taking: Marine Insurance and Probability Calculus in the Late Middle Age », sur Journ@l Électronique d'Histoire des Probabilités et de la Statistique, juin 2007.

↑ http://www.cict.fr/~stpierre/histoire/node1.html site sur l'histoire des probabilités

↑ Aslangul 2004, p. 1

↑ Tricot 1990, p. 16

↑ Jacod et Protter 2003, p. 7

↑ Les probabilités : Approche historique et définition.

↑ http://www.cict.fr/~stpierre/histoire/node3.html, une histoire de la probabilité jusqu'à Laplace

↑ Ian Hacking L'émergence des probabilités

↑ http://www.cict.fr/~stpierre/histoire/node4.html histoire des probabilités de Borel à la seconde guerre mondiale

↑ Entre De Moivre et Laplace

↑ DicoMaths : Chaine de Markov « Copie archivée » (version du 14 juin 2015 sur l'Internet Archive)

↑ un article sur la mise en place de l'axiomatisation  des probabilités.

↑ Biographie d'Itô sur le site de Mac Tutor

↑ Bernard Bru et Marc Yor (éd.), « Sur l'équation de Kolmogoroff, par W Doeblin », C. R. Acad. Sci. Paris, Série I 331 (2000). Sur la vie de Doeblin, voir Bernard  Bru, « La vie et l'œuvre de W. Doeblin (1915-1940) d'après les archives parisiennes », Math. Inform. Sci. Humaines 119 (1992), 5-51 et, en anglais, Biographie de Doeblin sur le site de Mac Tutor

↑ Sinaï 1992, p. 6

↑ Le Gall 2006, p. 93

↑ Bertoin 2000, p. 34

↑ Le Gall 2006, p. 120

↑ Le Gall 2006, p. 138

↑ Revuz et Yor 2004, p. 15

↑ Thierry Martin, La probabilité, un concept pluriel,Pour la Science, n°385, novembre 2009, p.46-50

↑ Mikaël Cozic, Isabelle Drouet, Interpréter les probabilités, Pour la Science, n°385, novembre 2009, p.52-58

↑ « L’océan et la cryosphère dans le contexte du changement climatique », 2019 (consulté le 24 janvier 2021), p. 6

↑ Saporta 2006, p. 319

↑ Saporta 2006, p. 289

↑ a et b Saporta 2006, p. 292

↑ Saporta 2006, p. 278



Articles et autres sources[modifier | modifier le code]

↑ Norbert Meusnier, « L'émergence d'une mathématique du probable au XVIIe siècle », Revue d'histoire des mathématiques, vol. 2,‎ 1996, p. 119-147 (lire en ligne).

↑ a b c d et e Thierry Martin, « La logique probabiliste de Gabriel Cramer », Mathematics and social sciences, vol. 4, no 176,‎ 2006, p. 43-60 (lire en ligne)

↑ a b c d e et f « Définition de probabilité », sur CNRTL

↑ a b et c « Définition : probabilité », sur Larousse

↑ Arnaud Macé, « Aristote - Définir, décrire, classer chez Aristote : des opérations propédeutiques à la connaissance scientifique des choses », Phulopsis,‎ 2006 (lire en ligne)

↑ Marta Spranzi Zuber, « Rhétorique, dialectique et probabilité au XVIe siècle », Revue de Synthèse, vol. 122, nos 2-4,‎ 2001, p. 297-317 (lire en ligne)

↑ David Stadelmann, « Les conceptions de la probabilité: Comparaison des différentes approches », 2003

↑ Christian Robert, « L'analyse statistique bayésienne », Courrier des statistiques,‎ 2001 (lire en ligne)



Voir aussi[modifier | modifier le code]

Sur les autres projets Wikimedia :

probabilités, sur le WiktionnaireProbabilité, sur Wikiversity


Bibliographie[modifier | modifier le code]
Sylvie Méléard, Aléatoire - Introduction à la théorie et au calcul des probabilités, Éditions de l'École Polytechnique, 2010
Claude Aslangul, Mathématiques pour physiciens, Université Pierre et Marie Curie, La science à Paris, 2004 (lire en ligne), chap. 8 
Jean Bertoin, Probabilités : cours de licence de mathématiques appliquées, 2000, 79 p. (lire en ligne) 
Bernard Courtebras, Mathématiser le hasard, Vuibert, 2008
(en) Jean Jacod et Philip E. Protter, Probability Essentials, Springer, 2003, 254 p. (lire en ligne) 
Jean-François Le Gall, Intégration, Probabilités et Processus aléatoires : cours de l'ENS, 2006, 248 p. (lire en ligne) 
(en) Daniel Revuz et Marc Yor, Continuous martingales and Brownian motion, vol. 293, Springer, 2004, 3e éd., 606 p. (lire en ligne) 
Gilbert Saporta, Probabilités, Analyse des données et Statistiques, Paris, Éditions Technip, 2006, 622 p. [détail des éditions] (ISBN 978-2-7108-0814-5, présentation en ligne).
(en) Iakov Sinaï, Probability theory : An introductory course, Berlin/Heidelberg/Paris etc., Springer, 1992, 138 p. (ISBN 3-540-53348-6, lire en ligne) 
J Tricot, Les topiques, vol. V, t. 1 à 8, VRIN, 1990, 368 p. (lire en ligne) 
Articles connexes[modifier | modifier le code]

Cindyniques
Chance
Plausibilité 
Probabilité (mathématiques élémentaires)
Statistique
Théorie des probabilités
Appel à la probabilité

Liens externes[modifier | modifier le code]
Journal électronique d'histoire des probabilités et de la statistique et site associé (articles, bibliographie, biographies)


v · mDomaines des mathématiques
 

Algèbre
Algèbre commutative
Algèbre homologique
Algèbre linéaire
Analyse
Analyse réelle
Analyse complexe
Analyse fonctionnelle
Analyse numérique
Calcul quantique
Combinatoire
Géométrie
Géométrie algébrique
Géométrie différentielle
Géométrie non commutative
Optimisation
Physique mathématique
Probabilités
Statistiques
Systèmes dynamiques
Théorie des nombres
Théorie de Galois
Théorie des groupes
Topologie
Topologie algébrique

 

v · mIndex du projet probabilités et statistiques
 

Théorie des probabilités
 
Bases théoriques


Principes généraux
Axiomes des probabilités · Espace probabilisable · Probabilité · Événement ·  Tribu · Indépendance · Variable aléatoire · Espérance ·  Variables iid
 
Convergence de lois
Théorème central limite · Loi des grands nombres · Théorème de Borel-Cantelli
 
Calcul stochastique
Marche aléatoire · Chaîne de Markov · Processus stochastique · Processus de Markov · Martingale · Mouvement brownien · Équation différentielle stochastique


 
Lois de probabilité


Lois continues
Loi exponentielle ·  Loi normale · Loi uniforme · Loi de Student · Loi de Fisher · Loi du χ²
 
Lois discrètes
Loi de Bernoulli ·  Loi binomiale · Loi de Poisson · Loi géométrique · Loi hypergéométrique


 
Mélange entre statistiques et probabilités


Intervalle de confiance





Théorie des statistiques
 
Statistiques descriptives


Bases théoriques

Une statistique
Caractère
Échantillon
Erreur type
Intervalle de confiance
Fonction de répartition empirique
Théorème de Glivenko-Cantelli
Inférence bayésienne
Régression linéaire
Méthode des moindres carrés
Analyse des données
Corrélation

 
Tableaux

Tableau de contingence
Tableau disjonctif complet
Table de Burt

 
Visualisation de données

Histogramme
Diagramme à barres
Graphique en aires
Diagramme circulaire
Treemap
Boîte à moustaches
Nuage de points
Graphique à bulles
Diagramme en cascade
Graphique en entonnoir
Diagramme de Kiviat
Corrélogramme
Graphique en forêt
Diagramme branche-et-feuille
Heat map
Sparkline

 
Paramètres de position

Moyenne arithmétique
Mode
Médiane
Quantile
Quartile
Décile
Centile

 
Paramètres de dispersion

Étendue
Écart moyen
Variance
Écart type
Déviation absolue moyenne
Écart interquartile
Coefficient de variation

 
Paramètres de forme

Coefficient d'asymétrie
Coefficient d'aplatissement



 
Statistiques inductives


Bases théoriques
Hypothèse statistique · Hypothèse nulle · Estimateur · Signification statistique · Sensibilité et spécificité · Courbe ROC · Nombre de sujets nécessaires · Valeur p · Contraste (statistiques) · Statistique de test · Taille d'effet · Puissance statistique
 
Tests paramétriques
Test d'hypothèse · Test de Bartlett · Test de normalité · Test de Fisher d'égalité de deux variances · Test d'Hausman · Test d'Anderson-Darling · Test de Banerji · Test de Durbin-Watson · Test de Goldfeld et Quandt · Test de Jarque-Bera · Test de Mood · Test de Lilliefors · Test de Wald · Test T pour des échantillons indépendants · Test T pour des échantillons appariés · Test de corrélation de Pearson
 
Tests non-paramétriques
Test U de Mann-Whitney · Test de Kruskal-Wallis · Test exact de Fisher · Test de Kolmogorov-Smirnov · Test de Shapiro-Wilk · Test de Chow · Test de McNemar · Test de Spearman · Tau de Kendall · Test Gamma · Test des suites de Wald-Wolfowitz · Test de la médiane · Test des signes · ANOVA de Friedman · Concordance de Kendall · Test Q de Cochran · Test des rangs signés de Wilcoxon · Test de Sargan





Application
 
Économétrie · Mécanique statistique · Jeu de hasard · Biomathématique · Biostatistique · Mathématiques financières


 

v · mLogique
 
Domaines académiques
Argumentation · Axiologie · Esprit critique · Philosophie · Histoire de la logique · Logique mathématique · Mathématique · Métamathématique · Théorie des modèles · Philosophie de la logique · Philosophie des mathématiques · Théorie des ensembles · Théorie de la démonstration
 
Concepts fondamentaux
Abduction · A priori · Jugement synthétique a priori · Déduction · Définition · Description · Implication · Inférence · Induction · Sens · Paradoxe · Mondes possibles · Présupposition · Probabilité · Raison · Référence · Sémantique · Syllogisme · Vérité · Valeur de vérité · Valide
 
Esprit critique et logique informelle
Affirmation · Analyse · Ambiguïté · Conclusion · Crédibilité · Évidence · Explication · Sophisme · Opinion · Parcimonie · Prémisse · Propagande · Prudence · Rhétorique
 
Théories de la déduction
Constructivisme · Atomisme logique · Logicisme · Nominalisme · Pragmatisme · Réalisme
 
Métalogique et métamathématique
Théorème de Cantor · Thèse de Church · Fondements des mathématiques · Théorème de complétude de Gödel · Théorème d'incomplétude de Gödel · Complétude · Décidabilité · Théorème de Löwenheim-Skolem
 
Logique mathématique
Algèbre de Boole · Calcul des prédicats · Calcul des propositions · Théorie de la calculabilité · Déduction naturelle · Logique traditionnelle · Logique classique · Logique linéaire · Lois de De Morgan · Théorie de la démonstration · Théorie des ensembles · Théorie des modèles
 
Logiques non classiques
Logique de description · Logique intuitionniste · Logique minimale · Logique floue · Logique modale · Logique non monotone · Logique paracohérente · Logiques sous-structurelles · Logique de Łukasiewicz
 
Logiciens
Aristote · Avicenne · Averroès · Bain · Barwise · Bernays · Boole · Cantor · Carnap · Church · Chrysippe de Soles · Curry · De Morgan · Frege · Gentzen · Gödel · Hilbert · Kleene · Kripke · Leibniz · Löwenheim · Guillaume d'Ockham · Peano · Peirce · Popper · Putnam · Quine · Russell · Schröder · Scot · Skolem · Smullyan · Tarski · Turing · Whitehead · Wittgenstein · Zermelo
 

 Portail des probabilités et de la statistique   Portail de la logique   Portail de la philosophie   Portail de la finance  




Ce document provient de « https://fr.wikipedia.org/w/index.php?title=Probabilité&oldid=195609716 ».
Catégories : ProbabilitésFinance de marchéCatégories cachées : Portail:Probabilités et statistiques/Articles liésProjet:Mathématiques/ArticlesPortail:Sciences/Articles liésPortail:Logique/Articles liésPortail:Philosophie/Articles liésPortail:Société/Articles liésPortail:Sciences humaines et sociales/Articles liésPortail:Finance/Articles liésPortail:Économie/Articles liés






 La dernière modification de cette page a été faite le 26 juillet 2022 à 14:06.
Droit d'auteur : les textes sont disponibles sous licence Creative Commons attribution, partage dans les mêmes conditions ; d’autres conditions peuvent s’appliquer. Voyez les conditions d’utilisation pour plus de détails, ainsi que les crédits graphiques. En cas de réutilisation des textes de cette page, voyez comment citer les auteurs et mentionner la licence.
Wikipedia® est une marque déposée de la Wikimedia Foundation, Inc., organisation de bienfaisance régie par le paragraphe 501(c)(3) du code fiscal des États-Unis.


Politique de confidentialité
À propos de Wikipédia
Avertissements
Contact
Version mobile
Développeurs
Statistiques
Déclaration sur les témoins (cookies)













