Big Bang
Introduction
Big Bang ou état stationnaire ?
Preuves observationnelles
Chronologie de l'histoire de l'Univers
Problèmes apparents posés par le Big Bang et leurs solutions
Modèle standard de la cosmologie
Quelques idées fausses sur le Big Bang
Implications philosophiques et statut épistémologique
Notes et références
Voir aussi
Fond diffus cosmologique
Nucléosynthèse primordiale
Évolution des galaxies
Mesure de la température du fond diffus cosmologique à grand décalage vers le rouge
L’Univers aujourd’hui (+ 13,8 milliards d’années)
Recombinaison (+ 380 000 ans)
Nucléosynthèse primordiale (+ 3 minutes)
Annihilation électrons-positrons
Découplage des neutrinos
Baryogénèse
Ère de grande unification
Inflation cosmique
Ère de Planck : cosmologie quantique
Problème de l’horizon
Problème de la platitude
Problème des monopôles
Problème de la formation des structures
Solutions proposées
Le Big Bang ne se réfère pas à un instant « initial » de l’histoire de l’Univers
Le Big Bang n’est pas une explosion, il ne s’est pas produit « quelque part »
Critiques de la part de scientifiques
Statut actuel
Pie XII et le Big Bang
Notes
Références
Bibliographie
Articles connexes
Liens externes
Sur le problème de l’horizon
Sur le problème de la platitude
Sur le problème des monopôles
Sur la formation des grandes structures
Pages pour les contributeurs déconnectés en savoir plus
Sommaire
				déplacer vers la barre latérale
masquer

Pour les articles homonymes, voir Big Bang (homonymie).
Le Big Bang (« Grand Boum »[a]) est un modèle cosmologique utilisé par les scientifiques pour décrire l'origine et l'évolution de l'Univers[1].
De façon générale, le terme « Big Bang » est associé à toutes les théories qui décrivent notre Univers comme issu d'une dilatation rapide. Par extension, il est également associé à cette époque dense et chaude qu’a connue l’Univers il y a 13,8 milliards d’années[b], sans que cela préjuge de l’existence d’un « instant initial » ou d’un commencement à son histoire. La comparaison avec une explosion, souvent employée, est elle aussi impropre[3].
Le concept a été initialement proposé en 1927 par l'astrophysicien et chanoine catholique belge Georges Lemaître[4], qui décrivait dans les grandes lignes l’expansion de l'Univers, avant que celle-ci soit mise en évidence par l'astronome américain Edwin Hubble en 1929[5]. Ce modèle est désigné pour la première fois sous le terme ironique de « Big Bang » lors d’une émission de la BBC, The Nature of Things le 28 mars 1949[6] (dont le texte fut publié en 1950), par le physicien britannique Fred Hoyle[7], qui lui-même préférait les modèles d'état stationnaire[8].
Le concept général du Big Bang, à savoir que l’Univers est en expansion et a été plus dense et plus chaud par le passé, doit sans doute être attribué au Russe Alexandre Friedmann, qui l'avait proposé en 1922, cinq ans avant Lemaître[9]. Son assise ne fut cependant établie qu’en 1965 avec la découverte du fond diffus cosmologique, l'« éclat disparu de la formation des mondes », selon les termes de Georges Lemaître, qui attesta de façon définitive la réalité de l’époque dense et chaude de l’Univers primordial. Albert Einstein, en mettant au point la relativité générale, aurait pu déduire l'expansion de l'Univers, mais a préféré modifier ses équations en y ajoutant sa constante cosmologique, car il était persuadé que l'Univers devait être statique.
Le terme de « Big Bang chaud » (« Hot Big Bang ») était parfois utilisé initialement pour indiquer que, selon ce modèle, l’Univers était plus chaud quand il était plus dense. Le qualificatif de « chaud » était ajouté par souci de précision, car le fait que l’on puisse associer une notion de température à l’Univers dans son ensemble n’était pas encore bien compris au moment où le modèle a été proposé, au milieu du XXe siècle.
La découverte de la relativité générale par Albert Einstein en 1915 marque le début de la cosmologie moderne, où il devient possible de décrire l’Univers dans son ensemble comme un système physique, son évolution à grande échelle étant décrite par la relativité générale.
Einstein est d’ailleurs le premier à utiliser sa théorie fraîchement découverte, tout en y  ajoutant un terme supplémentaire, la constante cosmologique, pour proposer une solution issue de la relativité générale décrivant l’espace dans son ensemble, appelée univers d’Einstein. Ce modèle introduit un concept extrêmement audacieux pour l’époque, le principe cosmologique, qui stipule que l’Homme n’occupe pas de position privilégiée dans l’Univers, ce qu’Einstein traduit par le fait que l’Univers soit homogène et isotrope, c’est-à-dire semblable à lui-même quels que soient le lieu et la direction dans laquelle on regarde. Cette hypothèse était relativement hardie, car, à l’époque, aucune observation concluante ne permettait d’affirmer l’existence d’objets extérieurs à la Voie lactée, bien que le débat sur cette question existe dès cette époque (par la suite appelé le Grand Débat).
Au principe cosmologique, Einstein ajoute implicitement une autre hypothèse qui paraît aujourd’hui nettement moins justifiée, celle que l’Univers est statique, c’est-à-dire n’évolue pas avec le temps. C’est cet ensemble qui le conduit à modifier sa formulation initiale en ajoutant à ses équations le terme de constante cosmologique. L’avenir lui donne tort, car dans les années 1920, Edwin Hubble découvre la nature extragalactique de certaines « nébuleuses » (aujourd’hui appelées galaxies), puis leur éloignement de la Galaxie avec une vitesse proportionnelle à leur distance[c] : c’est la loi de Hubble. Dès lors, plus rien ne justifie l’hypothèse d’un Univers statique proposée par Einstein.
Avant même la découverte de Hubble, plusieurs physiciens, dont Willem de Sitter, Georges Lemaître et Alexandre Friedmann, découvrent d’autres solutions de la relativité générale décrivant un Univers en expansion. Leurs modèles sont alors immédiatement acceptés dès la découverte de l’expansion de l’Univers. Ils décrivent ainsi un Univers en expansion depuis plusieurs milliards d’années. Par le passé, celui-ci était donc plus dense et plus chaud.
La découverte de l’expansion de l’Univers prouve que celui-ci n’est pas statique, mais laisse place à plusieurs interprétations possibles :
Dans un premier temps, c’est cette seconde hypothèse qui a été la plus populaire, bien que le phénomène de création de matière ne soit pas motivé par des considérations physiques. L’une des raisons de ce succès est que dans ce modèle, appelé théorie de l’état stationnaire, l’univers est éternel. Il ne peut donc y avoir de conflit entre l’âge de celui-ci et l'âge d’un objet céleste quelconque.
À l’inverse, dans l’hypothèse du Big Bang, l’Univers a un âge fini, que l’on déduit directement de son taux d’expansion (voir équations de Friedmann). Dans les années 1940, le taux d’expansion de l’Univers était très largement surestimé, ce qui conduisait à une importante sous-estimation de l’âge de l’Univers. Or diverses méthodes de datation de la Terre indiquaient que celle-ci était plus vieille que l’âge de l’Univers estimé par son taux d’expansion. Les modèles de type Big Bang étaient donc en difficulté vis-à-vis de telles observations. Ces difficultés ont disparu à la suite d'une réévaluation plus précise du taux d’expansion de l’Univers.
Deux preuves observationnelles décisives ont donné raison aux modèles de Big Bang : il s’agit de la détection du fond diffus cosmologique, rayonnement de basse énergie (domaine micro-onde) vestige de l’époque chaude de l’histoire de l’univers, et la mesure de l’abondance des éléments légers, c’est-à-dire des abondances relatives de différents isotopes de l’hydrogène, de l’hélium et du lithium qui se sont formés pendant la phase chaude primordiale.
Ces deux observations remontent au début de la seconde moitié du XXe siècle, et ont assis le Big Bang comme le modèle décrivant l’univers observable. Outre la cohérence quasi parfaite du modèle avec tout un autre ensemble d’observations cosmologiques effectuées depuis, d’autres preuves relativement directes sont venues s’ajouter : l’observation de l’évolution des populations galactiques, et la mesure du refroidissement du fond diffus cosmologique depuis plusieurs milliards d’années.
L’expansion induit naturellement que l’Univers a été plus dense par le passé. À l’instar d’un gaz qui s’échauffe quand on le comprime, l’Univers devait aussi être plus chaud par le passé. Cette possibilité semble évoquée pour la première fois en 1934 par Georges Lemaître, mais n’est réellement étudiée qu’à partir des années 1940. Selon l’étude de George Gamow (entre autres), l’Univers doit être empli d'un rayonnement qui perd de l’énergie du fait de l’expansion, selon un processus semblable à celui du décalage vers le rouge du rayonnement des objets astrophysiques distants.
Gamow réalise en effet que les fortes densités de l’Univers primordial doivent avoir permis l’instauration d’un équilibre thermique entre les atomes, et par suite l’existence d'un rayonnement émis par ceux-ci. Ce rayonnement devait être d’autant plus intense que l'Univers était dense, et devait donc encore exister aujourd’hui, bien que considérablement moins intense. Gamow fut le premier (avec Ralph Alpher et Robert C. Herman) à réaliser que la température actuelle de ce rayonnement pouvait être calculée à partir de la connaissance de l’âge de l'Univers, la densité de matière, et l'abondance d’hélium.
Ce rayonnement est appelé aujourd’hui fond diffus cosmologique, ou parfois rayonnement fossile. Il correspond à un rayonnement de corps noir à basse température (2,7 kelvins), conformément aux prédictions de Gamow. Sa découverte, quelque peu fortuite, est due à Arno Allan Penzias et Robert Woodrow Wilson en 1965, qui seront récompensés par le prix Nobel de physique en 1978.
L’existence d’un rayonnement de corps noir est facile à expliquer dans le cadre du modèle du Big Bang : par le passé, l’Univers était très chaud et baignait dans un rayonnement intense. La densité de celui-ci fut telle que de très nombreuses interactions entre matière et rayonnement se produisirent, entraînant la thermalisation de ce dernier (son spectre électromagnétique est celui d’un corps noir). L’existence d’un tel rayonnement au sein de la théorie de l’Univers stationnaire est par contre presque impossible à justifier (bien que ses rares tenants affirment le contraire).
Bien que correspondant à un rayonnement à basse température et peu énergétique, le fond diffus cosmologique n’en demeure pas moins la plus grande forme d’énergie électromagnétique de l’Univers : près de 96 % de l’énergie existant sous forme de photons se situe dans ce rayonnement fossile, les 4 % restants résultant du rayonnement des étoiles (dans le domaine visible) et du gaz froid dans les galaxies (en infrarouge). Ces autres sources émettent des photons certes plus énergétiques, mais nettement moins nombreux.
Dans la théorie de l’Univers stationnaire, l’existence du fond diffus cosmologique est supposée résulter d’une thermalisation du rayonnement stellaire par d’hypothétiques aiguillettes de fer microscopiques ; un tel modèle s’avère être en contradiction avec les données observables, tant en terme d’abondance du fer qu’en terme d’efficacité du processus de thermalisation (il est impossible d’expliquer dans ce cadre que le fond diffus cosmologique soit un corps noir quasiment parfait) ou d’isotropie (on s’attendrait à ce que la thermalisation soit plus ou moins efficace selon la distance aux galaxies).
La découverte du fond diffus cosmologique fut historiquement la preuve décisive du Big Bang.
Dès la découverte de l’interaction forte et du fait que c’était elle qui était la source d’énergie des étoiles, s’est posée la question d’expliquer l’abondance des différents éléments chimiques dans l’Univers. Au tournant des années 1950 deux processus expliquant cette abondance étaient en compétition : la nucléosynthèse stellaire et la nucléosynthèse primordiale.
Des tenants de l'idée d’état stationnaire comme Fred Hoyle supposaient que de l’hydrogène était produit constamment au cours du temps, et que celui-ci était peu à peu transformé en hélium puis en éléments plus lourds au cœur des étoiles. La fraction d’hélium ou des autres éléments lourds restait constante au cours du temps car la proportion d’hélium augmentait du fait de la nucléosynthèse, mais diminuait en proportion semblable du fait de la création d’hydrogène. À l’inverse, les tenants du Big Bang supposaient que tous les éléments, de l’hélium à l’uranium, avaient été produits lors de la phase dense et chaude de l’univers primordial.
Le modèle actuel emprunte aux deux hypothèses :
D’après celle-ci, l’hélium et le lithium ont effectivement été produits pendant la nucléosynthèse primordiale, mais les éléments plus lourds, comme le carbone ou l’oxygène, ont été créés plus tard au cœur des étoiles (nucléosynthèse stellaire). La principale preuve de cela vient de l’étude de l’abondance des éléments dits « légers » (hydrogène, hélium, lithium) dans les quasars lointains. D’après le modèle du Big Bang, leurs abondances relatives dépendent exclusivement d’un seul paramètre, à savoir le rapport de la densité de photons à la densité de baryons, qui est quasi constant depuis la nucléosynthèse primordiale. À partir de ce seul paramètre, que l’on peut d’ailleurs mesurer par d’autres méthodes, on peut expliquer l’abondance des deux isotopes de l’hélium (3He et 4He) et de celle du lithium (7Li). On observe également une augmentation de la fraction d’hélium au sein des galaxies proches, signe de l’enrichissement progressif du milieu interstellaire par les éléments synthétisés par les étoiles.
Le modèle du Big Bang présuppose que l’Univers ait été par le passé dans un état bien plus homogène qu’aujourd’hui. La preuve en est apportée par l’observation du fond diffus cosmologique dont le rayonnement est extraordinairement isotrope : les écarts de température ne varient guère plus d’un cent-millième de degré selon la direction d’observation.
Il est donc supposé que les structures astrophysiques (galaxies, amas de galaxies) n’existaient pas à l’époque du Big Bang mais se sont peu à peu formées. Le processus à l’origine de leur formation est d’ailleurs connu depuis les travaux de James Jeans en 1902 : c’est l’instabilité gravitationnelle.
Le Big Bang prédit donc que les galaxies que nous observons se sont formées quelque temps après le Big Bang, et d’une manière générale que les galaxies du passé ne ressemblaient pas exactement à celles que l’on observe dans notre voisinage. Comme la lumière voyage à une vitesse finie, il suffit de regarder des objets lointains pour voir à quoi ressemblait l’univers par le passé.
L’observation des galaxies lointaines, qui d’après la loi de Hubble ont un grand décalage vers le rouge montre effectivement que les galaxies primordiales étaient assez différentes de celles d’aujourd’hui : les interactions entre galaxies étaient plus nombreuses, les galaxies massives moins nombreuses, ces dernières étant apparues plus tard des suites des phénomènes de fusion entre galaxies. De même, la proportion de galaxies spirale, elliptique et irrégulière varie au cours du temps.
Toutes ces observations sont relativement délicates à effectuer, en grande partie car les galaxies lointaines sont peu lumineuses et nécessitent des moyens d’observation très performants pour être bien observées. Depuis la mise en service du télescope spatial Hubble en 1990 puis des grands observatoires au sol VLT, Keck, Subaru, l’observation des galaxies à grand redshift a permis de vérifier les phénomènes d’évolution des populations galactiques prédits par les modèles de formation et d’évolution des galaxies dans le cadre des modèles du Big Bang.
L’étude des toutes premières générations d’étoiles et de galaxies demeure un des enjeux majeurs de la recherche astronomique du début du XXIe siècle.
En décembre 2000, Raghunathan Srianand, Patrick Petitjean et Cédric Ledoux ont mesuré la température du fond diffus cosmologique baignant un nuage interstellaire dont ils ont observé l’absorption du rayonnement émis par le quasar d’arrière plan PKS 1232+0815, situé à un décalage vers le rouge de 2,57[10].
L’étude du spectre d’absorption permet de déduire la composition chimique du nuage, mais aussi sa température si l’on peut détecter les raies correspondant à des transitions entre différents niveaux excités de divers atomes ou ions présents dans le nuage (dans le cas présent, du carbone neutre). La principale difficulté dans une telle analyse est d’arriver à séparer les différents processus physiques pouvant peupler les niveaux excités des atomes.
Les propriétés chimiques de ce nuage, ajoutées à la très haute résolution spectrale de l’instrument utilisé (le spectrographe UVES du Very Large Telescope) ont pour la première fois permis d’isoler la température du rayonnement de fond. Srianand, Petitjean et Ledoux ont trouvé une température du fond diffus cosmologique comprise entre 6 et 14 kelvins, en accord avec la prédiction du Big Bang, de 9,1 K, étant donné que le nuage est situé à un décalage vers le rouge de 2,33771[précision nécessaire].
Du fait de l’expansion, l’Univers était par le passé plus dense et plus chaud. La chronologie du Big Bang revient essentiellement à déterminer à rebours l’état de l’Univers à mesure que sa densité et sa température augmentent dans le passé.
L’Univers est à l’heure actuelle extrêmement peu dense (quelques atomes par mètre cube, voir l’article densité critique) et froid (2,73 kelvins, soit −271 °C). En effet, s’il existe des objets astrophysiques très chauds (les étoiles), le rayonnement ambiant dans lequel baigne l’Univers est très faible. Cela provient du fait que la densité d’étoiles est extrêmement faible dans l’Univers : la distance moyenne d’un point quelconque de l’Univers à l’étoile la plus proche est immense[réf. nécessaire]. L’observation astronomique nous apprend de plus que les étoiles ont existé très tôt dans l’histoire de l’Univers : moins d’un milliard d’années après le Big Bang, étoiles et galaxies existaient déjà en nombre. Cependant, à des époques encore plus reculées elles n’existaient pas encore. Si tel avait été le cas, le fond diffus cosmologique porterait les traces de leur présence.
380 000 ans après le Big Bang, alors que l’Univers est mille fois plus chaud et un milliard de fois plus dense qu’aujourd’hui, les étoiles et les galaxies n’existaient pas encore. Ce moment marque l’époque où l’Univers est devenu suffisamment peu dense pour que la lumière puisse s’y propager, essentiellement grâce au fait que le principal obstacle à sa propagation était la présence d’électrons libres. Lors de son refroidissement, l’Univers voit les électrons libres se combiner aux noyaux atomiques pour former les atomes. Cette époque porte pour cette raison le nom de recombinaison. Comme elle correspond aussi au moment où l’Univers a permis la propagation de la lumière, on parle aussi de découplage entre matière et rayonnement. La lueur du fond diffus cosmologique a donc pu se propager jusqu’à nous depuis cette époque[d].
Moins de 380 000 ans après le Big Bang, l’Univers est composé d’un plasma d’électrons et de noyaux atomiques. Quand la température est suffisamment élevée, les noyaux atomiques eux-mêmes ne peuvent exister. On est alors en présence d’un mélange de protons, de neutrons et d’électrons. Dans les conditions qui règnent dans l’Univers primordial, ce n’est que lorsque sa température descend en dessous de 0,1 MeV (soit environ un milliard de degrés) que les nucléons peuvent se combiner pour former des noyaux atomiques. Il n’est cependant pas possible de fabriquer ainsi des noyaux atomiques lourds plus gros que le lithium. Ainsi, seuls les noyaux d’hydrogène, d’hélium et de lithium sont produits lors de cette phase qui commence environ une seconde après le Big Bang et qui dure environ trois minutes[11]. C’est ce que l’on appelle la nucléosynthèse primordiale, dont la prédiction, la compréhension et l’observation des conséquences représentent un des premiers accomplissements majeurs de la cosmologie moderne.
Peu avant la nucléosynthèse primordiale (qui débute à 0,1 MeV), la température de l’Univers dépasse 0,5 MeV (cinq milliards de degrés), correspondant à l’énergie de masse des électrons. Au-delà de cette température, interactions entre électrons et photons peuvent spontanément créer des paires d’électron-positrons. Ces paires s’annihilent spontanément mais sont sans cesse recréées tant que la température dépasse le seuil de 0,5 MeV. Dès qu'elle descend en dessous de celui-ci, la quasi-totalité des paires s’annihilent en photons, laissant place au très léger excès d’électrons issus de la baryogenèse (voir infra).
Peu avant cette époque, la température est supérieure à 1 MeV (dix milliards de degrés), ce qui est suffisant pour qu’électrons, photons et neutrinos aient de nombreuses interactions. Ces trois espèces sont à l’équilibre thermique à des températures plus élevées. Quand l’Univers refroidit, électrons et photons continuent à interagir, mais plus les neutrinos, qui cessent également d’interagir entre eux. À l’instar du découplage mentionné plus haut qui concernait les photons, cette époque correspond à celle du découplage des neutrinos. Il existe donc un fond cosmologique de neutrinos présentant des caractéristiques semblables à celles du fond diffus cosmologique. L’existence de ce fond cosmologique de neutrinos est attestée indirectement par les résultats de la nucléosynthèse primordiale, puisque ceux-ci y jouent un rôle indirect[e]. La détection directe de ce fond cosmologique de neutrinos représente un défi technologique extraordinairement difficile[12], mais son existence n’en est aucunement remise en cause.
La physique des particules repose sur l’idée générale, étayée par l’expérience, que les diverses particules élémentaires et interactions fondamentales ne sont que des aspects différents d’entités plus élémentaires (par exemple, l’électromagnétisme et la force nucléaire faible peuvent être décrits comme deux aspects d’une seule interaction, l’interaction électrofaible). Plus généralement, il est présumé que les lois de la physique, et par suite l’Univers dans son ensemble, sont dans un état d'autant plus « symétrique » que la température est élevée. On considère ainsi que, par le passé, matière et antimatière existaient en quantités strictement identiques dans l’Univers. Les observations actuelles indiquent que l’antimatière est quasiment absente dans l’univers observable[f]. La présence de matière est donc le signe qu’à un moment donné s’est formé un léger excès de matière par rapport à l’antimatière. Lors de l’évolution ultérieure de l’Univers, matière et antimatière se sont annihilées en quantités strictement égales, laissant derrière elles le très léger surplus de matière qui s’était formé. Comme la matière ordinaire est formée de particules appelées baryons, la phase où cet excès de matière s’est formé est appelée baryogenèse. Très peu de choses sont connues sur cette phase ou sur le processus qui s’est produit alors. Par exemple, l’échelle de température où elle s’est produite varie, selon les modèles, de 103 à 1016 GeV (soit entre 1016 et 1029 kelvins…). Les conditions nécessaires pour que la baryogenèse se produise sont appelées conditions de Sakharov, à la suite des travaux du physicien russe Andreï Sakharov en 1967.
Un nombre croissant d’indications suggère que les forces électromagnétiques, et les forces nucléaires faible et forte ne sont que des aspects différents d’une seule et unique interaction. Celle-ci est en général appelée théorie grand unifiée (« GUT » en anglais, pour Grand Unified Theory), ou grande unification. On pense qu’elle se manifeste au-delà de températures de l’ordre de 1016 GeV (1029 kelvin). Il est donc probable que l’Univers ait connu une phase où la théorie grand unifiée était de mise. Cette phase pourrait être à l’origine de la baryogenèse, ainsi éventuellement que de la matière noire, dont la nature exacte reste inconnue.
Le Big Bang amène de nouvelles questions en cosmologie. Par exemple, il suppose que l’Univers est homogène et isotrope (ce qu’il est effectivement, du moins dans la région observable), mais n’explique pas pourquoi il devrait en être ainsi. Or dans sa version naïve, il n’existe pas de mécanisme pendant le Big Bang qui provoque une homogénéisation de l’Univers (voir infra). La motivation initiale de l’inflation était ainsi de proposer un processus provoquant l’homogénéisation et l’isotropisation de l’Univers.
L’inventeur de l’inflation est Alan Guth qui a été le premier à proposer explicitement un scénario réaliste décrivant un tel processus. À son nom méritent aussi d’être associés ceux de François Englert et Alexeï Starobinski, qui ont également travaillé sur certaines de ces problématiques à la même époque (1980). Il a par la suite été réalisé (en 1982) que l’inflation permettait non seulement d’expliquer pourquoi l’Univers était homogène, mais aussi pourquoi il devait aussi présenter de petits écarts à l’homogénéité, comportant les germes des grandes structures astrophysiques.
L’on peut montrer que pour que l’inflation résolve tous ces problèmes, elle doit avoir eu lieu à des époques extrêmement reculées et chaudes de l’histoire de l’Univers (entre 1014 et 1019 GeV, soit de 1027 à 1032 degrés…), c’est-à-dire au voisinage des époques de Planck et de grande unification. L’efficacité de l’inflation à résoudre la quasi-totalité des problèmes exhibés par le Big Bang lui a rapidement donné un statut de premier plan en cosmologie, bien que divers autres scénarios, souvent plus complexes et moins aboutis (pré Big Bang, défauts topologiques, univers ekpyrotique), aient été proposés pour résoudre les mêmes problèmes. Depuis l’observation détaillée des anisotropies du fond diffus cosmologique, les modèles d’inflation sont sortis considérablement renforcés. Leur accord avec l’ensemble des observations allié à l’élégance du concept font de l’inflation le scénario de loin le plus intéressant pour les problématiques qu’il aborde.
La phase d’inflation en elle-même se compose d’une expansion extrêmement rapide de l’Univers (pouvant durer un temps assez long), à l’issue de laquelle la dilution causée par cette expansion rapide est telle qu’il n’existe essentiellement plus aucune particule dans l’Univers, mais que celui-ci est empli d’une forme d’énergie très homogène. Cette énergie est alors convertie de façon très efficace en particules qui très vite vont se mettre à interagir et à s’échauffer. Ces deux phases qui closent l’inflation sont appelées préchauffage pour la création « explosive » de particules et réchauffage pour leur thermalisation. Si le mécanisme général de l’inflation est parfaitement bien compris (quoique de très nombreuses variantes existent), celui du préchauffage et du réchauffage le sont beaucoup moins et sont toujours l’objet de nombreuses recherches.
Au-delà de la phase d’inflation, et plus généralement à des températures de l’ordre de la température de Planck, on entre dans le domaine où les théories physiques actuelles ne deviennent plus valables, car nécessitant un traitement de la relativité générale incluant les concepts de la mécanique quantique. Cette théorie de la gravité quantique, non découverte à ce jour mais qui sera peut-être issue de la théorie des cordes encore en développement, laisse à l’heure actuelle place à des spéculations nombreuses concernant l’Univers à cette époque dite ère de Planck. Plusieurs auteurs, dont Stephen Hawking, ont proposé diverses pistes de recherche pour tenter de décrire l’Univers à ces époques. Ce domaine de recherche est ce que l’on appelle la cosmologie quantique.
L’étude des modèles de Big Bang révèle un certain nombre de problèmes inhérents à ce type de modèle. En l’absence de modifications, le modèle naïf du Big Bang apparaît peu convaincant, car il nécessite de supposer qu’un certain nombre de quantités physiques sont soit extrêmement grandes, soit extrêmement petites par rapport aux valeurs que l’on pourrait naïvement penser leur attribuer. En d’autres termes, le Big Bang semble nécessiter d’ajuster un certain nombre de paramètres à des valeurs inattendues pour pouvoir être viable. Ce type d’ajustement fin de l’univers est considéré comme problématique dans tout modèle physique (en rapport avec la cosmologie ou pas, d’ailleurs), au point que le Big Bang pourrait être considéré comme un concept posant autant de problèmes qu’il en résout, rendant cette solution peu attractive, malgré ses succès à expliquer nombre d’observations. Fort heureusement, des scénarios existent, en particulier l’inflation cosmique, qui, inclus dans les modèles de Big Bang, permettent d’éviter les observations initialement considérées comme étant problématiques. Il est ainsi possible d’avoir aujourd’hui une vision unifiée du contenu matériel, de la structure, de l’histoire et de l’évolution de l’univers, appelée par analogie avec la physique des particules le modèle standard de la cosmologie.
Les observations indiquent que l’univers est homogène et isotrope. Il est possible de montrer à l’aide des équations de Friedmann qu’un univers homogène et isotrope à un instant donné va le rester. Par contre, le fait que l’univers soit homogène et isotrope dès l’origine est plus difficile à justifier.
À l’exception d’arguments esthétiques et de simplicité, il n’existe pas a priori de raison valable de supposer que l’univers soit aussi homogène et isotrope que ce qui est observé. Aucun mécanisme satisfaisant n’explique par ailleurs pourquoi il devrait exister de petits écarts à cette homogénéité, comme ceux qui sont observés dans les anisotropies du fond diffus cosmologique et qui seraient responsables de la formation des grandes structures dans l’univers (galaxie, amas de galaxies…).
Cette situation est insatisfaisante et on a longtemps cherché à proposer des mécanismes qui, partant de conditions initiales relativement génériques, pourraient expliquer pourquoi l’univers a évolué vers l’état observé à notre ère. On peut en effet montrer que deux régions distantes de l’univers observable sont tellement éloignées l’une de l’autre qu’elles n’ont pas eu le temps d’échanger une quelconque information, quand bien même elles étaient bien plus proches l’une de l’autre par le passé qu’elles ne le sont aujourd’hui. Le fait que ces régions distantes présentent essentiellement les mêmes caractéristiques reste donc difficile à justifier. Ce problème est connu sous le nom de problème de l’horizon.
Un autre problème qui apparaît quand on considère l’étude de l’évolution de l’univers est celui de son éventuel rayon de courbure.
La relativité générale indique que si la répartition de matière est homogène dans l’univers, alors la géométrie de celui-ci ne dépend que d’un paramètre, appelé courbure spatiale. Intuitivement, cette quantité donne l’échelle de distance au-delà de laquelle la géométrie euclidienne (comme le théorème de Pythagore) cesse d’être valable. Par exemple, la somme des angles d’un triangle de taille gigantesque (plusieurs milliards d’années-lumière) pourrait ne pas être égale à 180 degrés. Il reste parfaitement possible que de tels effets, non observés, n’apparaissent qu’à des distances bien plus grandes que celles de l’univers observable.
Néanmoins un problème apparaît si l’on remarque que cette échelle de longueur, appelée rayon de courbure, a tendance à devenir de plus en plus petite par rapport à la taille de l’univers observable. En d’autres termes, si le rayon de courbure était à peine plus grand que la taille de l’univers observable il y a 5 milliards d’années, il devrait être aujourd’hui plus petit que cette dernière, et les effets géométriques sus-mentionnés devraient devenir visibles. En continuant ce raisonnement, il est possible de voir qu’à l’époque de la nucléosynthèse le rayon de courbure devait être immensément plus grand que la taille de l’univers observable pour que les effets dus à la courbure ne soient pas encore visibles aujourd’hui. Le fait que le rayon de courbure soit encore aujourd’hui plus grand que la taille de l’univers observable est connu sous le nom de problème de la platitude.
La physique des particules prévoit l’apparition progressive de nouvelles particules lors du refroidissement résultant de l’expansion de l’univers.
Certaines sont produites lors d’un phénomène appelé transition de phase que l’on pense générique dans l’univers primordial. Ces particules, dont certaines sont appelées monopôles, ont la particularité d’être stables, extrêmement massives (ordinairement 1015 fois plus que le proton) et très nombreuses. Si de telles particules existaient, leur contribution à la densité de l’univers devrait en fait être considérablement plus élevée que celle de la matière ordinaire.
Or, si une partie de la densité de l’univers est due à des formes de matière mal connues (voir plus bas), il n’y a certainement pas la place pour une proportion significative de monopôles. Le problème des monopôles est donc la constatation qu’il n’existe pas en proportion significative de telles particules massives dans l’univers, alors que la physique des particules prédit naturellement leur existence avec une abondance très élevée.
Si l’observation révèle que l’univers est homogène à grande échelle, elle révèle aussi qu’il présente des hétérogénéités importantes à plus petite échelle (planètes, étoiles, galaxies, etc.). Le fait que l’univers présente des hétérogénéités plus marquées à petite échelle n’est pas évident en soi. L’on sait expliquer comment, dans certaines circonstances, une petite hétérogénéité dans la distribution de matière peut croître jusqu’à former un objet astrophysique significativement plus compact que son environnement : c’est ce que l’on appelle le mécanisme d’instabilité gravitationnelle, ou instabilité de Jeans (du nom de James Jeans). Cependant, pour qu’un tel mécanisme se produise, il faut supposer la présence initiale d’une petite hétérogénéité, et de plus la variété des structures astrophysiques observées indique que la répartition en amplitude et en taille de ces hétérogénéités initiales suivait une loi bien précise, connue sous le nom de spectre de Harrison-Zeldovitch. Les premiers modèles de Big Bang étaient dans l’incapacité d’expliquer la présence de telles fluctuations. On parlait alors du problème de la formation des structures.
Les problèmes de l’horizon et de la platitude ont une origine commune. Le problème de l’horizon vient du fait qu’à mesure que le temps passe, l’on a accès à des régions de plus en plus grandes, et contenant de plus en plus de matière. Par exemple, avec une expansion dictée par de la matière ordinaire, un nombre croissant de galaxies est visible au cours du temps. Il est donc surprenant que celles-ci possèdent les mêmes caractéristiques.
On se rend compte que ce problème pourrait être résolu si on imaginait qu’une certaine information sur l’état de l’univers ait pu se propager extrêmement rapidement tôt dans l’histoire de l’univers. Dans un tel cas, des régions extrêmement distantes les unes des autres pourraient avoir échangé suffisamment d’information pour qu’il soit possible qu’elles soient dans des configurations semblables. La relativité restreinte stipule cependant que rien ne peut se déplacer plus vite que la lumière, aussi paraît-il difficilement imaginable que le processus proposé soit possible.
Néanmoins, si on suppose que l’expansion de l’univers est très rapide et se fait à taux d’expansion constant, alors on peut contourner la limitation de la relativité restreinte. En effet, dans un tel cas, la distance entre deux régions de l’univers croît exponentiellement au cours du temps, tandis que la taille de l’univers observable reste constante. Une région initialement très petite et homogène va donc avoir la possibilité de prendre une taille démesurée par rapport à la région de l’univers qui est observable. Quand cette phase à taux d’expansion constant s’achève, la région homogène de l’univers dans laquelle nous nous trouvons peut alors être immensément plus grande que celle qui est accessible à nos observations. Quand bien même la phase d’expansion classique reprend son cours, il devient naturel d’observer un univers homogène sur des distances de plus en plus grandes, tant que les limites de la région homogène initiale ne sont pas atteintes. Un tel scénario nécessite que l’expansion de l’univers puisse se faire à taux constant, ou plus généralement de façon accélérée (la vitesse à laquelle deux régions distantes s’éloignent doit croître avec le temps). Les équations de Friedmann stipulent que cela est possible, mais au prix de l’hypothèse qu’une forme de matière atypique existe dans l’univers (elle doit avoir une pression négative).
Le problème de la platitude peut se résoudre de façon essentiellement identique. Initialement, le problème vient du fait que le rayon de courbure croît moins vite que la taille de l’univers observable. Or cela peut ne plus être vrai si la loi qui gouverne l’expansion est différente de celle qui gouverne l’expansion d’un univers empli de matière ordinaire. Si en lieu et place de celle-ci l’on imagine qu’une autre forme de matière aux propriétés atypiques existe (que sa pression soit négative), alors on peut montrer que, dans un tel cas, le rayon de courbure va croître plus vite que la taille de l’univers observable. Si une telle phase d’expansion s’est produite dans le passé et a duré suffisamment longtemps, alors il n’est plus surprenant que le rayon de courbure ne soit pas mesurable.
Enfin, le problème des monopôles est naturellement résolu avec une phase d’expansion accélérée, car celle-ci a tendance à diluer toute la matière ordinaire de l’univers. Cela amène un nouveau problème : la phase d’expansion accélérée laisse un univers homogène, spatialement plat, sans reliques massives, mais vide de matière. Il faut donc repeupler l’univers avec de la matière ordinaire à l’issue de cette phase d’expansion accélérée.
Le scénario de l’inflation cosmique, proposé par Alan Guth au début des années 1980 répond à l’ensemble de ces critères. La forme de matière atypique qui cause la phase d’expansion accélérée est ce que l’on appelle un champ scalaire (souvent appelé inflaton dans ce contexte), qui possède toutes les propriétés requises. Il peut être à l’origine du démarrage de cette phase accélérée si certaines conditions favorables génériques se trouvent réunies en un endroit de l’univers. À l’issue de cette phase d’expansion accélérée, c’est le champ scalaire lui-même responsable de cette phase d’expansion qui devient instable et se désintègre en plusieurs étapes en particules du modèle standard au cours d’un ensemble de processus complexes appelés préchauffage et réchauffage (voir plus haut).
Les premiers modèles d’inflation souffraient d’un certain nombre de problèmes techniques, notamment les circonstances qui donnaient lieu au démarrage de la phase d’expansion accélérée et à son arrêt étaient peu satisfaisantes. Les modèles d’inflation plus récents évitent ces écueils, et proposent des scénarios tout à fait plausibles pour décrire une telle phase.
De plus l’inflaton possède, comme toute forme de matière, des fluctuations quantiques (résultat du principe d’indétermination d’Heisenberg). Une des conséquences inattendues de l’inflation est que ces fluctuations, initialement de nature quantique, évoluent durant la phase d’expansion accélérée pour devenir des variations classiques ordinaires de densité. Par ailleurs le calcul du spectre de ces fluctuations effectué dans le cadre de la théorie des perturbations cosmologiques montre qu’il suit précisément les contraintes du spectre de Harrison-Zeldovitch.
Ainsi, l’inflation permet d’expliquer l’apparition de petits écarts à l’homogénéité de l’univers, résolvant du même coup le problème de la formation des structures susmentionnées. Ce succès inattendu de l’inflation a immédiatement contribué à en faire un modèle extrêmement attractif, d’autant que le détail des inhomogénéités créées lors de la phase d’inflation peut être confronté aux inhomogénéités existant dans l’univers actuel.
L’accord remarquable entre les prévisions du modèle cosmologique standard et l'exploitation des données relatives aux fluctuations du fond diffus, fournies entre autres par les satellites COBE et WMAP et de façon beaucoup plus précise encore par le satellite Planck, ainsi que les catalogues de galaxies comme celui réalisé par la mission SDSS est sans nul doute un des plus grands succès de la cosmologie du XXe siècle.
Il n’en demeure pas moins vrai que des alternatives à l’inflation ont été proposées malgré les succès indéniables de celle-ci. Parmi ceux-ci, citons le pré Big Bang proposé entre autres par Gabriele Veneziano, et l’univers ekpyrotique. Ces modèles sont globalement considérés comme moins génératiques, moins esthétiques et moins achevés que les modèles d’inflation. Ce sont donc ces derniers qui à l’heure actuelle sont de loin considérés comme les plus réalistes.
La construction de ce qui est désormais appelé le modèle standard de la cosmologie est la conséquence logique de l’idée du Big Bang proposée dans la première partie du XXe siècle. Ce modèle standard de la cosmologie, qui tire son nom par analogie avec le modèle standard de la physique des particules, offre une description de l’univers compatible avec l’ensemble des observations de l’univers. Il stipule en particulier les deux points suivants :
Un très grand nombre d’observations astronomiques rendent ces ingrédients indispensables pour décrire l’univers que nous connaissons. La recherche en cosmologie vise essentiellement à déterminer l’abondance et les propriétés de ces formes de matière, ainsi qu’à contraindre le scénario d’expansion accélérée de l’univers primordial (ou d’en proposer d’autres). Trois ingrédients de ce modèle standard de la cosmologie nécessitent de faire appel à des phénomènes physiques non observés en laboratoire : l’inflation, la matière noire et l’énergie noire. Néanmoins, les indications observationnelles en faveur de l’existence de ces trois phénomènes sont telles qu’il semble extrêmement difficile d’envisager d’éviter d’y faire appel. Il n’existe de fait aucun modèle cosmologique satisfaisant s’affranchissant d’un ou plusieurs de ces ingrédients.
Il indique seulement que celui-ci a connu une période dense et chaude. De nombreux modèles cosmologiques décrivent de façons très diverses cette phase dense et chaude. Le statut de cette phase a d’ailleurs été soumis à maints remaniements. Dans un de ses premiers modèles, Georges Lemaître proposait un état initial dont la matière aurait la densité de la matière nucléaire (1015 g/cm3). Lemaître considérait (à juste titre) qu’il était difficile de prétendre connaître avec certitude le comportement de la matière à de telles densités, et supposait que c’était la désintégration de ce noyau atomique géant et instable qui avait initié l’expansion (hypothèse de l’atome primitif). Auparavant, Lemaître avait en 1931 fait remarquer que la mécanique quantique devait invariablement être invoquée pour décrire les tout premiers instants de l’histoire de l’Univers, jetant par là les bases de la cosmologie quantique, et que les notions de temps et d’espace perdaient probablement leur caractère usuel[13]. Aujourd’hui, certains modèles d’inflation supposent par exemple un univers éternel[14], d’autres modèles comme celui du pré Big Bang supposent un état initial peu dense mais en contraction suivi d’une phase de rebond, d’autres modèles encore, basés sur la théorie des cordes, prédisent que l’univers observable n’est qu’un objet appelé « brane » (tiré du mot anglais « membrane », identique à sa traduction française) plongé dans un espace à plus de quatre dimensions (le « bulk »), le big bang et le démarrage de l’expansion étant dus à une collision entre deux branes (univers ekpyrotique). Cependant, c’est lors de cette phase dense et chaude que se forment les particules élémentaires que nous connaissons aujourd’hui, puis, plus tard toutes les structures que l’on observe dans l’Univers. Ainsi reste-t-il légitime de dire que l’univers est né du Big Bang, au sens où l’Univers tel que nous le connaissons s’est structuré à cette époque.
Le Big Bang ne s’est pas produit en un point d’où aurait été éjectée la matière qui forme aujourd’hui les galaxies, contrairement à ce que son nom suggère et à ce que l’imagerie populaire véhicule souvent[15]. À l’« époque » du Big Bang, les conditions qui régnaient « partout » dans l’Univers (du moins la région de l’Univers observable) étaient identiques. Il est par contre vrai que les éléments de matière s’éloignaient alors très rapidement les uns des autres, du fait de l’expansion de l'Univers. Le terme de Big Bang renvoie donc à la violence de ce mouvement d’expansion, mais pas à un « lieu » privilégié. En particulier il n’y a pas de « centre » du Big Bang ou de direction privilégiée dans laquelle il nous faudrait observer pour le voir. C’est l’observation des régions lointaines de l’Univers (quelle que soit leur direction) qui nous permet de voir l’Univers tel qu’il était par le passé (car la lumière voyageant à une vitesse finie, elle nous fait voir des objets lointains tels qu’ils étaient à une époque reculée, leur état actuel nous étant d’ailleurs inaccessible) et donc de nous rapprocher de cette époque. Ce qu’il nous est donné de voir aujourd’hui n’est pas l’époque du Big Bang lui-même, mais le fond diffus cosmologique, sorte d’écho lumineux de cette phase chaude de l’histoire de l’Univers. Ce rayonnement est essentiellement uniforme quelle que soit la direction dans laquelle on l’observe, ce qui indique que le Big Bang s’est produit de façon extrêmement homogène dans les régions qu’il nous est possible d’observer. La raison pour laquelle il n’est pas possible de voir jusqu’au Big Bang est que l’Univers primordial est opaque au rayonnement du fait de sa densité élevée, de même qu’il n’est pas possible de voir directement le centre du Soleil et que l’on ne peut observer que sa surface. Voir l’article fond diffus cosmologique pour plus de détails.
Le caractère apparemment créationniste du Big Bang a suscité de nombreuses réflexions, y compris hors des cercles scientifiques, parce qu'il laissait entrevoir pour la première fois que la science puisse apporter des éléments de réponse à des domaines jusque-là réservés à la philosophie et à la théologie. Ce point de vue sera en particulier exprimé par le pape Pie XII (voir infra).
Remarquons au passage que la chronologie suggérée par le Big Bang va à l’inverse des convictions des deux grands architectes des théories de la gravitation, Isaac Newton et Albert Einstein, qui croyaient que l'Univers était éternel. Dans le cas d’Einstein, toutefois, il ne semble pas avéré qu’il y avait un préconçu philosophique pour motiver cette intuition, qui pourrait être avant tout issue de motivations physiques (voir l’article Univers d’Einstein).
Lemaître élaborera un point de vue différent de celui exprimé par le pape : la cosmologie, et la science en général, n’ont pas vocation à conforter ou à infirmer ce qui est du domaine du religieux (ou philosophique). Elle se contente de proposer un scénario réaliste permettant de décrire de façon cohérente l’ensemble des observations dont on dispose à un instant donné. Pour l’heure, l’interprétation des décalages vers le rouge en termes d’expansion de l’Univers est établie au-delà de tout doute raisonnable, aucune autre interprétation ne résistant à un examen sérieux, ou étant motivée par des arguments physiques pertinents, et l’existence de la phase dense et chaude est également avérée (voir plus haut).
Par contre les convictions ou les réticences des acteurs qui ont participé à l’émergence du concept ont joué un rôle dans ce processus de maturation, et il a souvent été dit que les convictions religieuses de Lemaître l’avaient aidé à proposer le modèle du Big Bang, bien que cela ne repose pas sur des preuves tangibles[16]. En revanche, l’idée que tout l’Univers eût pu avoir été créé à un instant donné paraissait à Fred Hoyle bien plus critiquable que son hypothèse de création lente mais continue de matière dans la théorie de l’état stationnaire, ce qui est sans doute à l’origine de son rejet du Big Bang. De nombreux autres exemples de réticences sont connus chez des personnalités du monde scientifique, en particulier :
« Arno et moi, bien sûr, étions très heureux d’avoir une réponse de quelque nature que ce soit à notre problème. Toute explication raisonnable nous aurait satisfait. […] Nous nous étions habitués à l’idée d’une cosmologie de l’état stationnaire. […] Philosophiquement, j’aimais la cosmologie de l’état stationnaire. Aussi ai-je pensé que nous devions rapporter notre résultat comme une simple mesure : au moins la mesure pourrait rester vraie même si la cosmologie derrière se révélait fausse. »
Même aujourd’hui, et malgré ses succès indéniables, le Big Bang rencontre encore une opposition (quoique très faible) de la part d’une partie du monde scientifique, y compris chez certains astronomes. Parmi ceux-ci figurent ses opposants historiques comme Geoffrey Burbidge, Fred Hoyle et Jayant Narlikar, qui après avoir finalement abandonné la théorie de l’état stationnaire, en ont proposé une version modifiée, toujours basée sur la création de matière, mais avec une succession de phases d’expansion et de recontraction, la théorie de l'état quasi stationnaire[18], n’ayant pas rencontré de succès probant en raison de leur incapacité à faire des prédictions précises et compatibles avec les données observationnelles actuelles, notamment celles du fond diffus cosmologique[19]. Une des critiques récurrentes du Big Bang porte sur l’éventuelle incohérence entre l’âge de l’Univers, plus jeune que celui d’objets lointains, comme cela a été le cas pour les galaxies Abell 1835 IR1916 et HUDF-JD2, mais la plupart du temps, ces problèmes d’âge résultent surtout de mauvaises estimations de l’âge de ces objets (voir les articles correspondants), ainsi qu’une sous-estimation des barres d’erreur correspondantes[g].
Dans le monde francophone, Jean-Claude Pecker, membre de l’académie des sciences, Jean-Marc Bonnet-Bidaud, astrophysicien au Commissariat à l’énergie atomique émettent des critiques sur le Big Bang[20]. Christian Magnan, chercheur au Groupe de recherches en astronomie (GRAAL) de l'université de Montpellier continue à défendre fermement la réalité du Big Bang mais se montre néanmoins insatisfait du modèle standard de la cosmologie. Il critique notamment ce qu’il décrit comme « la soumission inconditionnelle au modèle d’Univers homogène et isotrope » (c’est-à-dire satisfaisant au principe cosmologique) qui conduit selon lui à des difficultés[21]. La plupart de ces critiques ne sont cependant pas étayées par des éléments scientifiques concrets, et ces personnes ne comptent pas de publications sur le sujet dans des revues scientifiques à comité de lecture[22]. Il n’en demeure pas moins que la presse scientifique grand public se fait souvent l’écho de telles positions marginales, offrant parfois une vision faussée du domaine à ses lecteurs[23].
Les progrès constants dans le domaine de la cosmologie observationnelle donnent à la théorie du Big Bang une assise solide dont résulte un large consensus parmi les chercheurs travaillant dans le domaine[24], même si des réserves sont émises par des chercheurs demeurant dans le cadre de cette théorie[25]. Il n’existe d’autre part aucun modèle concurrent sérieux au Big Bang. Le seul qui ait jamais existé, la théorie de l’état stationnaire, est aujourd’hui complètement marginal du fait de son incapacité à expliquer les observations élémentaires du fond diffus cosmologique, de l’abondance des éléments légers et surtout de l’évolution des galaxies. Ses auteurs se sont d’ailleurs finalement résignés à en proposer au début des années 1990 une version significativement différente, la théorie de l'état quasi stationnaire, qui comme son nom ne l’indique pas comporte un cycle de phases denses et chaudes, lors desquelles les conditions sont essentiellement semblables à celles du Big Bang.
Il n’existe désormais pas d’argument théorique sérieux pour remettre en cause le Big Bang. Celui-ci est en effet une conséquence relativement générique de la théorie de la relativité générale qui n’a, à l’heure actuelle, pas été mise en défaut par les observations. Remettre en cause le Big Bang nécessiterait donc soit de rejeter la relativité générale (malgré l’absence d’éléments observationnels allant dans ce sens), soit de supposer des propriétés extrêmement exotiques d’une ou plusieurs formes de matière. Même dans ce cas, il semble impossible de nier que la nucléosynthèse primordiale ait eu lieu, ce qui implique que l’Univers soit passé par une phase un milliard de fois plus chaude et un milliard de milliards de milliards de fois plus dense qu’aujourd’hui. De telles conditions rendent le terme de Big Bang légitime pour parler de cette époque dense et chaude. De plus, les seuls modèles réalistes permettant de rendre compte de la présence des grandes structures dans l’Univers supposent que celui-ci ait connu une phase dont les températures étaient entre 1026 et 1029 fois plus élevées qu’aujourd’hui.
Cela étant, il arrive que la presse scientifique grand public se fasse parfois l’écho de telles positions marginales[20],[23]. Il est par contre faux de dire que l’intégralité du scénario décrivant cette phase dense et chaude est comprise. Plusieurs époques ou phénomènes en sont encore mal connus, comme en particulier celle de la baryogénèse, qui a vu se produire un léger excès de matière par rapport à l’antimatière avant la disparition de cette dernière, ainsi que les détails de la fin de la phase d’inflation (si celle-ci a effectivement eu lieu), en particulier le préchauffage et le réchauffage : si les modèles de Big Bang sont en constante évolution, le concept général est en revanche très difficilement discutable.
L’illustration la plus révélatrice sans doute des réactions suscitées par l’invention du Big Bang est celle du pape Pie XII. Celui-ci, dans un discours de 1951 resté célèbre[26] et très explicitement intitulé Les preuves de l’existence de Dieu à la lumière de la science actuelle de la nature, fait le point sur les dernières découvertes en astrophysique, physique nucléaire et cosmologie, faisant preuve d’une connaissance aiguë de la science de son temps. Il ne mentionne aucunement la théorie de l’état stationnaire, mais tire de l’observation de l’expansion et de la cohérence entre âge estimé de l’Univers et autres méthodes de datation la preuve de la création du monde :
« […] Avec le même regard limpide et critique dont, il [l’esprit éclairé et enrichi par les connaissances scientifiques] examine et juge les faits, il y entrevoit et reconnaît l’œuvre de la Toute-Puissance créatrice, dont la vérité, suscitée par le puissant « Fiat » prononcé il y a des milliards d’années par l’Esprit créateur, s’est déployée dans l’Univers […]. Il semble, en vérité, que la science d’aujourd’hui, remontant d’un trait des millions de siècles, ait réussi à se faire témoin de ce « Fiat Lux » initial, de cet instant où surgit du néant avec la matière, un océan de lumière et de radiations, tandis que les particules des éléments chimiques se séparaient et s’assemblaient en millions de galaxies. »
Il conclut son texte en affirmant :
« Ainsi, création dans le temps ; et pour cela, un Créateur ; et par conséquent, Dieu ! Le voici, donc — encore qu’implicite et imparfait — le mot que Nous demandions à la science et que la présente génération attend d’elle. […] »
N’approuvant pas une telle interprétation de découvertes scientifiques, Lemaître demanda audience à Pie XII, lui faisant part de son point de vue que science et foi ne devaient pas être mêlées[27]. Il est souvent dit que Pie XII se rétracta de ce premier commentaire lors d’un discours prononcé l’année suivante, devant un auditoire d’astronomes[28]. Sans parler de rétractation, Pie XII n’évoque plus la création de l’Univers, mais invite les astronomes à « acquérir un perfectionnement plus profond de l’image astronomique de l’Univers ».
Sur les autres projets Wikimedia :
Concepts fondamentaux :
Fondateurs du modèle :
