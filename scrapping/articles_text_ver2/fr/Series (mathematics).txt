Série (mathématiques)
Séries numériques[modifier | modifier le code]
Aspects historiques[modifier | modifier le code]
Étude de la nature des séries numériques[modifier | modifier le code]
Séries et intégrales[modifier | modifier le code]
Séries à valeurs vectorielles[modifier | modifier le code]
Séries de fonctions[modifier | modifier le code]
Notion de sommes infinies[modifier | modifier le code]
Articles connexes[modifier | modifier le code]
Notes et références[modifier | modifier le code]
Convergence[modifier | modifier le code]
Exemple de série[modifier | modifier le code]
Reste d'une série convergente[modifier | modifier le code]
Série et suite des termes généraux[modifier | modifier le code]
Calculs explicites[modifier | modifier le code]
Principes d'étude[modifier | modifier le code]
Exemples de référence[modifier | modifier le code]
Contre-exemple de référence[modifier | modifier le code]
Séries trigonométriques et séries de Fourier[modifier | modifier le code]
Séries entières[modifier | modifier le code]
Séries de Dirichlet[modifier | modifier le code]
Les séries ne sont pas vraiment des sommes[modifier | modifier le code]
Procédés de sommation des séries divergentes[modifier | modifier le code]
Pages pour les contributeurs déconnectés en savoir plus
Sommaire
				déplacer vers la barre latérale
masquer
Pour les articles homonymes, voir Série.
En mathématiques, la notion de série permet de généraliser la notion de somme finie.
Étant donnée une suite de terme général un, étudier la série de terme général un c'est étudier la suite obtenue en prenant la somme des premiers termes de la suite (un), autrement dit la suite de terme général Sn défini par :
L'étude d'une série peut passer par la recherche d'une écriture simplifiée des sommes finies en jeu et par la recherche éventuelle d'une limite finie quand n tend vers l'infini. Quand cette limite existe, la série est dite convergente, et la limite de la suite (Sn) est alors appelée somme de la série, et notée 




∑

k
=
0


+
∞



u

k




{\displaystyle \sum _{k=0}^{+\infty }u_{k}}

.
Le calcul d'une somme finie ne pouvant pas toujours être simplifié, un certain nombre de méthodes permettent de déterminer la nature (convergence ou non) d'une série sans réaliser explicitement les calculs[2]. Toutefois, certaines règles de calcul sur les sommes finies ne sont pas nécessairement conservées par cette notion de série, comme la commutativité ou l'associativité, c'est-à-dire la possibilité de permuter les termes de la suite ou de regrouper certains d'entre eux sans modifier ni la convergence ni la somme de la série.
La notion de série peut être étendue à des sommes infinies dont les termes un ne sont pas nécessairement des nombres, mais par exemple des vecteurs, des fonctions ou des matrices.
Une série de terme général xn peut être définie formellement comme le couple formé des deux suites 





(

x

n


)


n
∈

N





{\displaystyle \left(x_{n}\right)_{n\in \mathbb {N} }}

 et 





(


∑

k
=
0


n



x

k



)


n
∈

N





{\displaystyle \left(\sum _{k=0}^{n}x_{k}\right)_{n\in \mathbb {N} }}

[3].
Le terme d'ordre n de la seconde suite, 




S

n


=

∑

k
=
0


n



x

k




{\displaystyle S_{n}=\sum _{k=0}^{n}x_{k}}

, est la somme des n + 1 premiers termes de la suite 



(

x

n



)

n
∈

N





{\displaystyle (x_{n})_{n\in \mathbb {N} }}

, appelé également somme partielle d'ordre n. La suite 





(

S

n


)


n
∈

N





{\displaystyle \left(S_{n}\right)_{n\in \mathbb {N} }}

 est appelée suite des sommes partielles de la série de terme xn.
Ainsi, la suite des sommes partielles associée à la série de terme général xn peut s'écrire :
Les séries numériques sont les séries dont les termes xn sont des nombres réels ou des nombres complexes. Il existe également des séries vectorielles, dont les termes sont des vecteurs d'un certain espace vectoriel. On peut ainsi étudier par exemple des séries de matrices ou des séries de fonctions.
On note la série de terme général xn :




∑

x

n




{\displaystyle \sum x_{n}}

 ou 




∑

n
≥
0



x

n




{\displaystyle \sum _{n\geq 0}x_{n}}

[réf. souhaitée].
Dire que la série numérique 



∑

x

n




{\displaystyle \sum x_{n}}

 est convergente signifie, par définition, que la suite des sommes partielles 



(

S

n



)

n
∈

N





{\displaystyle (S_{n})_{n\in \mathbb {N} }}

 est convergente ; sa limite S est alors appelée somme de la série, elle est notée 




∑

k
=
0


+
∞



x

k




{\displaystyle \sum _{k=0}^{+\infty }x_{k}}

, et son calcul est la sommation de la série. [réf. nécessaire] Dans le cas contraire, la série est dite divergente.
Deux séries sont dites de même nature si elles sont toutes deux convergentes ou toutes deux divergentes.
On parle de série absolument convergente lorsque la série de terme général |xk| est elle-même convergente (|x| signifiant ici « valeur absolue de x » si x est un nombre réel, « module de x » si x est un nombre complexe, norme s'il s'agit d'un élément d'un espace vectoriel normé). Si la série est convergente sans être absolument convergente, alors on parle de série semi-convergente.
Le fait qu'une série puisse être convergente résout beaucoup de problèmes, comme certains des paradoxes de Zénon. En revanche, il est rare qu'on sache calculer de façon explicite la somme d'une série. Hormis quelques calculs classiques, la théorie des séries a pour objectif de déterminer la nature d'une série sans calcul de la suite des sommes partielles, et éventuellement de procéder à un calcul approché de la somme.
Si la série converge, alors son terme général tend vers zéro. La réciproque est fausse (exemple de la série harmonique, dont le terme général tend vers zéro tout en étant divergente). Si une série ne respecte pas cette condition, on dit qu'elle diverge grossièrement.
La série de terme général (1/2)n est convergente et sa somme vaut :
1 + 1/2 + 1/4 + 1/8 + 1/16 + ⋯ = 2.
Il est possible de « visualiser » sa convergence sur la droite réelle : on peut imaginer un segment de longueur 2, que l'on découpe en segments successifs de longueurs 1, 1/2, 1/4, etc. Il y a toujours assez de place pour marquer le segment suivant, parce que la longueur restante est constamment égale à la longueur du segment qui vient d'être marqué. Lorsque nous avons marqué 1/2, il reste un morceau de longueur 1/2 non marqué, ainsi nous pouvons encore certainement marquer le prochain 1/4. Cet argument ne peut en aucune façon servir de démonstration que la somme de toutes les longueurs des segments est égale à 2, mais permet de deviner que cette somme va rester inférieure à 2 et donc que la suite des sommes partielles est croissante et majorée.
Cette série est une série géométrique ; on démontre sa convergence en écrivant pour tout entier naturel n, sa somme partielle au rang n qui vaut :
La suite géométrique 





(


(


1
2


)


n


)


n
∈

N





{\displaystyle \left(\left({\frac {1}{2}}\right)^{n}\right)_{n\in \mathbb {N} }}

 de raison 1/2 est convergente et de limite nulle donc
Si la série 



∑

x

n




{\displaystyle \sum x_{n}}

 est convergente, alors pour tout entier naturel n, la somme 




R

n


=

∑

k
=
n
+
1


∞



x

k




{\displaystyle R_{n}=\sum _{k=n+1}^{\infty }x_{k}}

 existe, et 




lim

n
→
+
∞



R

n


=
0


{\displaystyle \lim _{n\rightarrow +\infty }R_{n}=0}

. Le terme Rn s'appelle le reste d'ordre n de la série 



∑

x

n




{\displaystyle \sum x_{n}}

.
Il est facile, par un procédé itératif, de calculer un terme de la suite des sommes partielles. Pour une série convergente, et pour tout naturel n, la relation entre la somme, la somme partielle d'ordre n et le reste d'ordre n s'écrit




S
=

S

n


+

R

n


.


{\displaystyle S=S_{n}+R_{n}.}


Ainsi, si l'on sait borner le reste, la somme partielle peut être vue comme une valeur approchée de la somme, avec une incertitude connue.
Il est possible de retrouver le terme général à partir de la suite des sommes partielles par les formules





a

0


=

S

0



∀
n
∈


N


∗




a

n


=

S

n


−

S

n
−
1


.


{\displaystyle a_{0}=S_{0}\qquad \forall n\in \mathbb {N} ^{*}\quad a_{n}=S_{n}-S_{n-1}.}
Ainsi toute somme partielle est une suite, mais toute suite est également une somme partielle (associée à la série des différences des termes consécutifs, avec un premier terme nul). Selon le cas, on aura intérêt à considérer une suite comme une somme partielle, ou inversement, selon la facilité de l'analyse des termes.
Par ailleurs, si la série 



∑

a

n




{\displaystyle \sum a_{n}}

 est convergente, alors la suite 



(

a

n



)

n
∈

N





{\displaystyle (a_{n})_{n\in \mathbb {N} }}

 converge vers 0. En effet, si l'on suppose que la série converge et a pour somme S, alors on a 




a

n


=

S

n


−

S

n
−
1



⟶

n
→
+
∞


S
−
S
=
0


{\displaystyle a_{n}=S_{n}-S_{n-1}\longrightarrow _{n\to +\infty }S-S=0}

.
La réciproque est fausse (on peut prendre la série harmonique comme contre-exemple). Lorsque le terme général d'une série ne tend pas vers 0, celle-ci est dite trivialement ou grossièrement divergente.
Exemples : 



∑
(
−
1

)

n




{\displaystyle \sum (-1)^{n}}

 est une série grossièrement divergente ; en revanche, pour 



∑



ln
⁡
n

n




{\displaystyle \sum {\frac {\ln n}{n}}}

, bien que le terme général tende vers zéro, on ne peut pas trancher sans d'autres théorèmes.
La considération de véritables sommes infinies est une question étroitement liée à celle du passage à la limite. L'absence persistante des concepts satisfaisants engendra de nombreuses interrogations et spéculations, à l'exemple des paradoxes de Zénon. On trouve néanmoins déjà chez Archimède (La quadrature de la parabole) les premières sommations explicites, avec les progressions géométriques comme 1/4 + 1/16 + 1/64 + 1/256 + ⋯.
En Angleterre, Richard Suiseth (XIVe siècle) calcule la somme de la série de terme général n/2n et son contemporain Nicole Oresme établit que la série harmonique (de terme général 1/n) est divergente[4]. À la même époque, le mathématicien et astronome indien Madhava est le premier à considérer des développements de fonctions trigonométriques, sous forme de séries, séries de Taylor, séries trigonométriques. Il utilise ces concepts pour des calculs d'approximation (notamment pour estimer le nombre π) et effectue des estimations de l'erreur commise. Il introduit aussi les premiers critères de convergence. Ses travaux furent poursuivis par ses successeurs de l'école du Kerala, région du sud de l'Inde, et nous sont connus par le livre Yuktibhasa[5].
Au XVIIe siècle, James Gregory redécouvre plusieurs de ces résultats, notamment le développement des fonctions trigonométriques en séries de Taylor et celui de la fonction arc tangente permettant le calcul de π. En 1715, Brook Taylor, en donnant la construction générale des séries qui portent son nom, établit un lien fructueux avec le calcul différentiel. Au XVIIIe siècle également, Leonhard Euler établit de nombreuses relations remarquables portant sur des séries et introduit les séries hypergéométriques.
Il est rare de pouvoir calculer explicitement tous les termes de la suite des sommes partielles.
Il existe un grand nombre de règles pour les séries à termes positifs. Elles sont toutes basées sur le principe de comparaison : si, pour tout entier n, on a 



0
≤

u

n


≤

v

n




{\displaystyle 0\leq u_{n}\leq v_{n}}

, alors
Cela reste vrai si l'on a les inégalités précédentes non plus pour tout entier n, mais pour tout entier n « assez grand » (c'est-à-dire à partir d'un certain rang), et conduit
au résultat suivant :
Pour ces séries à termes positifs, il convient donc de déterminer la nature de certaines séries de références (telles que les séries géométriques ou les séries de Riemann), puis de comparer à ces séries.
L'étude des séries à termes réels ou complexes, sans hypothèse particulière, peut poser plus de problèmes. Une condition suffisante a une grande importance : si la série des valeurs absolues (série à termes réels) ou des modules (séries à termes complexes) 



∑

|

a

n


|



{\displaystyle \sum \left|a_{n}\right|}

 converge, alors la série 



∑

a

n




{\displaystyle \sum a_{n}}

 converge également. Elle est alors dite absolument convergente.
Il existe des séries convergentes sans être absolument convergentes, comme la série harmonique alternée 



∑



(
−
1

)

n



n




{\displaystyle \sum {\frac {(-1)^{n}}{n}}}

. Les méthodes d'étude pour ce type de série, plus techniques, (critère de convergence des séries alternées, théorème d'Abel, …) sont présentées dans l'article détaillé Série convergente.
Attention : les critères de convergence concernant les séries à termes positifs peuvent ne pas s'appliquer dans le cas général.
Un exemple typique est celui de la série 




∑

n
=
1


∞





(
−
1

)

n




n





{\displaystyle \sum _{n=1}^{\infty }{\frac {(-1)^{n}}{\sqrt {n}}}}

.
Elle est convergente, car c'est une série alternée dont le terme général tend vers zéro en décroissant en valeur absolue, mais pas
absolument convergente : la série des valeurs absolues est une série de Riemann divergente.
Par contre, la série 




∑

n
=
1


∞





(
−
1

)

n






n


+
(
−
1

)

n
+
1







{\displaystyle \sum _{n=1}^{\infty }{\frac {(-1)^{n}}{{\sqrt {n}}+(-1)^{n+1}}}}

 est divergente. Cet exemple illustre deux phénomènes :
Le critère de comparaison entre série et intégrale est très utile, c'est lui qui permet de déterminer notamment la convergence ou la divergence des séries de Riemann et de Bertrand.
Soit 



f
:
[
1
,
+
∞
[
→

R



{\displaystyle f:[1,+\infty [\to \mathbb {R} }

 une fonction décroissante et positive. Alors la série 




∑

n
=
1


∞


f
(
n
)


{\displaystyle \sum _{n=1}^{\infty }f(n)}

 et l'intégrale 




∫

1


∞


f
(
t
)


d

t


{\displaystyle \int _{1}^{\infty }f(t)\,\mathrm {d} t}

 sont simultanément convergentes ou divergentes.
Si E est un espace vectoriel normé, une série dont les termes sont à valeurs dans E est dite convergente lorsque la suite des sommes partielles converge pour la norme choisie. Si E est de dimension finie, tous les choix de normes donneront la même notion de convergence.
Dans le cas des espaces de Banach, beaucoup de critères de convergence peuvent être énoncés, puisqu'il suffit de prouver la convergence absolue de la série pour montrer qu'elle converge (on parle dans ce cas de convergence normale). Cela permet fréquemment de conclure avec les outils d'étude des séries à termes positifs.
Plus généralement, la notion de série peut être définie dans tout groupe abélien topologique.
Formellement, les séries de fonctions sont simplement des séries dont le terme général appartient à un espace vectoriel de fonctions. Ainsi la fonction exponentielle est somme d'une série de fonctions puissances puisque
Il existe de nombreuses façons non équivalentes de définir la convergence d'une telle série, comme dans le cas des suites de fonctions. Les plus classiques sont sans doute la convergence simple et la convergence uniforme. Un grand nombre de théorèmes existent détaillant, en fonction du type de convergence, s'il est possible d'effectuer des calculs tels que dérivation ou intégration de la fonction somme d'une série.
Les séries trigonométriques sont obtenues en sommant des fonctions sinusoïdales de fréquence n f où f est une fréquence de référence donnée. Une question fondamentale en analyse harmonique est la possibilité de faire apparaître une fonction périodique donnée comme somme d'une série trigonométrique : sa série de Fourier.
La plupart des fonctions usuelles en mathématiques peuvent être représentées localement par une série de Taylor. Ce sont des séries dont le terme général s'écrit avec une puissance d'une variable ; elles sont appelées séries entières. Mais seulement dans certains cas.
Historiquement, des mathématiciens comme Leonhard Euler travaillaient librement avec les séries, même si celles-ci n'étaient pas convergentes.
Lorsque les bases du calcul ont été solidement posées au XIXe siècle, des démonstrations rigoureuses de la convergence des séries ont été exigées.
Cependant, les calculs formels avec des séries (pas forcément convergentes) sont à l'origine des séries formelles dans les anneaux, en algèbre générale, mais aussi en algèbre combinatoire pour décrire et étudier certaines suites grâce à leurs fonctions génératrices.
Les séries ne sont que l'exemple le plus simple de formalisation de la notion de somme infinie. Il existe d'autres définitions, plus exigeantes ou au contraire plus souples.
Il y a dans la définition des sommes de séries convergentes un calcul de somme finie, suivi d'un passage à la limite. Cette deuxième étape de passage à la limite fait que l'expression « somme infinie » n'est pas correcte pour qualifier les séries. Une telle « somme » n'est en effet ni commutative ni associative. Il n'est pas non plus possible, en général, de dériver une telle somme terme à terme par rapport à un paramètre. [pourquoi ?] [réf. souhaitée]
Les familles sommables ont des propriétés qui leur donnent beaucoup plus de titres à être qualifiées de « sommes infinies ». Alors que, dans le cas des séries, on ajoute les termes dans l'ordre de succession des indices u0,u1, … puis un, la notion de famille sommable demande d'obtenir un même résultat quel que soit l'ordre dans lequel on effectue les sommations. Ainsi, pour les familles sommables, la propriété de commutativité est vraie par définition même.
Les procédés de sommation sont des types de convergence plus faibles permettant de définir la somme de certaines séries divergentes. Par exemple, le procédé de sommation de Cesàro donne pour résultat 1/2 lorsqu'on somme la série de Grandi
Il est défini en calculant successivement les moyennes des n premiers termes de la suite des sommes partielles et en passant à la limite.
Les autres procédés de sommation les plus classiques sont la sommation d'Abel et la sommation de Borel.
Sur les autres projets Wikimedia :

